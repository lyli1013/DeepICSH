ACC_average: 0.7236959761549926
Sens_average: 0.5610501066098081
Spec_average: 0.8866311300639659
MCC_average: 0.4739352267174383
ROC_average: 0.7433804193319119
PRC_average: 0.816064077662624nohup: ignoring input
Using TensorFlow backend.
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

2023-05-26 19:32:15.369312: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-05-26 19:32:15.406425: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz
2023-05-26 19:32:15.439335: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5632d81123f0 executing computations on platform Host. Devices:
2023-05-26 19:32:15.439398: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-05-26 19:32:15.481227: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:40: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 8, activation="relu", padding="same")`
  omics_conv1_ = Conv1D(128, 8, activation='relu', border_mode='same')
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:42: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 1, activation="relu", padding="same")`
  omics_conv2_ = Conv1D(64, 1, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:44: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation="relu", padding="same")`
  omics_conv3_ = Conv1D(64, 3, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:46: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 1, activation="relu", padding="same")`
  omics_conv4_ = Conv1D(128, 1, activation='relu', border_mode='same')
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:63: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_omics], output=[pred_output])
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Fitting first model...
Train on 2417 samples, validate on 269 samples
Epoch 1/10

  64/2417 [..............................] - ETA: 35s - loss: 0.6832 - acc: 0.6719
 192/2417 [=>............................] - ETA: 12s - loss: 0.6356 - acc: 0.5625
 320/2417 [==>...........................] - ETA: 7s - loss: 0.5983 - acc: 0.5813 
 448/2417 [====>.........................] - ETA: 5s - loss: 0.6011 - acc: 0.5558
 576/2417 [======>.......................] - ETA: 3s - loss: 0.6203 - acc: 0.5920
 704/2417 [=======>......................] - ETA: 3s - loss: 0.6742 - acc: 0.6094
 832/2417 [=========>....................] - ETA: 2s - loss: 0.6677 - acc: 0.6346
 960/2417 [==========>...................] - ETA: 2s - loss: 0.6542 - acc: 0.6521
1088/2417 [============>.................] - ETA: 1s - loss: 0.6523 - acc: 0.6608
1216/2417 [==============>...............] - ETA: 1s - loss: 0.6449 - acc: 0.6727
1344/2417 [===============>..............] - ETA: 1s - loss: 0.6503 - acc: 0.6786
1472/2417 [=================>............] - ETA: 1s - loss: 0.6459 - acc: 0.6793
1600/2417 [==================>...........] - ETA: 0s - loss: 0.6415 - acc: 0.6850
1728/2417 [====================>.........] - ETA: 0s - loss: 0.6354 - acc: 0.6898
1856/2417 [======================>.......] - ETA: 0s - loss: 0.6374 - acc: 0.6907
1984/2417 [=======================>......] - ETA: 0s - loss: 0.6305 - acc: 0.6905
2112/2417 [=========================>....] - ETA: 0s - loss: 0.6286 - acc: 0.6903
2240/2417 [==========================>...] - ETA: 0s - loss: 0.6271 - acc: 0.6915
2368/2417 [============================>.] - ETA: 0s - loss: 0.6310 - acc: 0.6896
2417/2417 [==============================] - 2s 916us/step - loss: 0.6300 - acc: 0.6905 - val_loss: 0.5237 - val_acc: 0.7658

Epoch 00001: val_acc improved from -inf to 0.76580, saving model to /data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/checkpoints_4layer_130-/omics_model/model_multi_omics1.hdf5
Epoch 2/10

  64/2417 [..............................] - ETA: 1s - loss: 0.4838 - acc: 0.7656
 192/2417 [=>............................] - ETA: 1s - loss: 0.5710 - acc: 0.7135
 320/2417 [==>...........................] - ETA: 1s - loss: 0.5563 - acc: 0.7344
 448/2417 [====>.........................] - ETA: 1s - loss: 0.5567 - acc: 0.7321
 576/2417 [======>.......................] - ETA: 0s - loss: 0.5463 - acc: 0.7396
 704/2417 [=======>......................] - ETA: 0s - loss: 0.5598 - acc: 0.7230
 832/2417 [=========>....................] - ETA: 0s - loss: 0.5627 - acc: 0.7151
 960/2417 [==========>...................] - ETA: 0s - loss: 0.5747 - acc: 0.7125
1088/2417 [============>.................] - ETA: 0s - loss: 0.5754 - acc: 0.7160
1216/2417 [==============>...............] - ETA: 0s - loss: 0.5794 - acc: 0.7188
1344/2417 [===============>..............] - ETA: 0s - loss: 0.5790 - acc: 0.7158
1472/2417 [=================>............] - ETA: 0s - loss: 0.5781 - acc: 0.7188
1600/2417 [==================>...........] - ETA: 0s - loss: 0.5787 - acc: 0.7175
1728/2417 [====================>.........] - ETA: 0s - loss: 0.5754 - acc: 0.7222
1856/2417 [======================>.......] - ETA: 0s - loss: 0.5731 - acc: 0.7236
1984/2417 [=======================>......] - ETA: 0s - loss: 0.5711 - acc: 0.7233
2112/2417 [=========================>....] - ETA: 0s - loss: 0.5728 - acc: 0.7221
2240/2417 [==========================>...] - ETA: 0s - loss: 0.5750 - acc: 0.7219
2368/2417 [============================>.] - ETA: 0s - loss: 0.5819 - acc: 0.7188
2417/2417 [==============================] - 1s 483us/step - loss: 0.5804 - acc: 0.7187 - val_loss: 0.5223 - val_acc: 0.7695

Epoch 00002: val_acc improved from 0.76580 to 0.76952, saving model to /data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/checkpoints_4layer_130-/omics_model/model_multi_omics1.hdf5
Epoch 3/10

  64/2417 [..............................] - ETA: 1s - loss: 0.5423 - acc: 0.7812
 192/2417 [=>............................] - ETA: 1s - loss: 0.5455 - acc: 0.7396
 320/2417 [==>...........................] - ETA: 0s - loss: 0.5565 - acc: 0.7438
 448/2417 [====>.........................] - ETA: 0s - loss: 0.5665 - acc: 0.7411
 576/2417 [======>.......................] - ETA: 0s - loss: 0.5661 - acc: 0.7326
 704/2417 [=======>......................] - ETA: 0s - loss: 0.5682 - acc: 0.7259
 832/2417 [=========>....................] - ETA: 0s - loss: 0.5720 - acc: 0.7224
 960/2417 [==========>...................] - ETA: 0s - loss: 0.5716 - acc: 0.7208
1088/2417 [============>.................] - ETA: 0s - loss: 0.5752 - acc: 0.7160
1216/2417 [==============>...............] - ETA: 0s - loss: 0.5729 - acc: 0.7204
1344/2417 [===============>..............] - ETA: 0s - loss: 0.5751 - acc: 0.7173
1472/2417 [=================>............] - ETA: 0s - loss: 0.5722 - acc: 0.7215
1600/2417 [==================>...........] - ETA: 0s - loss: 0.5716 - acc: 0.7188
1728/2417 [====================>.........] - ETA: 0s - loss: 0.5726 - acc: 0.7159
1856/2417 [======================>.......] - ETA: 0s - loss: 0.5742 - acc: 0.7161
1984/2417 [=======================>......] - ETA: 0s - loss: 0.5677 - acc: 0.7203
2112/2417 [=========================>....] - ETA: 0s - loss: 0.5772 - acc: 0.7188
2240/2417 [==========================>...] - ETA: 0s - loss: 0.5754 - acc: 0.7223
2368/2417 [============================>.] - ETA: 0s - loss: 0.5757 - acc: 0.7196
2417/2417 [==============================] - 1s 468us/step - loss: 0.5765 - acc: 0.7199 - val_loss: 0.5076 - val_acc: 0.7658

Epoch 00003: val_acc did not improve from 0.76952
Epoch 4/10

  64/2417 [..............................] - ETA: 1s - loss: 0.5375 - acc: 0.7500
 192/2417 [=>............................] - ETA: 1s - loss: 0.5923 - acc: 0.6979
 320/2417 [==>...........................] - ETA: 0s - loss: 0.5768 - acc: 0.7250
 448/2417 [====>.........................] - ETA: 0s - loss: 0.5789 - acc: 0.7165
 576/2417 [======>.......................] - ETA: 0s - loss: 0.5714 - acc: 0.7135
 704/2417 [=======>......................] - ETA: 0s - loss: 0.5753 - acc: 0.7116
 832/2417 [=========>....................] - ETA: 0s - loss: 0.5741 - acc: 0.7103
 960/2417 [==========>...................] - ETA: 0s - loss: 0.5736 - acc: 0.7083
1088/2417 [============>.................] - ETA: 0s - loss: 0.5746 - acc: 0.7086
1216/2417 [==============>...............] - ETA: 0s - loss: 0.5725 - acc: 0.7113
1344/2417 [===============>..............] - ETA: 0s - loss: 0.5744 - acc: 0.7165
1472/2417 [=================>............] - ETA: 0s - loss: 0.5710 - acc: 0.7188
1600/2417 [==================>...........] - ETA: 0s - loss: 0.5716 - acc: 0.7212
1728/2417 [====================>.........] - ETA: 0s - loss: 0.5752 - acc: 0.7205
1856/2417 [======================>.......] - ETA: 0s - loss: 0.5789 - acc: 0.7231
1984/2417 [=======================>......] - ETA: 0s - loss: 0.5774 - acc: 0.7228
2112/2417 [=========================>....] - ETA: 0s - loss: 0.5765 - acc: 0.7221
2240/2417 [==========================>...] - ETA: 0s - loss: 0.5748 - acc: 0.7241
2368/2417 [============================>.] - ETA: 0s - loss: 0.5747 - acc: 0.7226
2417/2417 [==============================] - 1s 466us/step - loss: 0.5733 - acc: 0.7232 - val_loss: 0.5085 - val_acc: 0.7695

Epoch 00004: val_acc did not improve from 0.76952
Epoch 5/10

  64/2417 [..............................] - ETA: 1s - loss: 0.6090 - acc: 0.7188
 192/2417 [=>............................] - ETA: 1s - loss: 0.5596 - acc: 0.7188
 320/2417 [==>...........................] - ETA: 0s - loss: 0.5436 - acc: 0.7312
 448/2417 [====>.........................] - ETA: 0s - loss: 0.5494 - acc: 0.7254
 576/2417 [======>.......................] - ETA: 0s - loss: 0.5494 - acc: 0.7257
 704/2417 [=======>......................] - ETA: 0s - loss: 0.5626 - acc: 0.7315
 832/2417 [=========>....................] - ETA: 0s - loss: 0.5649 - acc: 0.7320
 960/2417 [==========>...................] - ETA: 0s - loss: 0.5642 - acc: 0.7323
1088/2417 [============>.................] - ETA: 0s - loss: 0.5720 - acc: 0.7270
1216/2417 [==============>...............] - ETA: 0s - loss: 0.5680 - acc: 0.7294
1344/2417 [===============>..............] - ETA: 0s - loss: 0.5640 - acc: 0.7307
1472/2417 [=================>............] - ETA: 0s - loss: 0.5647 - acc: 0.7310
1600/2417 [==================>...........] - ETA: 0s - loss: 0.5666 - acc: 0.7300
1728/2417 [====================>.........] - ETA: 0s - loss: 0.5695 - acc: 0.7269
1856/2417 [======================>.......] - ETA: 0s - loss: 0.5702 - acc: 0.7252
1984/2417 [=======================>......] - ETA: 0s - loss: 0.5709 - acc: 0.7228
2112/2417 [=========================>....] - ETA: 0s - loss: 0.5700 - acc: 0.7235
2240/2417 [==========================>...] - ETA: 0s - loss: 0.5711 - acc: 0.7219
2368/2417 [============================>.] - ETA: 0s - loss: 0.5708 - acc: 0.7238
2417/2417 [==============================] - 1s 466us/step - loss: 0.5715 - acc: 0.7236 - val_loss: 0.5108 - val_acc: 0.7658

Epoch 00005: val_acc did not improve from 0.76952
Epoch 6/10

  64/2417 [..............................] - ETA: 1s - loss: 0.5356 - acc: 0.7656
 192/2417 [=>............................] - ETA: 1s - loss: 0.5730 - acc: 0.7188
 320/2417 [==>...........................] - ETA: 0s - loss: 0.5676 - acc: 0.7188
 448/2417 [====>.........................] - ETA: 0s - loss: 0.5762 - acc: 0.7054
 576/2417 [======>.......................] - ETA: 0s - loss: 0.5731 - acc: 0.7135
 704/2417 [=======>......................] - ETA: 0s - loss: 0.5713 - acc: 0.7173
 832/2417 [=========>....................] - ETA: 0s - loss: 0.5679 - acc: 0.7163
 960/2417 [==========>...................] - ETA: 0s - loss: 0.5665 - acc: 0.7188
1088/2417 [============>.................] - ETA: 0s - loss: 0.5601 - acc: 0.7289
1216/2417 [==============>...............] - ETA: 0s - loss: 0.5682 - acc: 0.7229
1344/2417 [===============>..............] - ETA: 0s - loss: 0.5701 - acc: 0.7180
1472/2417 [=================>............] - ETA: 0s - loss: 0.5667 - acc: 0.7181
1600/2417 [==================>...........] - ETA: 0s - loss: 0.5662 - acc: 0.7156
1728/2417 [====================>.........] - ETA: 0s - loss: 0.5682 - acc: 0.7141
1856/2417 [======================>.......] - ETA: 0s - loss: 0.5651 - acc: 0.7182
1984/2417 [=======================>......] - ETA: 0s - loss: 0.5626 - acc: 0.7223
2112/2417 [=========================>....] - ETA: 0s - loss: 0.5721 - acc: 0.7188
2240/2417 [==========================>...] - ETA: 0s - loss: 0.5707 - acc: 0.7214
2368/2417 [============================>.] - ETA: 0s - loss: 0.5704 - acc: 0.7230
2417/2417 [==============================] - 1s 463us/step - loss: 0.5697 - acc: 0.7236 - val_loss: 0.5016 - val_acc: 0.7621

Epoch 00006: val_acc did not improve from 0.76952
Epoch 7/10

  64/2417 [..............................] - ETA: 1s - loss: 0.5776 - acc: 0.7031
 192/2417 [=>............................] - ETA: 1s - loss: 0.5962 - acc: 0.6979
 320/2417 [==>...........................] - ETA: 0s - loss: 0.5620 - acc: 0.7188
 448/2417 [====>.........................] - ETA: 0s - loss: 0.5817 - acc: 0.6987
 576/2417 [======>.......................] - ETA: 0s - loss: 0.5852 - acc: 0.7031
 704/2417 [=======>......................] - ETA: 0s - loss: 0.5703 - acc: 0.7088
 832/2417 [=========>....................] - ETA: 0s - loss: 0.5762 - acc: 0.6995
 960/2417 [==========>...................] - ETA: 0s - loss: 0.5791 - acc: 0.6927
1088/2417 [============>.................] - ETA: 0s - loss: 0.5859 - acc: 0.7068
1216/2417 [==============>...............] - ETA: 0s - loss: 0.5819 - acc: 0.7122
1344/2417 [===============>..............] - ETA: 0s - loss: 0.5809 - acc: 0.7083
1472/2417 [=================>............] - ETA: 0s - loss: 0.5835 - acc: 0.7072
1600/2417 [==================>...........] - ETA: 0s - loss: 0.5818 - acc: 0.7100
1728/2417 [====================>.........] - ETA: 0s - loss: 0.5795 - acc: 0.7124
1856/2417 [======================>.......] - ETA: 0s - loss: 0.5787 - acc: 0.7112
1984/2417 [=======================>......] - ETA: 0s - loss: 0.5828 - acc: 0.7077
2112/2417 [=========================>....] - ETA: 0s - loss: 0.5779 - acc: 0.7116
2240/2417 [==========================>...] - ETA: 0s - loss: 0.5731 - acc: 0.7170
2368/2417 [============================>.] - ETA: 0s - loss: 0.5727 - acc: 0.7192
2417/2417 [==============================] - 1s 459us/step - loss: 0.5720 - acc: 0.7207 - val_loss: 0.5109 - val_acc: 0.7621

Epoch 00007: val_acc did not improve from 0.76952
Epoch 8/10

  64/2417 [..............................] - ETA: 1s - loss: 0.5839 - acc: 0.6875
 192/2417 [=>............................] - ETA: 1s - loss: 0.6516 - acc: 0.7083
 320/2417 [==>...........................] - ETA: 0s - loss: 0.6346 - acc: 0.6969
 448/2417 [====>.........................] - ETA: 0s - loss: 0.6174 - acc: 0.6987
 576/2417 [======>.......................] - ETA: 0s - loss: 0.6169 - acc: 0.6840
 704/2417 [=======>......................] - ETA: 0s - loss: 0.6024 - acc: 0.6946
 832/2417 [=========>....................] - ETA: 0s - loss: 0.5929 - acc: 0.7007
 960/2417 [==========>...................] - ETA: 0s - loss: 0.5840 - acc: 0.7094
1088/2417 [============>.................] - ETA: 0s - loss: 0.5819 - acc: 0.7123
1216/2417 [==============>...............] - ETA: 0s - loss: 0.5814 - acc: 0.7097
1344/2417 [===============>..............] - ETA: 0s - loss: 0.5816 - acc: 0.7054
1472/2417 [=================>............] - ETA: 0s - loss: 0.5770 - acc: 0.7092
1600/2417 [==================>...........] - ETA: 0s - loss: 0.5746 - acc: 0.7137
1728/2417 [====================>.........] - ETA: 0s - loss: 0.5787 - acc: 0.7130
1856/2417 [======================>.......] - ETA: 0s - loss: 0.5729 - acc: 0.7188
1984/2417 [=======================>......] - ETA: 0s - loss: 0.5741 - acc: 0.7162
2112/2417 [=========================>....] - ETA: 0s - loss: 0.5712 - acc: 0.7188
2240/2417 [==========================>...] - ETA: 0s - loss: 0.5696 - acc: 0.7201
2368/2417 [============================>.] - ETA: 0s - loss: 0.5684 - acc: 0.7209
2417/2417 [==============================] - 1s 479us/step - loss: 0.5671 - acc: 0.7220 - val_loss: 0.4983 - val_acc: 0.7695

Epoch 00008: val_acc did not improve from 0.76952
Epoch 9/10

  64/2417 [..............................] - ETA: 1s - loss: 0.6185 - acc: 0.6875
 192/2417 [=>............................] - ETA: 1s - loss: 0.6023 - acc: 0.7083
 320/2417 [==>...........................] - ETA: 1s - loss: 0.6020 - acc: 0.7063
 448/2417 [====>.........................] - ETA: 1s - loss: 0.6102 - acc: 0.6897
 576/2417 [======>.......................] - ETA: 0s - loss: 0.6102 - acc: 0.6840
 704/2417 [=======>......................] - ETA: 0s - loss: 0.5912 - acc: 0.6974
 832/2417 [=========>....................] - ETA: 0s - loss: 0.5859 - acc: 0.7067
 960/2417 [==========>...................] - ETA: 0s - loss: 0.5818 - acc: 0.7135
1088/2417 [============>.................] - ETA: 0s - loss: 0.5793 - acc: 0.7160
1216/2417 [==============>...............] - ETA: 0s - loss: 0.5789 - acc: 0.7138
1344/2417 [===============>..............] - ETA: 0s - loss: 0.5740 - acc: 0.7158
1472/2417 [=================>............] - ETA: 0s - loss: 0.5718 - acc: 0.7188
1600/2417 [==================>...........] - ETA: 0s - loss: 0.5719 - acc: 0.7175
1728/2417 [====================>.........] - ETA: 0s - loss: 0.5769 - acc: 0.7118
1856/2417 [======================>.......] - ETA: 0s - loss: 0.5737 - acc: 0.7128
1984/2417 [=======================>......] - ETA: 0s - loss: 0.5772 - acc: 0.7152
2112/2417 [=========================>....] - ETA: 0s - loss: 0.5732 - acc: 0.7188
2240/2417 [==========================>...] - ETA: 0s - loss: 0.5721 - acc: 0.7192
2368/2417 [============================>.] - ETA: 0s - loss: 0.5691 - acc: 0.7221
2417/2417 [==============================] - 1s 517us/step - loss: 0.5670 - acc: 0.7236 - val_loss: 0.4983 - val_acc: 0.7695

Epoch 00009: val_acc did not improve from 0.76952
Epoch 10/10

  64/2417 [..............................] - ETA: 1s - loss: 0.5231 - acc: 0.7031
 192/2417 [=>............................] - ETA: 1s - loss: 0.5358 - acc: 0.7292
 320/2417 [==>...........................] - ETA: 1s - loss: 0.5552 - acc: 0.7312
 448/2417 [====>.........................] - ETA: 0s - loss: 0.5444 - acc: 0.7455
 576/2417 [======>.......................] - ETA: 0s - loss: 0.5383 - acc: 0.7483
 704/2417 [=======>......................] - ETA: 0s - loss: 0.5445 - acc: 0.7358
 832/2417 [=========>....................] - ETA: 0s - loss: 0.5538 - acc: 0.7236
 960/2417 [==========>...................] - ETA: 0s - loss: 0.5524 - acc: 0.7250
1088/2417 [============>.................] - ETA: 0s - loss: 0.5576 - acc: 0.7243
1216/2417 [==============>...............] - ETA: 0s - loss: 0.5589 - acc: 0.7270
1344/2417 [===============>..............] - ETA: 0s - loss: 0.5549 - acc: 0.7299
1472/2417 [=================>............] - ETA: 0s - loss: 0.5529 - acc: 0.7310
1600/2417 [==================>...........] - ETA: 0s - loss: 0.5596 - acc: 0.7250
1728/2417 [====================>.........] - ETA: 0s - loss: 0.5772 - acc: 0.7164
1856/2417 [======================>.......] - ETA: 0s - loss: 0.5721 - acc: 0.7214
1984/2417 [=======================>......] - ETA: 0s - loss: 0.5734 - acc: 0.7193
2112/2417 [=========================>....] - ETA: 0s - loss: 0.5737 - acc: 0.7169
2240/2417 [==========================>...] - ETA: 0s - loss: 0.5702 - acc: 0.7192
2368/2417 [============================>.] - ETA: 0s - loss: 0.5702 - acc: 0.7196
2417/2417 [==============================] - 1s 478us/step - loss: 0.5694 - acc: 0.7207 - val_loss: 0.5090 - val_acc: 0.7695

Epoch 00010: val_acc did not improve from 0.76952
Saved model to disk
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:40: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 8, activation="relu", padding="same")`
  omics_conv1_ = Conv1D(128, 8, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:42: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 1, activation="relu", padding="same")`
  omics_conv2_ = Conv1D(64, 1, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:44: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation="relu", padding="same")`
  omics_conv3_ = Conv1D(64, 3, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:46: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 1, activation="relu", padding="same")`
  omics_conv4_ = Conv1D(128, 1, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:63: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_omics], output=[pred_output])
ACC: 0.7130044843049327
Sens: 0.5744047619047619
Spec: 0.8528528528528528
MCC: 0.4445902626139731
ROC_AUC: 0.7396816459316459
PRC_ROC: 0.8154313631517387
WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:40: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 8, activation="relu", padding="same")`
  omics_conv1_ = Conv1D(128, 8, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:42: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 1, activation="relu", padding="same")`
  omics_conv2_ = Conv1D(64, 1, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:44: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation="relu", padding="same")`
  omics_conv3_ = Conv1D(64, 3, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:46: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 1, activation="relu", padding="same")`
  omics_conv4_ = Conv1D(128, 1, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:63: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_omics], output=[pred_output])
Fitting first model...
Train on 2417 samples, validate on 269 samples
Epoch 1/10

  64/2417 [..............................] - ETA: 29s - loss: 0.6651 - acc: 0.6406
 192/2417 [=>............................] - ETA: 10s - loss: 0.6538 - acc: 0.5260
 320/2417 [==>...........................] - ETA: 6s - loss: 0.6323 - acc: 0.5406 
 448/2417 [====>.........................] - ETA: 4s - loss: 0.6244 - acc: 0.5469
 576/2417 [======>.......................] - ETA: 3s - loss: 0.6351 - acc: 0.5903
 704/2417 [=======>......................] - ETA: 2s - loss: 0.6283 - acc: 0.6222
 832/2417 [=========>....................] - ETA: 2s - loss: 0.6178 - acc: 0.6334
 960/2417 [==========>...................] - ETA: 1s - loss: 0.6261 - acc: 0.6479
1088/2417 [============>.................] - ETA: 1s - loss: 0.6196 - acc: 0.6553
1216/2417 [==============>...............] - ETA: 1s - loss: 0.6151 - acc: 0.6678
1344/2417 [===============>..............] - ETA: 1s - loss: 0.6140 - acc: 0.6682
1472/2417 [=================>............] - ETA: 0s - loss: 0.6104 - acc: 0.6732
1600/2417 [==================>...........] - ETA: 0s - loss: 0.6071 - acc: 0.6831
1728/2417 [====================>.........] - ETA: 0s - loss: 0.6048 - acc: 0.6863
1856/2417 [======================>.......] - ETA: 0s - loss: 0.6035 - acc: 0.6880
1984/2417 [=======================>......] - ETA: 0s - loss: 0.6047 - acc: 0.6890
2112/2417 [=========================>....] - ETA: 0s - loss: 0.6095 - acc: 0.6870
2240/2417 [==========================>...] - ETA: 0s - loss: 0.6041 - acc: 0.6906
2368/2417 [============================>.] - ETA: 0s - loss: 0.6024 - acc: 0.6921
2417/2417 [==============================] - 2s 861us/step - loss: 0.6016 - acc: 0.6934 - val_loss: 0.5000 - val_acc: 0.7732

Epoch 00001: val_acc improved from -inf to 0.77323, saving model to /data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/checkpoints_4layer_130-/omics_model/model_multi_omics2.hdf5
Epoch 2/10

  64/2417 [..............................] - ETA: 1s - loss: 0.5098 - acc: 0.7969
 192/2417 [=>............................] - ETA: 1s - loss: 0.4881 - acc: 0.7865
 320/2417 [==>...........................] - ETA: 1s - loss: 0.5336 - acc: 0.7500
 448/2417 [====>.........................] - ETA: 0s - loss: 0.5564 - acc: 0.7388
 576/2417 [======>.......................] - ETA: 0s - loss: 0.5784 - acc: 0.7465
 704/2417 [=======>......................] - ETA: 0s - loss: 0.5780 - acc: 0.7457
 832/2417 [=========>....................] - ETA: 0s - loss: 0.5846 - acc: 0.7320
 960/2417 [==========>...................] - ETA: 0s - loss: 0.5733 - acc: 0.7323
1088/2417 [============>.................] - ETA: 0s - loss: 0.5737 - acc: 0.7243
1216/2417 [==============>...............] - ETA: 0s - loss: 0.5701 - acc: 0.7286
1344/2417 [===============>..............] - ETA: 0s - loss: 0.5674 - acc: 0.7262
1472/2417 [=================>............] - ETA: 0s - loss: 0.5683 - acc: 0.7249
1600/2417 [==================>...........] - ETA: 0s - loss: 0.5673 - acc: 0.7256
1728/2417 [====================>.........] - ETA: 0s - loss: 0.5640 - acc: 0.7309
1856/2417 [======================>.......] - ETA: 0s - loss: 0.5607 - acc: 0.7322
1984/2417 [=======================>......] - ETA: 0s - loss: 0.5641 - acc: 0.7278
2112/2417 [=========================>....] - ETA: 0s - loss: 0.5619 - acc: 0.7311
2240/2417 [==========================>...] - ETA: 0s - loss: 0.5636 - acc: 0.7277
2368/2417 [============================>.] - ETA: 0s - loss: 0.5660 - acc: 0.7238
2417/2417 [==============================] - 1s 466us/step - loss: 0.5698 - acc: 0.7236 - val_loss: 0.5057 - val_acc: 0.7695

Epoch 00002: val_acc did not improve from 0.77323
Epoch 3/10

  64/2417 [..............................] - ETA: 1s - loss: 0.5389 - acc: 0.7188
 192/2417 [=>............................] - ETA: 0s - loss: 0.5844 - acc: 0.6875
 320/2417 [==>...........................] - ETA: 0s - loss: 0.5627 - acc: 0.7188
 448/2417 [====>.........................] - ETA: 0s - loss: 0.5644 - acc: 0.7076
 576/2417 [======>.......................] - ETA: 0s - loss: 0.5655 - acc: 0.7153
 704/2417 [=======>......................] - ETA: 0s - loss: 0.5651 - acc: 0.7145
 832/2417 [=========>....................] - ETA: 0s - loss: 0.5616 - acc: 0.7175
 960/2417 [==========>...................] - ETA: 0s - loss: 0.5596 - acc: 0.7177
1088/2417 [============>.................] - ETA: 0s - loss: 0.5607 - acc: 0.7178
1216/2417 [==============>...............] - ETA: 0s - loss: 0.5621 - acc: 0.7171
1344/2417 [===============>..............] - ETA: 0s - loss: 0.5649 - acc: 0.7128
1472/2417 [=================>............] - ETA: 0s - loss: 0.5635 - acc: 0.7133
1600/2417 [==================>...........] - ETA: 0s - loss: 0.5632 - acc: 0.7150
1728/2417 [====================>.........] - ETA: 0s - loss: 0.5624 - acc: 0.7159
1856/2417 [======================>.......] - ETA: 0s - loss: 0.5618 - acc: 0.7166
1984/2417 [=======================>......] - ETA: 0s - loss: 0.5674 - acc: 0.7193
2112/2417 [=========================>....] - ETA: 0s - loss: 0.5655 - acc: 0.7216
2240/2417 [==========================>...] - ETA: 0s - loss: 0.5622 - acc: 0.7232
2368/2417 [============================>.] - ETA: 0s - loss: 0.5610 - acc: 0.7255
2417/2417 [==============================] - 1s 450us/step - loss: 0.5602 - acc: 0.7257 - val_loss: 0.5039 - val_acc: 0.7658

Epoch 00003: val_acc did not improve from 0.77323
Epoch 4/10

  64/2417 [..............................] - ETA: 1s - loss: 0.6025 - acc: 0.6719
 192/2417 [=>............................] - ETA: 0s - loss: 0.6031 - acc: 0.6771
 320/2417 [==>...........................] - ETA: 0s - loss: 0.5997 - acc: 0.6844
 448/2417 [====>.........................] - ETA: 0s - loss: 0.5901 - acc: 0.6853
 576/2417 [======>.......................] - ETA: 0s - loss: 0.5813 - acc: 0.7014
 704/2417 [=======>......................] - ETA: 0s - loss: 0.5827 - acc: 0.7003
 832/2417 [=========>....................] - ETA: 0s - loss: 0.5732 - acc: 0.7103
 960/2417 [==========>...................] - ETA: 0s - loss: 0.5640 - acc: 0.7146
1088/2417 [============>.................] - ETA: 0s - loss: 0.5629 - acc: 0.7151
1216/2417 [==============>...............] - ETA: 0s - loss: 0.5668 - acc: 0.7130
1344/2417 [===============>..............] - ETA: 0s - loss: 0.5634 - acc: 0.7180
1472/2417 [=================>............] - ETA: 0s - loss: 0.5644 - acc: 0.7174
1600/2417 [==================>...........] - ETA: 0s - loss: 0.5637 - acc: 0.7200
1728/2417 [====================>.........] - ETA: 0s - loss: 0.5630 - acc: 0.7205
1920/2417 [======================>.......] - ETA: 0s - loss: 0.5656 - acc: 0.7151
2048/2417 [========================>.....] - ETA: 0s - loss: 0.5669 - acc: 0.7129
2176/2417 [==========================>...] - ETA: 0s - loss: 0.5713 - acc: 0.7188
2304/2417 [===========================>..] - ETA: 0s - loss: 0.5717 - acc: 0.7166
2417/2417 [==============================] - 1s 522us/step - loss: 0.5671 - acc: 0.7211 - val_loss: 0.5021 - val_acc: 0.7732

Epoch 00004: val_acc improved from 0.77323 to 0.77323, saving model to /data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/checkpoints_4layer_130-/omics_model/model_multi_omics2.hdf5
Epoch 5/10

  64/2417 [..............................] - ETA: 1s - loss: 0.4991 - acc: 0.7812
 192/2417 [=>............................] - ETA: 1s - loss: 0.4953 - acc: 0.7812
 320/2417 [==>...........................] - ETA: 1s - loss: 0.5068 - acc: 0.7625
 448/2417 [====>.........................] - ETA: 0s - loss: 0.5209 - acc: 0.7500
 576/2417 [======>.......................] - ETA: 0s - loss: 0.5306 - acc: 0.7378
 704/2417 [=======>......................] - ETA: 0s - loss: 0.5319 - acc: 0.7415
 832/2417 [=========>....................] - ETA: 0s - loss: 0.5466 - acc: 0.7344
 960/2417 [==========>...................] - ETA: 0s - loss: 0.5406 - acc: 0.7406
1088/2417 [============>.................] - ETA: 0s - loss: 0.5571 - acc: 0.7390
1216/2417 [==============>...............] - ETA: 0s - loss: 0.5588 - acc: 0.7319
1344/2417 [===============>..............] - ETA: 0s - loss: 0.5639 - acc: 0.7254
1472/2417 [=================>............] - ETA: 0s - loss: 0.5644 - acc: 0.7289
1600/2417 [==================>...........] - ETA: 0s - loss: 0.5635 - acc: 0.7275
1728/2417 [====================>.........] - ETA: 0s - loss: 0.5595 - acc: 0.7303
1856/2417 [======================>.......] - ETA: 0s - loss: 0.5615 - acc: 0.7241
1984/2417 [=======================>......] - ETA: 0s - loss: 0.5650 - acc: 0.7198
2112/2417 [=========================>....] - ETA: 0s - loss: 0.5608 - acc: 0.7235
2240/2417 [==========================>...] - ETA: 0s - loss: 0.5588 - acc: 0.7241
2368/2417 [============================>.] - ETA: 0s - loss: 0.5580 - acc: 0.7251
2417/2417 [==============================] - 1s 475us/step - loss: 0.5593 - acc: 0.7240 - val_loss: 0.4966 - val_acc: 0.7695

Epoch 00005: val_acc did not improve from 0.77323
Epoch 6/10

  64/2417 [..............................] - ETA: 1s - loss: 0.5961 - acc: 0.7031
 192/2417 [=>............................] - ETA: 0s - loss: 0.5568 - acc: 0.7292
 320/2417 [==>...........................] - ETA: 0s - loss: 0.5821 - acc: 0.7031
 448/2417 [====>.........................] - ETA: 0s - loss: 0.5627 - acc: 0.7232
 576/2417 [======>.......................] - ETA: 0s - loss: 0.5514 - acc: 0.7326
 704/2417 [=======>......................] - ETA: 0s - loss: 0.5483 - acc: 0.7358
 832/2417 [=========>....................] - ETA: 0s - loss: 0.5459 - acc: 0.7344
 960/2417 [==========>...................] - ETA: 0s - loss: 0.5658 - acc: 0.7333
1088/2417 [============>.................] - ETA: 0s - loss: 0.5696 - acc: 0.7316
1216/2417 [==============>...............] - ETA: 0s - loss: 0.5659 - acc: 0.7327
1344/2417 [===============>..............] - ETA: 0s - loss: 0.5763 - acc: 0.7225
1472/2417 [=================>............] - ETA: 0s - loss: 0.5724 - acc: 0.7242
1600/2417 [==================>...........] - ETA: 0s - loss: 0.5721 - acc: 0.7256
1728/2417 [====================>.........] - ETA: 0s - loss: 0.5679 - acc: 0.7269
1920/2417 [======================>.......] - ETA: 0s - loss: 0.5669 - acc: 0.7229
2048/2417 [========================>.....] - ETA: 0s - loss: 0.5661 - acc: 0.7236
2176/2417 [==========================>...] - ETA: 0s - loss: 0.5651 - acc: 0.7252
2304/2417 [===========================>..] - ETA: 0s - loss: 0.5632 - acc: 0.7266
2417/2417 [==============================] - 1s 455us/step - loss: 0.5618 - acc: 0.7269 - val_loss: 0.4957 - val_acc: 0.7695

Epoch 00006: val_acc did not improve from 0.77323
Epoch 7/10

  64/2417 [..............................] - ETA: 1s - loss: 0.4726 - acc: 0.8125
 192/2417 [=>............................] - ETA: 1s - loss: 0.5238 - acc: 0.7396
 320/2417 [==>...........................] - ETA: 0s - loss: 0.5888 - acc: 0.7219
 448/2417 [====>.........................] - ETA: 0s - loss: 0.5767 - acc: 0.7188
 576/2417 [======>.......................] - ETA: 0s - loss: 0.5621 - acc: 0.7292
 704/2417 [=======>......................] - ETA: 0s - loss: 0.5530 - acc: 0.7301
 832/2417 [=========>....................] - ETA: 0s - loss: 0.5570 - acc: 0.7284
 960/2417 [==========>...................] - ETA: 0s - loss: 0.5711 - acc: 0.7188
1088/2417 [============>.................] - ETA: 0s - loss: 0.5682 - acc: 0.7206
1216/2417 [==============>...............] - ETA: 0s - loss: 0.5589 - acc: 0.7303
1344/2417 [===============>..............] - ETA: 0s - loss: 0.5570 - acc: 0.7307
1472/2417 [=================>............] - ETA: 0s - loss: 0.5541 - acc: 0.7276
1600/2417 [==================>...........] - ETA: 0s - loss: 0.5530 - acc: 0.7294
1728/2417 [====================>.........] - ETA: 0s - loss: 0.5539 - acc: 0.7269
1920/2417 [======================>.......] - ETA: 0s - loss: 0.5505 - acc: 0.7302
2048/2417 [========================>.....] - ETA: 0s - loss: 0.5512 - acc: 0.7305
2176/2417 [==========================>...] - ETA: 0s - loss: 0.5516 - acc: 0.7307
2304/2417 [===========================>..] - ETA: 0s - loss: 0.5524 - acc: 0.7296
2417/2417 [==============================] - 1s 461us/step - loss: 0.5538 - acc: 0.7278 - val_loss: 0.5035 - val_acc: 0.7695

Epoch 00007: val_acc did not improve from 0.77323
Epoch 8/10

  64/2417 [..............................] - ETA: 1s - loss: 0.5728 - acc: 0.6719
 192/2417 [=>............................] - ETA: 1s - loss: 0.6212 - acc: 0.5521
 320/2417 [==>...........................] - ETA: 0s - loss: 0.6043 - acc: 0.6188
 448/2417 [====>.........................] - ETA: 0s - loss: 0.5873 - acc: 0.6518
 576/2417 [======>.......................] - ETA: 0s - loss: 0.5581 - acc: 0.6840
 704/2417 [=======>......................] - ETA: 0s - loss: 0.5513 - acc: 0.6974
 832/2417 [=========>....................] - ETA: 0s - loss: 0.5648 - acc: 0.6875
 960/2417 [==========>...................] - ETA: 0s - loss: 0.5767 - acc: 0.6896
1088/2417 [============>.................] - ETA: 0s - loss: 0.5767 - acc: 0.6930
1216/2417 [==============>...............] - ETA: 0s - loss: 0.5716 - acc: 0.7015
1344/2417 [===============>..............] - ETA: 0s - loss: 0.5664 - acc: 0.7031
1472/2417 [=================>............] - ETA: 0s - loss: 0.5648 - acc: 0.7024
1600/2417 [==================>...........] - ETA: 0s - loss: 0.5626 - acc: 0.7056
1728/2417 [====================>.........] - ETA: 0s - loss: 0.5606 - acc: 0.7072
1856/2417 [======================>.......] - ETA: 0s - loss: 0.5653 - acc: 0.7080
1984/2417 [=======================>......] - ETA: 0s - loss: 0.5647 - acc: 0.7087
2112/2417 [=========================>....] - ETA: 0s - loss: 0.5611 - acc: 0.7112
2240/2417 [==========================>...] - ETA: 0s - loss: 0.5604 - acc: 0.7138
2368/2417 [============================>.] - ETA: 0s - loss: 0.5624 - acc: 0.7141
2417/2417 [==============================] - 1s 450us/step - loss: 0.5629 - acc: 0.7141 - val_loss: 0.4966 - val_acc: 0.7695

Epoch 00008: val_acc did not improve from 0.77323
Epoch 9/10

  64/2417 [..............................] - ETA: 1s - loss: 0.5103 - acc: 0.7656
 192/2417 [=>............................] - ETA: 0s - loss: 0.5076 - acc: 0.7760
 320/2417 [==>...........................] - ETA: 0s - loss: 0.4930 - acc: 0.7781
 448/2417 [====>.........................] - ETA: 0s - loss: 0.5302 - acc: 0.7321
 576/2417 [======>.......................] - ETA: 0s - loss: 0.5347 - acc: 0.7309
 704/2417 [=======>......................] - ETA: 0s - loss: 0.5414 - acc: 0.7202
 832/2417 [=========>....................] - ETA: 0s - loss: 0.5343 - acc: 0.7308
 960/2417 [==========>...................] - ETA: 0s - loss: 0.5323 - acc: 0.7354
1088/2417 [============>.................] - ETA: 0s - loss: 0.5346 - acc: 0.7371
1216/2417 [==============>...............] - ETA: 0s - loss: 0.5313 - acc: 0.7377
1344/2417 [===============>..............] - ETA: 0s - loss: 0.5321 - acc: 0.7366
1472/2417 [=================>............] - ETA: 0s - loss: 0.5407 - acc: 0.7344
1600/2417 [==================>...........] - ETA: 0s - loss: 0.5508 - acc: 0.7325
1792/2417 [=====================>........] - ETA: 0s - loss: 0.5498 - acc: 0.7299
1920/2417 [======================>.......] - ETA: 0s - loss: 0.5543 - acc: 0.7271
2048/2417 [========================>.....] - ETA: 0s - loss: 0.5606 - acc: 0.7222
2176/2417 [==========================>...] - ETA: 0s - loss: 0.5585 - acc: 0.7247
2304/2417 [===========================>..] - ETA: 0s - loss: 0.5580 - acc: 0.7235
2417/2417 [==============================] - 1s 466us/step - loss: 0.5547 - acc: 0.7269 - val_loss: 0.5085 - val_acc: 0.7695

Epoch 00009: val_acc did not improve from 0.77323
Epoch 10/10

  64/2417 [..............................] - ETA: 1s - loss: 0.4949 - acc: 0.7344
 192/2417 [=>............................] - ETA: 1s - loss: 0.5903 - acc: 0.7604
 320/2417 [==>...........................] - ETA: 0s - loss: 0.5738 - acc: 0.7438
 448/2417 [====>.........................] - ETA: 0s - loss: 0.5618 - acc: 0.7388
 576/2417 [======>.......................] - ETA: 0s - loss: 0.5750 - acc: 0.7240
 704/2417 [=======>......................] - ETA: 0s - loss: 0.5773 - acc: 0.7188
 832/2417 [=========>....................] - ETA: 0s - loss: 0.5745 - acc: 0.7175
 960/2417 [==========>...................] - ETA: 0s - loss: 0.5643 - acc: 0.7250
1088/2417 [============>.................] - ETA: 0s - loss: 0.5651 - acc: 0.7279
1216/2417 [==============>...............] - ETA: 0s - loss: 0.5630 - acc: 0.7253
1344/2417 [===============>..............] - ETA: 0s - loss: 0.5679 - acc: 0.7195
1536/2417 [==================>...........] - ETA: 0s - loss: 0.5638 - acc: 0.7207
1664/2417 [===================>..........] - ETA: 0s - loss: 0.5595 - acc: 0.7236
1792/2417 [=====================>........] - ETA: 0s - loss: 0.5608 - acc: 0.7254
1920/2417 [======================>.......] - ETA: 0s - loss: 0.5552 - acc: 0.7292
2048/2417 [========================>.....] - ETA: 0s - loss: 0.5551 - acc: 0.7280
2176/2417 [==========================>...] - ETA: 0s - loss: 0.5560 - acc: 0.7270
2304/2417 [===========================>..] - ETA: 0s - loss: 0.5564 - acc: 0.7244
2417/2417 [==============================] - 1s 447us/step - loss: 0.5576 - acc: 0.7236 - val_loss: 0.4922 - val_acc: 0.7695

Epoch 00010: val_acc did not improve from 0.77323
Saved model to disk
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:40: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 8, activation="relu", padding="same")`
  omics_conv1_ = Conv1D(128, 8, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:42: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 1, activation="relu", padding="same")`
  omics_conv2_ = Conv1D(64, 1, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:44: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation="relu", padding="same")`
  omics_conv3_ = Conv1D(64, 3, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:46: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 1, activation="relu", padding="same")`
  omics_conv4_ = Conv1D(128, 1, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:63: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_omics], output=[pred_output])
ACC: 0.6846038863976084
Sens: 0.49404761904761907
Spec: 0.8768768768768769
MCC: 0.40120940968568547
ROC_AUC: 0.7086416773916775
PRC_ROC: 0.783037391007663
WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:40: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 8, activation="relu", padding="same")`
  omics_conv1_ = Conv1D(128, 8, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:42: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 1, activation="relu", padding="same")`
  omics_conv2_ = Conv1D(64, 1, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:44: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation="relu", padding="same")`
  omics_conv3_ = Conv1D(64, 3, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:46: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 1, activation="relu", padding="same")`
  omics_conv4_ = Conv1D(128, 1, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:63: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_omics], output=[pred_output])
Fitting first model...
Train on 2417 samples, validate on 269 samples
Epoch 1/10

  64/2417 [..............................] - ETA: 25s - loss: 1.2637 - acc: 0.5156
 192/2417 [=>............................] - ETA: 9s - loss: 0.8550 - acc: 0.4948 
 320/2417 [==>...........................] - ETA: 5s - loss: 0.7528 - acc: 0.5031
 448/2417 [====>.........................] - ETA: 4s - loss: 0.7421 - acc: 0.4888
 576/2417 [======>.......................] - ETA: 3s - loss: 0.7215 - acc: 0.5330
 704/2417 [=======>......................] - ETA: 2s - loss: 0.6894 - acc: 0.5682
 832/2417 [=========>....................] - ETA: 2s - loss: 0.6674 - acc: 0.5938
 960/2417 [==========>...................] - ETA: 1s - loss: 0.6549 - acc: 0.6146
1088/2417 [============>.................] - ETA: 1s - loss: 0.6451 - acc: 0.6268
1216/2417 [==============>...............] - ETA: 1s - loss: 0.6391 - acc: 0.6382
1344/2417 [===============>..............] - ETA: 1s - loss: 0.6496 - acc: 0.6406
1472/2417 [=================>............] - ETA: 0s - loss: 0.6460 - acc: 0.6481
1600/2417 [==================>...........] - ETA: 0s - loss: 0.6493 - acc: 0.6444
1728/2417 [====================>.........] - ETA: 0s - loss: 0.6458 - acc: 0.6481
1856/2417 [======================>.......] - ETA: 0s - loss: 0.6420 - acc: 0.6552
1984/2417 [=======================>......] - ETA: 0s - loss: 0.6424 - acc: 0.6598
2112/2417 [=========================>....] - ETA: 0s - loss: 0.6363 - acc: 0.6657
2240/2417 [==========================>...] - ETA: 0s - loss: 0.6339 - acc: 0.6728
2368/2417 [============================>.] - ETA: 0s - loss: 0.6293 - acc: 0.6765
2417/2417 [==============================] - 2s 831us/step - loss: 0.6348 - acc: 0.6769 - val_loss: 0.5236 - val_acc: 0.7658

Epoch 00001: val_acc improved from -inf to 0.76580, saving model to /data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/checkpoints_4layer_130-/omics_model/model_multi_omics3.hdf5
Epoch 2/10

  64/2417 [..............................] - ETA: 1s - loss: 0.6442 - acc: 0.6094
 192/2417 [=>............................] - ETA: 1s - loss: 0.6180 - acc: 0.6354
 320/2417 [==>...........................] - ETA: 1s - loss: 0.5876 - acc: 0.6844
 448/2417 [====>.........................] - ETA: 1s - loss: 0.5935 - acc: 0.6875
 576/2417 [======>.......................] - ETA: 1s - loss: 0.5697 - acc: 0.7066
 704/2417 [=======>......................] - ETA: 0s - loss: 0.5655 - acc: 0.7088
 832/2417 [=========>....................] - ETA: 0s - loss: 0.5632 - acc: 0.7103
 960/2417 [==========>...................] - ETA: 0s - loss: 0.5635 - acc: 0.7083
1088/2417 [============>.................] - ETA: 0s - loss: 0.5646 - acc: 0.7114
1216/2417 [==============>...............] - ETA: 0s - loss: 0.5670 - acc: 0.7138
1344/2417 [===============>..............] - ETA: 0s - loss: 0.5699 - acc: 0.7083
1472/2417 [=================>............] - ETA: 0s - loss: 0.5724 - acc: 0.7052
1600/2417 [==================>...........] - ETA: 0s - loss: 0.5874 - acc: 0.7000
1728/2417 [====================>.........] - ETA: 0s - loss: 0.5861 - acc: 0.6997
1856/2417 [======================>.......] - ETA: 0s - loss: 0.5831 - acc: 0.7042
1984/2417 [=======================>......] - ETA: 0s - loss: 0.5874 - acc: 0.7036
2112/2417 [=========================>....] - ETA: 0s - loss: 0.5873 - acc: 0.7045
2240/2417 [==========================>...] - ETA: 0s - loss: 0.5847 - acc: 0.7054
2368/2417 [============================>.] - ETA: 0s - loss: 0.5841 - acc: 0.7057
2417/2417 [==============================] - 1s 525us/step - loss: 0.5822 - acc: 0.7067 - val_loss: 0.5032 - val_acc: 0.7695

Epoch 00002: val_acc improved from 0.76580 to 0.76952, saving model to /data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/checkpoints_4layer_130-/omics_model/model_multi_omics3.hdf5
Epoch 3/10

  64/2417 [..............................] - ETA: 1s - loss: 0.5782 - acc: 0.7344
 192/2417 [=>............................] - ETA: 1s - loss: 0.6068 - acc: 0.6667
 320/2417 [==>...........................] - ETA: 1s - loss: 0.6076 - acc: 0.6844
 448/2417 [====>.........................] - ETA: 0s - loss: 0.5939 - acc: 0.6897
 576/2417 [======>.......................] - ETA: 0s - loss: 0.6051 - acc: 0.6840
 704/2417 [=======>......................] - ETA: 0s - loss: 0.5971 - acc: 0.6932
 832/2417 [=========>....................] - ETA: 0s - loss: 0.5880 - acc: 0.6923
 960/2417 [==========>...................] - ETA: 0s - loss: 0.5913 - acc: 0.6896
1088/2417 [============>.................] - ETA: 0s - loss: 0.6022 - acc: 0.6958
1216/2417 [==============>...............] - ETA: 0s - loss: 0.5973 - acc: 0.6998
1344/2417 [===============>..............] - ETA: 0s - loss: 0.5957 - acc: 0.7001
1472/2417 [=================>............] - ETA: 0s - loss: 0.5940 - acc: 0.7011
1600/2417 [==================>...........] - ETA: 0s - loss: 0.5898 - acc: 0.7050
1728/2417 [====================>.........] - ETA: 0s - loss: 0.5949 - acc: 0.6997
1856/2417 [======================>.......] - ETA: 0s - loss: 0.5906 - acc: 0.7031
1984/2417 [=======================>......] - ETA: 0s - loss: 0.5878 - acc: 0.7051
2112/2417 [=========================>....] - ETA: 0s - loss: 0.5857 - acc: 0.7069
2240/2417 [==========================>...] - ETA: 0s - loss: 0.5803 - acc: 0.7112
2368/2417 [============================>.] - ETA: 0s - loss: 0.5807 - acc: 0.7095
2417/2417 [==============================] - 1s 480us/step - loss: 0.5798 - acc: 0.7104 - val_loss: 0.4986 - val_acc: 0.7658

Epoch 00003: val_acc did not improve from 0.76952
Epoch 4/10

  64/2417 [..............................] - ETA: 1s - loss: 0.5225 - acc: 0.7812
 192/2417 [=>............................] - ETA: 0s - loss: 0.5834 - acc: 0.7188
 320/2417 [==>...........................] - ETA: 0s - loss: 0.5506 - acc: 0.7344
 448/2417 [====>.........................] - ETA: 0s - loss: 0.5544 - acc: 0.7188
 576/2417 [======>.......................] - ETA: 0s - loss: 0.5708 - acc: 0.7066
 704/2417 [=======>......................] - ETA: 0s - loss: 0.5617 - acc: 0.7244
 832/2417 [=========>....................] - ETA: 0s - loss: 0.5630 - acc: 0.7248
 960/2417 [==========>...................] - ETA: 0s - loss: 0.5689 - acc: 0.7167
1088/2417 [============>.................] - ETA: 0s - loss: 0.5701 - acc: 0.7178
1216/2417 [==============>...............] - ETA: 0s - loss: 0.5610 - acc: 0.7303
1344/2417 [===============>..............] - ETA: 0s - loss: 0.5664 - acc: 0.7240
1472/2417 [=================>............] - ETA: 0s - loss: 0.5689 - acc: 0.7208
1600/2417 [==================>...........] - ETA: 0s - loss: 0.5747 - acc: 0.7156
1728/2417 [====================>.........] - ETA: 0s - loss: 0.5736 - acc: 0.7182
1856/2417 [======================>.......] - ETA: 0s - loss: 0.5846 - acc: 0.7128
1984/2417 [=======================>......] - ETA: 0s - loss: 0.5819 - acc: 0.7142
2112/2417 [=========================>....] - ETA: 0s - loss: 0.5809 - acc: 0.7169
2240/2417 [==========================>...] - ETA: 0s - loss: 0.5786 - acc: 0.7152
2368/2417 [============================>.] - ETA: 0s - loss: 0.5755 - acc: 0.7171
2417/2417 [==============================] - 1s 492us/step - loss: 0.5761 - acc: 0.7158 - val_loss: 0.5218 - val_acc: 0.7695

Epoch 00004: val_acc did not improve from 0.76952
Epoch 5/10

  64/2417 [..............................] - ETA: 1s - loss: 0.4226 - acc: 0.8438
 192/2417 [=>............................] - ETA: 1s - loss: 0.5279 - acc: 0.7500
 320/2417 [==>...........................] - ETA: 1s - loss: 0.5199 - acc: 0.7344
 448/2417 [====>.........................] - ETA: 1s - loss: 0.5304 - acc: 0.7366
 576/2417 [======>.......................] - ETA: 0s - loss: 0.5414 - acc: 0.7361
 704/2417 [=======>......................] - ETA: 0s - loss: 0.5386 - acc: 0.7401
 832/2417 [=========>....................] - ETA: 0s - loss: 0.5508 - acc: 0.7356
 960/2417 [==========>...................] - ETA: 0s - loss: 0.5576 - acc: 0.7302
1088/2417 [============>.................] - ETA: 0s - loss: 0.5657 - acc: 0.7215
1216/2417 [==============>...............] - ETA: 0s - loss: 0.5700 - acc: 0.7188
1344/2417 [===============>..............] - ETA: 0s - loss: 0.5849 - acc: 0.7128
1472/2417 [=================>............] - ETA: 0s - loss: 0.5850 - acc: 0.7079
1600/2417 [==================>...........] - ETA: 0s - loss: 0.5840 - acc: 0.7113
1728/2417 [====================>.........] - ETA: 0s - loss: 0.5817 - acc: 0.7124
1856/2417 [======================>.......] - ETA: 0s - loss: 0.5904 - acc: 0.7031
1984/2417 [=======================>......] - ETA: 0s - loss: 0.5867 - acc: 0.7061
2112/2417 [=========================>....] - ETA: 0s - loss: 0.5914 - acc: 0.7098
2240/2417 [==========================>...] - ETA: 0s - loss: 0.5934 - acc: 0.7094
2368/2417 [============================>.] - ETA: 0s - loss: 0.5909 - acc: 0.7103
2417/2417 [==============================] - 1s 483us/step - loss: 0.5918 - acc: 0.7096 - val_loss: 0.5050 - val_acc: 0.7695

Epoch 00005: val_acc did not improve from 0.76952
Epoch 6/10

  64/2417 [..............................] - ETA: 1s - loss: 0.5947 - acc: 0.7344
 192/2417 [=>............................] - ETA: 1s - loss: 0.5467 - acc: 0.7760
 320/2417 [==>...........................] - ETA: 0s - loss: 0.5642 - acc: 0.7531
 448/2417 [====>.........................] - ETA: 0s - loss: 0.5656 - acc: 0.7366
 576/2417 [======>.......................] - ETA: 0s - loss: 0.5545 - acc: 0.7465
 704/2417 [=======>......................] - ETA: 0s - loss: 0.5648 - acc: 0.7315
 832/2417 [=========>....................] - ETA: 0s - loss: 0.5687 - acc: 0.7308
 960/2417 [==========>...................] - ETA: 0s - loss: 0.5642 - acc: 0.7333
1088/2417 [============>.................] - ETA: 0s - loss: 0.5552 - acc: 0.7371
1216/2417 [==============>...............] - ETA: 0s - loss: 0.5617 - acc: 0.7278
1344/2417 [===============>..............] - ETA: 0s - loss: 0.5575 - acc: 0.7284
1472/2417 [=================>............] - ETA: 0s - loss: 0.5565 - acc: 0.7289
1600/2417 [==================>...........] - ETA: 0s - loss: 0.5607 - acc: 0.7262
1728/2417 [====================>.........] - ETA: 0s - loss: 0.5682 - acc: 0.7188
1856/2417 [======================>.......] - ETA: 0s - loss: 0.5720 - acc: 0.7198
1984/2417 [=======================>......] - ETA: 0s - loss: 0.5717 - acc: 0.7167
2112/2417 [=========================>....] - ETA: 0s - loss: 0.5733 - acc: 0.7145
2240/2417 [==========================>...] - ETA: 0s - loss: 0.5766 - acc: 0.7103
2368/2417 [============================>.] - ETA: 0s - loss: 0.5753 - acc: 0.7124
2417/2417 [==============================] - 1s 480us/step - loss: 0.5744 - acc: 0.7133 - val_loss: 0.5052 - val_acc: 0.7658

Epoch 00006: val_acc did not improve from 0.76952
Epoch 7/10

  64/2417 [..............................] - ETA: 1s - loss: 0.6445 - acc: 0.7188
 192/2417 [=>............................] - ETA: 1s - loss: 0.5947 - acc: 0.6927
 320/2417 [==>...........................] - ETA: 1s - loss: 0.5953 - acc: 0.6813
 448/2417 [====>.........................] - ETA: 0s - loss: 0.5927 - acc: 0.6808
 576/2417 [======>.......................] - ETA: 0s - loss: 0.5798 - acc: 0.6944
 704/2417 [=======>......................] - ETA: 0s - loss: 0.5756 - acc: 0.7031
 832/2417 [=========>....................] - ETA: 0s - loss: 0.5764 - acc: 0.7007
 960/2417 [==========>...................] - ETA: 0s - loss: 0.5719 - acc: 0.7031
1088/2417 [============>.................] - ETA: 0s - loss: 0.5699 - acc: 0.7105
1216/2417 [==============>...............] - ETA: 0s - loss: 0.5678 - acc: 0.7105
1344/2417 [===============>..............] - ETA: 0s - loss: 0.5688 - acc: 0.7076
1472/2417 [=================>............] - ETA: 0s - loss: 0.5648 - acc: 0.7126
1600/2417 [==================>...........] - ETA: 0s - loss: 0.5607 - acc: 0.7150
1728/2417 [====================>.........] - ETA: 0s - loss: 0.5679 - acc: 0.7182
1856/2417 [======================>.......] - ETA: 0s - loss: 0.5652 - acc: 0.7220
1984/2417 [=======================>......] - ETA: 0s - loss: 0.5678 - acc: 0.7177
2112/2417 [=========================>....] - ETA: 0s - loss: 0.5704 - acc: 0.7169
2240/2417 [==========================>...] - ETA: 0s - loss: 0.5714 - acc: 0.7174
2368/2417 [============================>.] - ETA: 0s - loss: 0.5724 - acc: 0.7179
2417/2417 [==============================] - 1s 477us/step - loss: 0.5736 - acc: 0.7162 - val_loss: 0.5013 - val_acc: 0.7658

Epoch 00007: val_acc did not improve from 0.76952
Epoch 8/10

  64/2417 [..............................] - ETA: 1s - loss: 0.6019 - acc: 0.6875
 192/2417 [=>............................] - ETA: 1s - loss: 0.5492 - acc: 0.7292
 320/2417 [==>...........................] - ETA: 0s - loss: 0.5483 - acc: 0.7406
 448/2417 [====>.........................] - ETA: 0s - loss: 0.5639 - acc: 0.7143
 576/2417 [======>.......................] - ETA: 0s - loss: 0.6005 - acc: 0.7031
 704/2417 [=======>......................] - ETA: 0s - loss: 0.5888 - acc: 0.7088
 832/2417 [=========>....................] - ETA: 0s - loss: 0.5775 - acc: 0.7248
 960/2417 [==========>...................] - ETA: 0s - loss: 0.5780 - acc: 0.7167
1088/2417 [============>.................] - ETA: 0s - loss: 0.5784 - acc: 0.7160
1216/2417 [==============>...............] - ETA: 0s - loss: 0.5794 - acc: 0.7163
1344/2417 [===============>..............] - ETA: 0s - loss: 0.5817 - acc: 0.7150
1472/2417 [=================>............] - ETA: 0s - loss: 0.5802 - acc: 0.7147
1600/2417 [==================>...........] - ETA: 0s - loss: 0.5767 - acc: 0.7156
1728/2417 [====================>.........] - ETA: 0s - loss: 0.5775 - acc: 0.7130
1856/2417 [======================>.......] - ETA: 0s - loss: 0.5747 - acc: 0.7171
1984/2417 [=======================>......] - ETA: 0s - loss: 0.5759 - acc: 0.7137
2112/2417 [=========================>....] - ETA: 0s - loss: 0.5733 - acc: 0.7150
2240/2417 [==========================>...] - ETA: 0s - loss: 0.5759 - acc: 0.7121
2368/2417 [============================>.] - ETA: 0s - loss: 0.5727 - acc: 0.7145
2417/2417 [==============================] - 1s 468us/step - loss: 0.5723 - acc: 0.7170 - val_loss: 0.4989 - val_acc: 0.7658

Epoch 00008: val_acc did not improve from 0.76952
Epoch 9/10

  64/2417 [..............................] - ETA: 1s - loss: 0.5812 - acc: 0.7031
 192/2417 [=>............................] - ETA: 1s - loss: 0.5532 - acc: 0.7292
 320/2417 [==>...........................] - ETA: 1s - loss: 0.5649 - acc: 0.7281
 448/2417 [====>.........................] - ETA: 0s - loss: 0.5576 - acc: 0.7321
 576/2417 [======>.......................] - ETA: 0s - loss: 0.5567 - acc: 0.7257
 704/2417 [=======>......................] - ETA: 0s - loss: 0.5679 - acc: 0.7116
 832/2417 [=========>....................] - ETA: 0s - loss: 0.5646 - acc: 0.7139
 960/2417 [==========>...................] - ETA: 0s - loss: 0.5661 - acc: 0.7094
1088/2417 [============>.................] - ETA: 0s - loss: 0.5641 - acc: 0.7123
1216/2417 [==============>...............] - ETA: 0s - loss: 0.5738 - acc: 0.7039
1344/2417 [===============>..............] - ETA: 0s - loss: 0.5737 - acc: 0.7046
1472/2417 [=================>............] - ETA: 0s - loss: 0.5685 - acc: 0.7120
1600/2417 [==================>...........] - ETA: 0s - loss: 0.5711 - acc: 0.7113
1728/2417 [====================>.........] - ETA: 0s - loss: 0.5737 - acc: 0.7060
1856/2417 [======================>.......] - ETA: 0s - loss: 0.5727 - acc: 0.7047
1984/2417 [=======================>......] - ETA: 0s - loss: 0.5710 - acc: 0.7077
2112/2417 [=========================>....] - ETA: 0s - loss: 0.5754 - acc: 0.7102
2240/2417 [==========================>...] - ETA: 0s - loss: 0.5742 - acc: 0.7116
2368/2417 [============================>.] - ETA: 0s - loss: 0.5727 - acc: 0.7137
2417/2417 [==============================] - 1s 490us/step - loss: 0.5706 - acc: 0.7158 - val_loss: 0.4999 - val_acc: 0.7621

Epoch 00009: val_acc did not improve from 0.76952
Epoch 10/10

  64/2417 [..............................] - ETA: 1s - loss: 0.5421 - acc: 0.7188
 192/2417 [=>............................] - ETA: 1s - loss: 0.5636 - acc: 0.7083
 320/2417 [==>...........................] - ETA: 0s - loss: 0.5286 - acc: 0.7469
 448/2417 [====>.........................] - ETA: 0s - loss: 0.5382 - acc: 0.7321
 576/2417 [======>.......................] - ETA: 0s - loss: 0.5460 - acc: 0.7309
 704/2417 [=======>......................] - ETA: 0s - loss: 0.5718 - acc: 0.7159
 832/2417 [=========>....................] - ETA: 0s - loss: 0.5711 - acc: 0.7139
 960/2417 [==========>...................] - ETA: 0s - loss: 0.5819 - acc: 0.7188
1088/2417 [============>.................] - ETA: 0s - loss: 0.5791 - acc: 0.7178
1216/2417 [==============>...............] - ETA: 0s - loss: 0.5787 - acc: 0.7146
1344/2417 [===============>..............] - ETA: 0s - loss: 0.5767 - acc: 0.7143
1472/2417 [=================>............] - ETA: 0s - loss: 0.5767 - acc: 0.7133
1600/2417 [==================>...........] - ETA: 0s - loss: 0.5759 - acc: 0.7119
1728/2417 [====================>.........] - ETA: 0s - loss: 0.5763 - acc: 0.7124
1856/2417 [======================>.......] - ETA: 0s - loss: 0.5763 - acc: 0.7091
1984/2417 [=======================>......] - ETA: 0s - loss: 0.5779 - acc: 0.7122
2112/2417 [=========================>....] - ETA: 0s - loss: 0.5770 - acc: 0.7145
2240/2417 [==========================>...] - ETA: 0s - loss: 0.5743 - acc: 0.7165
2368/2417 [============================>.] - ETA: 0s - loss: 0.5757 - acc: 0.7149
2417/2417 [==============================] - 1s 451us/step - loss: 0.5732 - acc: 0.7166 - val_loss: 0.4941 - val_acc: 0.7695

Epoch 00010: val_acc did not improve from 0.76952
Saved model to disk
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:40: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 8, activation="relu", padding="same")`
  omics_conv1_ = Conv1D(128, 8, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:42: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 1, activation="relu", padding="same")`
  omics_conv2_ = Conv1D(64, 1, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:44: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation="relu", padding="same")`
  omics_conv3_ = Conv1D(64, 3, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:46: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 1, activation="relu", padding="same")`
  omics_conv4_ = Conv1D(128, 1, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:63: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_omics], output=[pred_output])
ACC: 0.7309417040358744
Sens: 0.5386904761904762
Spec: 0.924924924924925
MCC: 0.5021407933177872
ROC_AUC: 0.7757266194766195
PRC_ROC: 0.8473457304964926
WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:40: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 8, activation="relu", padding="same")`
  omics_conv1_ = Conv1D(128, 8, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:42: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 1, activation="relu", padding="same")`
  omics_conv2_ = Conv1D(64, 1, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:44: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation="relu", padding="same")`
  omics_conv3_ = Conv1D(64, 3, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:46: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 1, activation="relu", padding="same")`
  omics_conv4_ = Conv1D(128, 1, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:63: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_omics], output=[pred_output])
Fitting first model...
Train on 2418 samples, validate on 269 samples
Epoch 1/10

  64/2418 [..............................] - ETA: 26s - loss: 0.6880 - acc: 0.5469
 192/2418 [=>............................] - ETA: 9s - loss: 0.6280 - acc: 0.5365 
 320/2418 [==>...........................] - ETA: 5s - loss: 0.6231 - acc: 0.5375
 448/2418 [====>.........................] - ETA: 4s - loss: 0.6271 - acc: 0.5491
 576/2418 [======>.......................] - ETA: 3s - loss: 0.6382 - acc: 0.5833
 704/2418 [=======>......................] - ETA: 2s - loss: 0.6309 - acc: 0.6065
 832/2418 [=========>....................] - ETA: 2s - loss: 0.6289 - acc: 0.6226
 960/2418 [==========>...................] - ETA: 1s - loss: 0.6219 - acc: 0.6323
1088/2418 [============>.................] - ETA: 1s - loss: 0.6223 - acc: 0.6434
1216/2418 [==============>...............] - ETA: 1s - loss: 0.6230 - acc: 0.6505
1344/2418 [===============>..............] - ETA: 1s - loss: 0.6204 - acc: 0.6585
1472/2418 [=================>............] - ETA: 0s - loss: 0.6165 - acc: 0.6630
1600/2418 [==================>...........] - ETA: 0s - loss: 0.6163 - acc: 0.6613
1728/2418 [====================>.........] - ETA: 0s - loss: 0.6137 - acc: 0.6644
1856/2418 [======================>.......] - ETA: 0s - loss: 0.6112 - acc: 0.6676
1984/2418 [=======================>......] - ETA: 0s - loss: 0.6132 - acc: 0.6749
2112/2418 [=========================>....] - ETA: 0s - loss: 0.6139 - acc: 0.6723
2240/2418 [==========================>...] - ETA: 0s - loss: 0.6074 - acc: 0.6777
2368/2418 [============================>.] - ETA: 0s - loss: 0.6057 - acc: 0.6799
2418/2418 [==============================] - 2s 803us/step - loss: 0.6037 - acc: 0.6807 - val_loss: 0.5088 - val_acc: 0.7695

Epoch 00001: val_acc improved from -inf to 0.76952, saving model to /data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/checkpoints_4layer_130-/omics_model/model_multi_omics4.hdf5
Epoch 2/10

  64/2418 [..............................] - ETA: 1s - loss: 0.6613 - acc: 0.6250
 192/2418 [=>............................] - ETA: 1s - loss: 0.6019 - acc: 0.6771
 320/2418 [==>...........................] - ETA: 0s - loss: 0.5976 - acc: 0.6875
 448/2418 [====>.........................] - ETA: 0s - loss: 0.5900 - acc: 0.6875
 576/2418 [======>.......................] - ETA: 0s - loss: 0.5800 - acc: 0.6997
 704/2418 [=======>......................] - ETA: 0s - loss: 0.5879 - acc: 0.6889
 832/2418 [=========>....................] - ETA: 0s - loss: 0.5832 - acc: 0.6959
1024/2418 [===========>..................] - ETA: 0s - loss: 0.5903 - acc: 0.7051
1152/2418 [=============>................] - ETA: 0s - loss: 0.5777 - acc: 0.7118
1280/2418 [==============>...............] - ETA: 0s - loss: 0.5820 - acc: 0.7039
1408/2418 [================>.............] - ETA: 0s - loss: 0.5820 - acc: 0.7045
1536/2418 [==================>...........] - ETA: 0s - loss: 0.5856 - acc: 0.7051
1664/2418 [===================>..........] - ETA: 0s - loss: 0.5858 - acc: 0.7031
1792/2418 [=====================>........] - ETA: 0s - loss: 0.5828 - acc: 0.7070
1920/2418 [======================>.......] - ETA: 0s - loss: 0.5834 - acc: 0.7089
2048/2418 [========================>.....] - ETA: 0s - loss: 0.5837 - acc: 0.7056
2176/2418 [=========================>....] - ETA: 0s - loss: 0.5815 - acc: 0.7054
2304/2418 [===========================>..] - ETA: 0s - loss: 0.5774 - acc: 0.7101
2418/2418 [==============================] - 1s 455us/step - loss: 0.5789 - acc: 0.7076 - val_loss: 0.5041 - val_acc: 0.7658

Epoch 00002: val_acc did not improve from 0.76952
Epoch 3/10

  64/2418 [..............................] - ETA: 1s - loss: 0.5637 - acc: 0.7031
 192/2418 [=>............................] - ETA: 1s - loss: 0.5422 - acc: 0.7500
 320/2418 [==>...........................] - ETA: 1s - loss: 0.5558 - acc: 0.7469
 448/2418 [====>.........................] - ETA: 0s - loss: 0.5510 - acc: 0.7455
 576/2418 [======>.......................] - ETA: 0s - loss: 0.5664 - acc: 0.7222
 704/2418 [=======>......................] - ETA: 0s - loss: 0.5650 - acc: 0.7287
 832/2418 [=========>....................] - ETA: 0s - loss: 0.5671 - acc: 0.7224
 960/2418 [==========>...................] - ETA: 0s - loss: 0.5665 - acc: 0.7229
1088/2418 [============>.................] - ETA: 0s - loss: 0.5710 - acc: 0.7151
1216/2418 [==============>...............] - ETA: 0s - loss: 0.5724 - acc: 0.7122
1344/2418 [===============>..............] - ETA: 0s - loss: 0.5735 - acc: 0.7135
1472/2418 [=================>............] - ETA: 0s - loss: 0.5708 - acc: 0.7154
1600/2418 [==================>...........] - ETA: 0s - loss: 0.5683 - acc: 0.7181
1728/2418 [====================>.........] - ETA: 0s - loss: 0.5652 - acc: 0.7193
1856/2418 [======================>.......] - ETA: 0s - loss: 0.5684 - acc: 0.7155
1984/2418 [=======================>......] - ETA: 0s - loss: 0.5671 - acc: 0.7182
2112/2418 [=========================>....] - ETA: 0s - loss: 0.5675 - acc: 0.7188
2240/2418 [==========================>...] - ETA: 0s - loss: 0.5681 - acc: 0.7165
2368/2418 [============================>.] - ETA: 0s - loss: 0.5674 - acc: 0.7166
2418/2418 [==============================] - 1s 489us/step - loss: 0.5679 - acc: 0.7175 - val_loss: 0.5010 - val_acc: 0.7658

Epoch 00003: val_acc did not improve from 0.76952
Epoch 4/10

  64/2418 [..............................] - ETA: 1s - loss: 0.5527 - acc: 0.7188
 192/2418 [=>............................] - ETA: 0s - loss: 0.5591 - acc: 0.7135
 320/2418 [==>...........................] - ETA: 0s - loss: 0.5551 - acc: 0.7156
 448/2418 [====>.........................] - ETA: 0s - loss: 0.5431 - acc: 0.7232
 576/2418 [======>.......................] - ETA: 0s - loss: 0.5359 - acc: 0.7240
 704/2418 [=======>......................] - ETA: 0s - loss: 0.5420 - acc: 0.7173
 832/2418 [=========>....................] - ETA: 0s - loss: 0.5477 - acc: 0.7188
 960/2418 [==========>...................] - ETA: 0s - loss: 0.5515 - acc: 0.7177
1088/2418 [============>.................] - ETA: 0s - loss: 0.5518 - acc: 0.7132
1216/2418 [==============>...............] - ETA: 0s - loss: 0.5540 - acc: 0.7130
1344/2418 [===============>..............] - ETA: 0s - loss: 0.5490 - acc: 0.7180
1472/2418 [=================>............] - ETA: 0s - loss: 0.5487 - acc: 0.7201
1600/2418 [==================>...........] - ETA: 0s - loss: 0.5560 - acc: 0.7200
1728/2418 [====================>.........] - ETA: 0s - loss: 0.5571 - acc: 0.7199
1856/2418 [======================>.......] - ETA: 0s - loss: 0.5609 - acc: 0.7166
1984/2418 [=======================>......] - ETA: 0s - loss: 0.5641 - acc: 0.7157
2112/2418 [=========================>....] - ETA: 0s - loss: 0.5661 - acc: 0.7131
2240/2418 [==========================>...] - ETA: 0s - loss: 0.5686 - acc: 0.7143
2368/2418 [============================>.] - ETA: 0s - loss: 0.5665 - acc: 0.7171
2418/2418 [==============================] - 1s 455us/step - loss: 0.5672 - acc: 0.7175 - val_loss: 0.5143 - val_acc: 0.7658

Epoch 00004: val_acc did not improve from 0.76952
Epoch 5/10

  64/2418 [..............................] - ETA: 1s - loss: 0.5944 - acc: 0.7031
 192/2418 [=>............................] - ETA: 1s - loss: 0.5602 - acc: 0.6979
 320/2418 [==>...........................] - ETA: 0s - loss: 0.5546 - acc: 0.7156
 448/2418 [====>.........................] - ETA: 0s - loss: 0.5569 - acc: 0.7165
 576/2418 [======>.......................] - ETA: 0s - loss: 0.5517 - acc: 0.7222
 704/2418 [=======>......................] - ETA: 0s - loss: 0.5438 - acc: 0.7287
 832/2418 [=========>....................] - ETA: 0s - loss: 0.5513 - acc: 0.7248
 960/2418 [==========>...................] - ETA: 0s - loss: 0.5562 - acc: 0.7177
1088/2418 [============>.................] - ETA: 0s - loss: 0.5580 - acc: 0.7178
1216/2418 [==============>...............] - ETA: 0s - loss: 0.5571 - acc: 0.7171
1344/2418 [===============>..............] - ETA: 0s - loss: 0.5750 - acc: 0.7106
1472/2418 [=================>............] - ETA: 0s - loss: 0.5778 - acc: 0.7154
1600/2418 [==================>...........] - ETA: 0s - loss: 0.5732 - acc: 0.7188
1728/2418 [====================>.........] - ETA: 0s - loss: 0.5730 - acc: 0.7193
1856/2418 [======================>.......] - ETA: 0s - loss: 0.5717 - acc: 0.7198
1984/2418 [=======================>......] - ETA: 0s - loss: 0.5686 - acc: 0.7233
2112/2418 [=========================>....] - ETA: 0s - loss: 0.5704 - acc: 0.7188
2240/2418 [==========================>...] - ETA: 0s - loss: 0.5692 - acc: 0.7179
2368/2418 [============================>.] - ETA: 0s - loss: 0.5702 - acc: 0.7204
2418/2418 [==============================] - 1s 469us/step - loss: 0.5707 - acc: 0.7188 - val_loss: 0.5002 - val_acc: 0.7658

Epoch 00005: val_acc did not improve from 0.76952
Epoch 6/10

  64/2418 [..............................] - ETA: 1s - loss: 0.6002 - acc: 0.6406
 192/2418 [=>............................] - ETA: 1s - loss: 0.5289 - acc: 0.7448
 320/2418 [==>...........................] - ETA: 0s - loss: 0.5282 - acc: 0.7344
 448/2418 [====>.........................] - ETA: 0s - loss: 0.5333 - acc: 0.7366
 576/2418 [======>.......................] - ETA: 0s - loss: 0.5320 - acc: 0.7361
 704/2418 [=======>......................] - ETA: 0s - loss: 0.5482 - acc: 0.7273
 832/2418 [=========>....................] - ETA: 0s - loss: 0.5481 - acc: 0.7296
 960/2418 [==========>...................] - ETA: 0s - loss: 0.5454 - acc: 0.7375
1088/2418 [============>.................] - ETA: 0s - loss: 0.5500 - acc: 0.7335
1216/2418 [==============>...............] - ETA: 0s - loss: 0.5562 - acc: 0.7253
1344/2418 [===============>..............] - ETA: 0s - loss: 0.5531 - acc: 0.7284
1536/2418 [==================>...........] - ETA: 0s - loss: 0.5581 - acc: 0.7188
1664/2418 [===================>..........] - ETA: 0s - loss: 0.5612 - acc: 0.7181
1792/2418 [=====================>........] - ETA: 0s - loss: 0.5675 - acc: 0.7126
1920/2418 [======================>.......] - ETA: 0s - loss: 0.5639 - acc: 0.7146
2048/2418 [========================>.....] - ETA: 0s - loss: 0.5626 - acc: 0.7173
2176/2418 [=========================>....] - ETA: 0s - loss: 0.5632 - acc: 0.7160
2304/2418 [===========================>..] - ETA: 0s - loss: 0.5657 - acc: 0.7148
2418/2418 [==============================] - 1s 434us/step - loss: 0.5621 - acc: 0.7171 - val_loss: 0.4991 - val_acc: 0.7658

Epoch 00006: val_acc did not improve from 0.76952
Epoch 7/10

  64/2418 [..............................] - ETA: 1s - loss: 0.5702 - acc: 0.7031
 192/2418 [=>............................] - ETA: 0s - loss: 0.5659 - acc: 0.6979
 320/2418 [==>...........................] - ETA: 0s - loss: 0.5831 - acc: 0.6719
 448/2418 [====>.........................] - ETA: 0s - loss: 0.5679 - acc: 0.7009
 576/2418 [======>.......................] - ETA: 0s - loss: 0.5680 - acc: 0.7101
 704/2418 [=======>......................] - ETA: 0s - loss: 0.5675 - acc: 0.7074
 832/2418 [=========>....................] - ETA: 0s - loss: 0.5658 - acc: 0.7079
 960/2418 [==========>...................] - ETA: 0s - loss: 0.5644 - acc: 0.7094
1088/2418 [============>.................] - ETA: 0s - loss: 0.5686 - acc: 0.7151
1216/2418 [==============>...............] - ETA: 0s - loss: 0.5608 - acc: 0.7220
1344/2418 [===============>..............] - ETA: 0s - loss: 0.5576 - acc: 0.7225
1536/2418 [==================>...........] - ETA: 0s - loss: 0.5607 - acc: 0.7188
1664/2418 [===================>..........] - ETA: 0s - loss: 0.5575 - acc: 0.7212
1792/2418 [=====================>........] - ETA: 0s - loss: 0.5618 - acc: 0.7188
1920/2418 [======================>.......] - ETA: 0s - loss: 0.5634 - acc: 0.7151
2048/2418 [========================>.....] - ETA: 0s - loss: 0.5607 - acc: 0.7153
2176/2418 [=========================>....] - ETA: 0s - loss: 0.5609 - acc: 0.7174
2304/2418 [===========================>..] - ETA: 0s - loss: 0.5628 - acc: 0.7188
2418/2418 [==============================] - 1s 452us/step - loss: 0.5644 - acc: 0.7188 - val_loss: 0.5074 - val_acc: 0.7658

Epoch 00007: val_acc did not improve from 0.76952
Epoch 8/10

  64/2418 [..............................] - ETA: 1s - loss: 0.5660 - acc: 0.7344
 192/2418 [=>............................] - ETA: 1s - loss: 0.5649 - acc: 0.7135
 320/2418 [==>...........................] - ETA: 0s - loss: 0.5702 - acc: 0.7094
 448/2418 [====>.........................] - ETA: 0s - loss: 0.5725 - acc: 0.7121
 576/2418 [======>.......................] - ETA: 0s - loss: 0.5743 - acc: 0.7101
 704/2418 [=======>......................] - ETA: 0s - loss: 0.5734 - acc: 0.7074
 832/2418 [=========>....................] - ETA: 0s - loss: 0.5767 - acc: 0.6995
 960/2418 [==========>...................] - ETA: 0s - loss: 0.5709 - acc: 0.7031
1088/2418 [============>.................] - ETA: 0s - loss: 0.5731 - acc: 0.7013
1216/2418 [==============>...............] - ETA: 0s - loss: 0.5671 - acc: 0.7056
1408/2418 [================>.............] - ETA: 0s - loss: 0.5673 - acc: 0.7124
1536/2418 [==================>...........] - ETA: 0s - loss: 0.5727 - acc: 0.7070
1664/2418 [===================>..........] - ETA: 0s - loss: 0.5655 - acc: 0.7151
1792/2418 [=====================>........] - ETA: 0s - loss: 0.5635 - acc: 0.7160
1920/2418 [======================>.......] - ETA: 0s - loss: 0.5623 - acc: 0.7188
2048/2418 [========================>.....] - ETA: 0s - loss: 0.5641 - acc: 0.7163
2176/2418 [=========================>....] - ETA: 0s - loss: 0.5649 - acc: 0.7165
2304/2418 [===========================>..] - ETA: 0s - loss: 0.5654 - acc: 0.7166
2418/2418 [==============================] - 1s 454us/step - loss: 0.5643 - acc: 0.7175 - val_loss: 0.4949 - val_acc: 0.7695

Epoch 00008: val_acc did not improve from 0.76952
Epoch 9/10

  64/2418 [..............................] - ETA: 1s - loss: 0.5808 - acc: 0.7031
 256/2418 [==>...........................] - ETA: 0s - loss: 0.6078 - acc: 0.6680
 384/2418 [===>..........................] - ETA: 0s - loss: 0.5779 - acc: 0.6979
 512/2418 [=====>........................] - ETA: 0s - loss: 0.5720 - acc: 0.7031
 640/2418 [======>.......................] - ETA: 0s - loss: 0.5668 - acc: 0.7063
 768/2418 [========>.....................] - ETA: 0s - loss: 0.5599 - acc: 0.7161
 896/2418 [==========>...................] - ETA: 0s - loss: 0.5580 - acc: 0.7165
1024/2418 [===========>..................] - ETA: 0s - loss: 0.5604 - acc: 0.7148
1152/2418 [=============>................] - ETA: 0s - loss: 0.5601 - acc: 0.7144
1280/2418 [==============>...............] - ETA: 0s - loss: 0.5526 - acc: 0.7219
1408/2418 [================>.............] - ETA: 0s - loss: 0.5523 - acc: 0.7230
1536/2418 [==================>...........] - ETA: 0s - loss: 0.5566 - acc: 0.7207
1664/2418 [===================>..........] - ETA: 0s - loss: 0.5525 - acc: 0.7218
1792/2418 [=====================>........] - ETA: 0s - loss: 0.5513 - acc: 0.7221
1920/2418 [======================>.......] - ETA: 0s - loss: 0.5622 - acc: 0.7208
2048/2418 [========================>.....] - ETA: 0s - loss: 0.5639 - acc: 0.7231
2176/2418 [=========================>....] - ETA: 0s - loss: 0.5665 - acc: 0.7192
2304/2418 [===========================>..] - ETA: 0s - loss: 0.5652 - acc: 0.7214
2418/2418 [==============================] - 1s 455us/step - loss: 0.5667 - acc: 0.7192 - val_loss: 0.5158 - val_acc: 0.7732

Epoch 00009: val_acc improved from 0.76952 to 0.77323, saving model to /data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/checkpoints_4layer_130-/omics_model/model_multi_omics4.hdf5
Epoch 10/10

  64/2418 [..............................] - ETA: 1s - loss: 0.5669 - acc: 0.7344
 192/2418 [=>............................] - ETA: 1s - loss: 0.5335 - acc: 0.7604
 320/2418 [==>...........................] - ETA: 1s - loss: 0.5757 - acc: 0.7250
 448/2418 [====>.........................] - ETA: 0s - loss: 0.5902 - acc: 0.6987
 576/2418 [======>.......................] - ETA: 0s - loss: 0.5863 - acc: 0.7014
 704/2418 [=======>......................] - ETA: 0s - loss: 0.5847 - acc: 0.7003
 832/2418 [=========>....................] - ETA: 0s - loss: 0.5830 - acc: 0.6983
 960/2418 [==========>...................] - ETA: 0s - loss: 0.5778 - acc: 0.7063
1088/2418 [============>.................] - ETA: 0s - loss: 0.5666 - acc: 0.7243
1216/2418 [==============>...............] - ETA: 0s - loss: 0.5667 - acc: 0.7270
1344/2418 [===============>..............] - ETA: 0s - loss: 0.5635 - acc: 0.7321
1472/2418 [=================>............] - ETA: 0s - loss: 0.5540 - acc: 0.7405
1600/2418 [==================>...........] - ETA: 0s - loss: 0.5504 - acc: 0.7406
1728/2418 [====================>.........] - ETA: 0s - loss: 0.5587 - acc: 0.7315
1856/2418 [======================>.......] - ETA: 0s - loss: 0.5662 - acc: 0.7252
1984/2418 [=======================>......] - ETA: 0s - loss: 0.5690 - acc: 0.7208
2112/2418 [=========================>....] - ETA: 0s - loss: 0.5719 - acc: 0.7178
2240/2418 [==========================>...] - ETA: 0s - loss: 0.5719 - acc: 0.7170
2368/2418 [============================>.] - ETA: 0s - loss: 0.5739 - acc: 0.7141
2418/2418 [==============================] - 1s 472us/step - loss: 0.5737 - acc: 0.7138 - val_loss: 0.5220 - val_acc: 0.7658

Epoch 00010: val_acc did not improve from 0.77323
Saved model to disk
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:40: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 8, activation="relu", padding="same")`
  omics_conv1_ = Conv1D(128, 8, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:42: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 1, activation="relu", padding="same")`
  omics_conv2_ = Conv1D(64, 1, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:44: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation="relu", padding="same")`
  omics_conv3_ = Conv1D(64, 3, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:46: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 1, activation="relu", padding="same")`
  omics_conv4_ = Conv1D(128, 1, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:63: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_omics], output=[pred_output])
ACC: 0.7174887892376681
Sens: 0.5345345345345346
Spec: 0.8988095238095238
MCC: 0.4656917789309296
ROC_AUC: 0.745995995995996
PRC_ROC: 0.8203569049329067
WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:40: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 8, activation="relu", padding="same")`
  omics_conv1_ = Conv1D(128, 8, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:42: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 1, activation="relu", padding="same")`
  omics_conv2_ = Conv1D(64, 1, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:44: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation="relu", padding="same")`
  omics_conv3_ = Conv1D(64, 3, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:46: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 1, activation="relu", padding="same")`
  omics_conv4_ = Conv1D(128, 1, activation='relu', border_mode='same')
/data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/Model_CNN.py:63: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_omics], output=[pred_output])
Fitting first model...
Train on 2418 samples, validate on 269 samples
Epoch 1/10

  64/2418 [..............................] - ETA: 25s - loss: 0.6717 - acc: 0.7188
 192/2418 [=>............................] - ETA: 8s - loss: 0.6093 - acc: 0.5729 
 320/2418 [==>...........................] - ETA: 5s - loss: 0.6094 - acc: 0.5656
 448/2418 [====>.........................] - ETA: 3s - loss: 0.6316 - acc: 0.6049
 576/2418 [======>.......................] - ETA: 3s - loss: 0.6419 - acc: 0.6267
 704/2418 [=======>......................] - ETA: 2s - loss: 0.6329 - acc: 0.6506
 832/2418 [=========>....................] - ETA: 2s - loss: 0.6234 - acc: 0.6647
 960/2418 [==========>...................] - ETA: 1s - loss: 0.6230 - acc: 0.6708
1088/2418 [============>.................] - ETA: 1s - loss: 0.6159 - acc: 0.6756
1216/2418 [==============>...............] - ETA: 1s - loss: 0.6094 - acc: 0.6875
1344/2418 [===============>..............] - ETA: 1s - loss: 0.6109 - acc: 0.6875
1472/2418 [=================>............] - ETA: 0s - loss: 0.6122 - acc: 0.6827
1600/2418 [==================>...........] - ETA: 0s - loss: 0.6193 - acc: 0.6856
1728/2418 [====================>.........] - ETA: 0s - loss: 0.6150 - acc: 0.6898
1856/2418 [======================>.......] - ETA: 0s - loss: 0.6120 - acc: 0.6923
1984/2418 [=======================>......] - ETA: 0s - loss: 0.6102 - acc: 0.6951
2112/2418 [=========================>....] - ETA: 0s - loss: 0.6075 - acc: 0.6946
2240/2418 [==========================>...] - ETA: 0s - loss: 0.6061 - acc: 0.6937
2368/2418 [============================>.] - ETA: 0s - loss: 0.6064 - acc: 0.6909
2418/2418 [==============================] - 2s 789us/step - loss: 0.6062 - acc: 0.6898 - val_loss: 0.6121 - val_acc: 0.7361

Epoch 00001: val_acc improved from -inf to 0.73606, saving model to /data/lyli/Silencer/HepG2/datasets/1679/12D/data_n=20/model/checkpoints_4layer_130-/omics_model/model_multi_omics5.hdf5
Epoch 2/10

  64/2418 [..............................] - ETA: 1s - loss: 0.5859 - acc: 0.7344
 192/2418 [=>............................] - ETA: 1s - loss: 0.5977 - acc: 0.6823
 320/2418 [==>...........................] - ETA: 1s - loss: 0.5744 - acc: 0.7156
 448/2418 [====>.........................] - ETA: 0s - loss: 0.5768 - acc: 0.7165
 576/2418 [======>.......................] - ETA: 0s - loss: 0.5842 - acc: 0.7083
 704/2418 [=======>......................] - ETA: 0s - loss: 0.5863 - acc: 0.7074
 832/2418 [=========>....................] - ETA: 0s - loss: 0.5883 - acc: 0.6935
 960/2418 [==========>...................] - ETA: 0s - loss: 0.5874 - acc: 0.6917
1088/2418 [============>.................] - ETA: 0s - loss: 0.5827 - acc: 0.6958
1216/2418 [==============>...............] - ETA: 0s - loss: 0.5828 - acc: 0.6965
1344/2418 [===============>..............] - ETA: 0s - loss: 0.5812 - acc: 0.6994
1472/2418 [=================>............] - ETA: 0s - loss: 0.5800 - acc: 0.7045
1536/2418 [==================>...........] - ETA: 0s - loss: 0.5776 - acc: 0.7064
1664/2418 [===================>..........] - ETA: 0s - loss: 0.5766 - acc: 0.7091
1856/2418 [======================>.......] - ETA: 0s - loss: 0.5761 - acc: 0.7101
1984/2418 [=======================>......] - ETA: 0s - loss: 0.5774 - acc: 0.7082
2112/2418 [=========================>....] - ETA: 0s - loss: 0.5800 - acc: 0.7079
2240/2418 [==========================>...] - ETA: 0s - loss: 0.5747 - acc: 0.7129
2368/2418 [============================>.] - ETA: 0s - loss: 0.5705 - acc: 0.7162
2418/2418 [==============================] - 1s 506us/step - loss: 0.5710 - acc: 0.7155 - val_loss: 0.6032 - val_acc: 0.7323

Epoch 00002: val_acc did not improve from 0.73606
Epoch 3/10

  64/2418 [..............................] - ETA: 1s - loss: 0.5108 - acc: 0.7500
 192/2418 [=>............................] - ETA: 1s - loss: 0.5358 - acc: 0.7344
 320/2418 [==>...........................] - ETA: 0s - loss: 0.5385 - acc: 0.7312
 448/2418 [====>.........................] - ETA: 0s - loss: 0.5592 - acc: 0.7210
 576/2418 [======>.......................] - ETA: 0s - loss: 0.5650 - acc: 0.7153
 704/2418 [=======>......................] - ETA: 0s - loss: 0.5743 - acc: 0.7145
 832/2418 [=========>....................] - ETA: 0s - loss: 0.5698 - acc: 0.7163
 960/2418 [==========>...................] - ETA: 0s - loss: 0.5638 - acc: 0.7240
1088/2418 [============>.................] - ETA: 0s - loss: 0.5638 - acc: 0.7224
1216/2418 [==============>...............] - ETA: 0s - loss: 0.5625 - acc: 0.7253
1344/2418 [===============>..............] - ETA: 0s - loss: 0.5624 - acc: 0.7202
1472/2418 [=================>............] - ETA: 0s - loss: 0.5599 - acc: 0.7228
1600/2418 [==================>...........] - ETA: 0s - loss: 0.5601 - acc: 0.7212
1728/2418 [====================>.........] - ETA: 0s - loss: 0.5567 - acc: 0.7245
1856/2418 [======================>.......] - ETA: 0s - loss: 0.5653 - acc: 0.7209
2048/2418 [========================>.....] - ETA: 0s - loss: 0.5658 - acc: 0.7197
2176/2418 [=========================>....] - ETA: 0s - loss: 0.5688 - acc: 0.7174
2304/2418 [===========================>..] - ETA: 0s - loss: 0.5713 - acc: 0.7140
2418/2418 [==============================] - 1s 447us/step - loss: 0.5702 - acc: 0.7171 - val_loss: 0.6122 - val_acc: 0.7323

Epoch 00003: val_acc did not improve from 0.73606
Epoch 4/10

  64/2418 [..............................] - ETA: 1s - loss: 0.5085 - acc: 0.7500
 192/2418 [=>............................] - ETA: 0s - loss: 0.5925 - acc: 0.7031
 320/2418 [==>...........................] - ETA: 0s - loss: 0.5743 - acc: 0.7250
 448/2418 [====>.........................] - ETA: 0s - loss: 0.5737 - acc: 0.7254
 576/2418 [======>.......................] - ETA: 0s - loss: 0.5603 - acc: 0.7274
 704/2418 [=======>......................] - ETA: 0s - loss: 0.5513 - acc: 0.7301
 832/2418 [=========>....................] - ETA: 0s - loss: 0.5559 - acc: 0.7260
 960/2418 [==========>...................] - ETA: 0s - loss: 0.5625 - acc: 0.7208
1088/2418 [============>.................] - ETA: 0s - loss: 0.5579 - acc: 0.7252
1216/2418 [==============>...............] - ETA: 0s - loss: 0.5575 - acc: 0.7245
1344/2418 [===============>..............] - ETA: 0s - loss: 0.5602 - acc: 0.7262
1472/2418 [=================>............] - ETA: 0s - loss: 0.5604 - acc: 0.7249
1600/2418 [==================>...........] - ETA: 0s - loss: 0.5641 - acc: 0.7256
1728/2418 [====================>.........] - ETA: 0s - loss: 0.5680 - acc: 0.7234
1856/2418 [======================>.......] - ETA: 0s - loss: 0.5645 - acc: 0.7258
1984/2418 [=======================>......] - ETA: 0s - loss: 0.5671 - acc: 0.7198
2112/2418 [=========================>....] - ETA: 0s - loss: 0.5662 - acc: 0.7173
2240/2418 [==========================>...] - ETA: 0s - loss: 0.5699 - acc: 0.7143
2368/2418 [============================>.] - ETA: 0s - loss: 0.5721 - acc: 0.7128
2418/2418 [==============================] - 1s 468us/step - loss: 0.5701 - acc: 0.7146 - val_loss: 0.6094 - val_acc: 0.7323

Epoch 00004: val_acc did not improve from 0.73606
Epoch 5/10

  64/2418 [..............................] - ETA: 1s - loss: 0.4469 - acc: 0.8750
 192/2418 [=>............................] - ETA: 0s - loss: 0.5213 - acc: 0.7656
 384/2418 [===>..........................] - ETA: 0s - loss: 0.5045 - acc: 0.7708
 512/2418 [=====>........................] - ETA: 0s - loss: 0.5120 - acc: 0.7695
 640/2418 [======>.......................] - ETA: 0s - loss: 0.5175 - acc: 0.7672
 768/2418 [========>.....................] - ETA: 0s - loss: 0.5314 - acc: 0.7513
 896/2418 [==========>...................] - ETA: 0s - loss: 0.5380 - acc: 0.7400
1024/2418 [===========>..................] - ETA: 0s - loss: 0.5471 - acc: 0.7295
1152/2418 [=============>................] - ETA: 0s - loss: 0.5477 - acc: 0.7283
1280/2418 [==============>...............] - ETA: 0s - loss: 0.5565 - acc: 0.7273
1408/2418 [================>.............] - ETA: 0s - loss: 0.5601 - acc: 0.7216
1536/2418 [==================>...........] - ETA: 0s - loss: 0.5592 - acc: 0.7220
1728/2418 [====================>.........] - ETA: 0s - loss: 0.5580 - acc: 0.7245
1856/2418 [======================>.......] - ETA: 0s - loss: 0.5608 - acc: 0.7252
1984/2418 [=======================>......] - ETA: 0s - loss: 0.5664 - acc: 0.7208
2176/2418 [=========================>....] - ETA: 0s - loss: 0.5618 - acc: 0.7224
2304/2418 [===========================>..] - ETA: 0s - loss: 0.5653 - acc: 0.7179
2418/2418 [==============================] - 1s 438us/step - loss: 0.5674 - acc: 0.7163 - val_loss: 0.6061 - val_acc: 0.7323

Epoch 00005: val_acc did not improve from 0.73606
Epoch 6/10

  64/2418 [..............................] - ETA: 1s - loss: 0.5212 - acc: 0.7500
 192/2418 [=>............................] - ETA: 0s - loss: 0.5689 - acc: 0.6927
 320/2418 [==>...........................] - ETA: 0s - loss: 0.5422 - acc: 0.7312
 448/2418 [====>.........................] - ETA: 0s - loss: 0.5496 - acc: 0.7232
 576/2418 [======>.......................] - ETA: 0s - loss: 0.5612 - acc: 0.7066
 704/2418 [=======>......................] - ETA: 0s - loss: 0.5501 - acc: 0.7159
 832/2418 [=========>....................] - ETA: 0s - loss: 0.5532 - acc: 0.7188
 960/2418 [==========>...................] - ETA: 0s - loss: 0.5504 - acc: 0.7188
1088/2418 [============>.................] - ETA: 0s - loss: 0.5435 - acc: 0.7316
1216/2418 [==============>...............] - ETA: 0s - loss: 0.5525 - acc: 0.7319
1344/2418 [===============>..............] - ETA: 0s - loss: 0.5608 - acc: 0.7277
1472/2418 [=================>............] - ETA: 0s - loss: 0.5638 - acc: 0.7255
1600/2418 [==================>...........] - ETA: 0s - loss: 0.5677 - acc: 0.7188
1728/2418 [====================>.........] - ETA: 0s - loss: 0.5662 - acc: 0.7182
1856/2418 [======================>.......] - ETA: 0s - loss: 0.5703 - acc: 0.7123
1984/2418 [=======================>......] - ETA: 0s - loss: 0.5735 - acc: 0.7087
2112/2418 [=========================>....] - ETA: 0s - loss: 0.5711 - acc: 0.7140
2240/2418 [==========================>...] - ETA: 0s - loss: 0.5689 - acc: 0.7174
2368/2418 [============================>.] - ETA: 0s - loss: 0.5684 - acc: 0.7175
2418/2418 [==============================] - 1s 446us/step - loss: 0.5703 - acc: 0.7175 - val_loss: 0.6108 - val_acc: 0.7323

Epoch 00006: val_acc did not improve from 0.73606
Epoch 7/10

  64/2418 [..............................] - ETA: 1s - loss: 0.5635 - acc: 0.7031
 192/2418 [=>............................] - ETA: 1s - loss: 0.5568 - acc: 0.7083
 320/2418 [==>...........................] - ETA: 0s - loss: 0.5480 - acc: 0.7094
 448/2418 [====>.........................] - ETA: 0s - loss: 0.5553 - acc: 0.7165
 576/2418 [======>.......................] - ETA: 0s - loss: 0.5504 - acc: 0.7257
 704/2418 [=======>......................] - ETA: 0s - loss: 0.5458 - acc: 0.7273
 832/2418 [=========>....................] - ETA: 0s - loss: 0.5565 - acc: 0.7200
 960/2418 [==========>...................] - ETA: 0s - loss: 0.5637 - acc: 0.7146
1088/2418 [============>.................] - ETA: 0s - loss: 0.5614 - acc: 0.7188
1216/2418 [==============>...............] - ETA: 0s - loss: 0.5644 - acc: 0.7179
1344/2418 [===============>..............] - ETA: 0s - loss: 0.5647 - acc: 0.7173
1472/2418 [=================>............] - ETA: 0s - loss: 0.5641 - acc: 0.7188
1600/2418 [==================>...........] - ETA: 0s - loss: 0.5638 - acc: 0.7194
1792/2418 [=====================>........] - ETA: 0s - loss: 0.5680 - acc: 0.7126
1920/2418 [======================>.......] - ETA: 0s - loss: 0.5687 - acc: 0.7135
2048/2418 [========================>.....] - ETA: 0s - loss: 0.5659 - acc: 0.7168
2176/2418 [=========================>....] - ETA: 0s - loss: 0.5668 - acc: 0.7160
2304/2418 [===========================>..] - ETA: 0s - loss: 0.5646 - acc: 0.7174
2418/2418 [==============================] - 1s 439us/step - loss: 0.5645 - acc: 0.7184 - val_loss: 0.6022 - val_acc: 0.7361

Epoch 00007: val_acc did not improve from 0.73606
Epoch 8/10

  64/2418 [..............................] - ETA: 1s - loss: 0.5458 - acc: 0.7188
 192/2418 [=>............................] - ETA: 0s - loss: 0.5767 - acc: 0.7344
 320/2418 [==>...........................] - ETA: 0s - loss: 0.5530 - acc: 0.7469
 448/2418 [====>.........................] - ETA: 0s - loss: 0.5491 - acc: 0.7433
 576/2418 [======>.......................] - ETA: 0s - loss: 0.5429 - acc: 0.7483
 704/2418 [=======>......................] - ETA: 0s - loss: 0.5421 - acc: 0.7415
 896/2418 [==========>...................] - ETA: 0s - loss: 0.5469 - acc: 0.7377
1024/2418 [===========>..................] - ETA: 0s - loss: 0.5538 - acc: 0.7256
1152/2418 [=============>................] - ETA: 0s - loss: 0.5523 - acc: 0.7274
1280/2418 [==============>...............] - ETA: 0s - loss: 0.5517 - acc: 0.7234
1408/2418 [================>.............] - ETA: 0s - loss: 0.5515 - acc: 0.7280
1536/2418 [==================>...........] - ETA: 0s - loss: 0.5521 - acc: 0.7272
1664/2418 [===================>..........] - ETA: 0s - loss: 0.5529 - acc: 0.7266
1792/2418 [=====================>........] - ETA: 0s - loss: 0.5532 - acc: 0.7232
1984/2418 [=======================>......] - ETA: 0s - loss: 0.5565 - acc: 0.7228
2112/2418 [=========================>....] - ETA: 0s - loss: 0.5573 - acc: 0.7211
2240/2418 [==========================>...] - ETA: 0s - loss: 0.5596 - acc: 0.7174
2368/2418 [============================>.] - ETA: 0s - loss: 0.5578 - acc: 0.7188
2418/2418 [==============================] - 1s 440us/step - loss: 0.5574 - acc: 0.7192 - val_loss: 0.6056 - val_acc: 0.7361

Epoch 00008: val_acc did not improve from 0.73606
Epoch 9/10

  64/2418 [..............................] - ETA: 1s - loss: 0.4996 - acc: 0.7812
 192/2418 [=>............................] - ETA: 1s - loss: 0.5675 - acc: 0.7083
 320/2418 [==>...........................] - ETA: 1s - loss: 0.5793 - acc: 0.6937
 448/2418 [====>.........................] - ETA: 0s - loss: 0.5711 - acc: 0.7054
 576/2418 [======>.......................] - ETA: 0s - loss: 0.5732 - acc: 0.7031
 704/2418 [=======>......................] - ETA: 0s - loss: 0.5619 - acc: 0.7116
 832/2418 [=========>....................] - ETA: 0s - loss: 0.5549 - acc: 0.7163
 960/2418 [==========>...................] - ETA: 0s - loss: 0.5459 - acc: 0.7302
1088/2418 [============>.................] - ETA: 0s - loss: 0.5507 - acc: 0.7307
1216/2418 [==============>...............] - ETA: 0s - loss: 0.5514 - acc: 0.7286
1344/2418 [===============>..............] - ETA: 0s - loss: 0.5477 - acc: 0.7314
1472/2418 [=================>............] - ETA: 0s - loss: 0.5525 - acc: 0.7255
1600/2418 [==================>...........] - ETA: 0s - loss: 0.5559 - acc: 0.7262
1728/2418 [====================>.........] - ETA: 0s - loss: 0.5578 - acc: 0.7240
1856/2418 [======================>.......] - ETA: 0s - loss: 0.5574 - acc: 0.7214
1984/2418 [=======================>......] - ETA: 0s - loss: 0.5605 - acc: 0.7198
2112/2418 [=========================>....] - ETA: 0s - loss: 0.5606 - acc: 0.7188
2240/2418 [==========================>...] - ETA: 0s - loss: 0.5600 - acc: 0.7192
2368/2418 [============================>.] - ETA: 0s - loss: 0.5580 - acc: 0.7200
2418/2418 [==============================] - 1s 455us/step - loss: 0.5601 - acc: 0.7175 - val_loss: 0.6095 - val_acc: 0.7361

Epoch 00009: val_acc did not improve from 0.73606
Epoch 10/10

  64/2418 [..............................] - ETA: 1s - loss: 0.6066 - acc: 0.6719
 192/2418 [=>............................] - ETA: 0s - loss: 0.5598 - acc: 0.7240
 384/2418 [===>..........................] - ETA: 0s - loss: 0.5803 - acc: 0.6901
 576/2418 [======>.......................] - ETA: 0s - loss: 0.5772 - acc: 0.6927
 704/2418 [=======>......................] - ETA: 0s - loss: 0.5659 - acc: 0.7017
 832/2418 [=========>....................] - ETA: 0s - loss: 0.5635 - acc: 0.7055
 960/2418 [==========>....