
ACC_average: 0.6515864128406121
Sens_average: 0.6593875441569744
Spec_average: 0.6446068108112071
MCC_average: 0.3047143129658593
ROC_average: 0.7133598555121413
PRC_average: 0.7083769371838875
nohup: ignoring input
Using TensorFlow backend.
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

2023-05-26 17:12:47.721661: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-05-26 17:12:47.767175: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz
2023-05-26 17:12:47.801713: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ad1caf6ba0 executing computations on platform Host. Devices:
2023-05-26 17:12:47.801815: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-05-26 17:12:47.851712: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
/data/lyli/Silencer/K562/datasets/6924/5fold/model/checkpoints_4layer_100-/Model_CNN.py:33: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[input_seq], output=[pred_output])
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Fitting first model...
Train on 9968 samples, validate on 1108 samples
Epoch 1/10

  64/9968 [..............................] - ETA: 1:25 - loss: 0.7024 - acc: 0.4844
 320/9968 [..............................] - ETA: 18s - loss: 0.7039 - acc: 0.4781 
 576/9968 [>.............................] - ETA: 10s - loss: 0.6944 - acc: 0.5156
 896/9968 [=>............................] - ETA: 7s - loss: 0.6894 - acc: 0.5391 
1216/9968 [==>...........................] - ETA: 5s - loss: 0.6820 - acc: 0.5617
1536/9968 [===>..........................] - ETA: 4s - loss: 0.6831 - acc: 0.5645
1856/9968 [====>.........................] - ETA: 3s - loss: 0.6845 - acc: 0.5668
2112/9968 [=====>........................] - ETA: 3s - loss: 0.6819 - acc: 0.5663
2432/9968 [======>.......................] - ETA: 3s - loss: 0.6811 - acc: 0.5695
2752/9968 [=======>......................] - ETA: 2s - loss: 0.6770 - acc: 0.5770
3072/9968 [========>.....................] - ETA: 2s - loss: 0.6758 - acc: 0.5771
3392/9968 [=========>....................] - ETA: 2s - loss: 0.6737 - acc: 0.5799
3648/9968 [=========>....................] - ETA: 2s - loss: 0.6752 - acc: 0.5784
3968/9968 [==========>...................] - ETA: 1s - loss: 0.6736 - acc: 0.5817
4288/9968 [===========>..................] - ETA: 1s - loss: 0.6725 - acc: 0.5805
4608/9968 [============>.................] - ETA: 1s - loss: 0.6710 - acc: 0.5833
4928/9968 [=============>................] - ETA: 1s - loss: 0.6703 - acc: 0.5836
5248/9968 [==============>...............] - ETA: 1s - loss: 0.6705 - acc: 0.5837
5568/9968 [===============>..............] - ETA: 1s - loss: 0.6674 - acc: 0.5880
5888/9968 [================>.............] - ETA: 1s - loss: 0.6660 - acc: 0.5914
6208/9968 [=================>............] - ETA: 1s - loss: 0.6654 - acc: 0.5921
6464/9968 [==================>...........] - ETA: 0s - loss: 0.6641 - acc: 0.5934
6784/9968 [===================>..........] - ETA: 0s - loss: 0.6627 - acc: 0.5957
7104/9968 [====================>.........] - ETA: 0s - loss: 0.6609 - acc: 0.5974
7424/9968 [=====================>........] - ETA: 0s - loss: 0.6608 - acc: 0.5979
7744/9968 [======================>.......] - ETA: 0s - loss: 0.6593 - acc: 0.5992
8000/9968 [=======================>......] - ETA: 0s - loss: 0.6578 - acc: 0.6005
8320/9968 [========================>.....] - ETA: 0s - loss: 0.6567 - acc: 0.6022
8640/9968 [=========================>....] - ETA: 0s - loss: 0.6548 - acc: 0.6037
8960/9968 [=========================>....] - ETA: 0s - loss: 0.6544 - acc: 0.6037
9280/9968 [==========================>...] - ETA: 0s - loss: 0.6534 - acc: 0.6051
9600/9968 [===========================>..] - ETA: 0s - loss: 0.6535 - acc: 0.6065
9920/9968 [============================>.] - ETA: 0s - loss: 0.6531 - acc: 0.6065
9968/9968 [==============================] - 3s 255us/step - loss: 0.6530 - acc: 0.6065 - val_loss: 0.6232 - val_acc: 0.6462

Epoch 00001: val_acc improved from -inf to 0.64621, saving model to /data/lyli/Silencer/K562/datasets/6924/5fold/model/checkpoints_4layer_100-/DNA_model/model_DNA1.hdf5
Epoch 2/10

  64/9968 [..............................] - ETA: 1s - loss: 0.6779 - acc: 0.6250
 384/9968 [>.............................] - ETA: 1s - loss: 0.6619 - acc: 0.6120
 640/9968 [>.............................] - ETA: 1s - loss: 0.6519 - acc: 0.6219
 960/9968 [=>............................] - ETA: 1s - loss: 0.6328 - acc: 0.6333
1216/9968 [==>...........................] - ETA: 1s - loss: 0.6193 - acc: 0.6439
1536/9968 [===>..........................] - ETA: 1s - loss: 0.6191 - acc: 0.6393
1856/9968 [====>.........................] - ETA: 1s - loss: 0.6298 - acc: 0.6331
2112/9968 [=====>........................] - ETA: 1s - loss: 0.6291 - acc: 0.6340
2432/9968 [======>.......................] - ETA: 1s - loss: 0.6293 - acc: 0.6361
2752/9968 [=======>......................] - ETA: 1s - loss: 0.6289 - acc: 0.6374
3072/9968 [========>.....................] - ETA: 1s - loss: 0.6277 - acc: 0.6383
3328/9968 [=========>....................] - ETA: 1s - loss: 0.6257 - acc: 0.6394
3584/9968 [=========>....................] - ETA: 1s - loss: 0.6286 - acc: 0.6381
3904/9968 [==========>...................] - ETA: 1s - loss: 0.6298 - acc: 0.6332
4224/9968 [===========>..................] - ETA: 1s - loss: 0.6314 - acc: 0.6323
4544/9968 [============>.................] - ETA: 1s - loss: 0.6334 - acc: 0.6287
4864/9968 [=============>................] - ETA: 0s - loss: 0.6325 - acc: 0.6283
5184/9968 [==============>...............] - ETA: 0s - loss: 0.6328 - acc: 0.6285
5504/9968 [===============>..............] - ETA: 0s - loss: 0.6315 - acc: 0.6301
5760/9968 [================>.............] - ETA: 0s - loss: 0.6310 - acc: 0.6309
6080/9968 [=================>............] - ETA: 0s - loss: 0.6302 - acc: 0.6332
6400/9968 [==================>...........] - ETA: 0s - loss: 0.6300 - acc: 0.6341
6656/9968 [===================>..........] - ETA: 0s - loss: 0.6286 - acc: 0.6366
6912/9968 [===================>..........] - ETA: 0s - loss: 0.6282 - acc: 0.6361
7168/9968 [====================>.........] - ETA: 0s - loss: 0.6287 - acc: 0.6353
7488/9968 [=====================>........] - ETA: 0s - loss: 0.6261 - acc: 0.6389
7808/9968 [======================>.......] - ETA: 0s - loss: 0.6256 - acc: 0.6395
8128/9968 [=======================>......] - ETA: 0s - loss: 0.6277 - acc: 0.6380
8448/9968 [========================>.....] - ETA: 0s - loss: 0.6284 - acc: 0.6374
8768/9968 [=========================>....] - ETA: 0s - loss: 0.6287 - acc: 0.6365
9024/9968 [==========================>...] - ETA: 0s - loss: 0.6286 - acc: 0.6356
9280/9968 [==========================>...] - ETA: 0s - loss: 0.6290 - acc: 0.6352
9600/9968 [===========================>..] - ETA: 0s - loss: 0.6287 - acc: 0.6359
9920/9968 [============================>.] - ETA: 0s - loss: 0.6286 - acc: 0.6360
9968/9968 [==============================] - 2s 192us/step - loss: 0.6286 - acc: 0.6364 - val_loss: 0.6224 - val_acc: 0.6525

Epoch 00002: val_acc improved from 0.64621 to 0.65253, saving model to /data/lyli/Silencer/K562/datasets/6924/5fold/model/checkpoints_4layer_100-/DNA_model/model_DNA1.hdf5
Epoch 3/10

  64/9968 [..............................] - ETA: 2s - loss: 0.6019 - acc: 0.6250
 384/9968 [>.............................] - ETA: 1s - loss: 0.6277 - acc: 0.6250
 704/9968 [=>............................] - ETA: 1s - loss: 0.6321 - acc: 0.6108
 960/9968 [=>............................] - ETA: 1s - loss: 0.6309 - acc: 0.6208
1280/9968 [==>...........................] - ETA: 1s - loss: 0.6313 - acc: 0.6250
1600/9968 [===>..........................] - ETA: 1s - loss: 0.6188 - acc: 0.6438
1920/9968 [====>.........................] - ETA: 1s - loss: 0.6136 - acc: 0.6495
2240/9968 [=====>........................] - ETA: 1s - loss: 0.6125 - acc: 0.6522
2560/9968 [======>.......................] - ETA: 1s - loss: 0.6085 - acc: 0.6566
2880/9968 [=======>......................] - ETA: 1s - loss: 0.6108 - acc: 0.6545
3200/9968 [========>.....................] - ETA: 1s - loss: 0.6114 - acc: 0.6531
3520/9968 [=========>....................] - ETA: 1s - loss: 0.6089 - acc: 0.6548
3840/9968 [==========>...................] - ETA: 1s - loss: 0.6101 - acc: 0.6560
4160/9968 [===========>..................] - ETA: 1s - loss: 0.6111 - acc: 0.6558
4480/9968 [============>.................] - ETA: 0s - loss: 0.6111 - acc: 0.6545
4800/9968 [=============>................] - ETA: 0s - loss: 0.6113 - acc: 0.6531
5056/9968 [==============>...............] - ETA: 0s - loss: 0.6120 - acc: 0.6531
5312/9968 [==============>...............] - ETA: 0s - loss: 0.6136 - acc: 0.6519
5632/9968 [===============>..............] - ETA: 0s - loss: 0.6128 - acc: 0.6536
5952/9968 [================>.............] - ETA: 0s - loss: 0.6151 - acc: 0.6494
6272/9968 [=================>............] - ETA: 0s - loss: 0.6149 - acc: 0.6494
6528/9968 [==================>...........] - ETA: 0s - loss: 0.6153 - acc: 0.6481
6848/9968 [===================>..........] - ETA: 0s - loss: 0.6152 - acc: 0.6491
7168/9968 [====================>.........] - ETA: 0s - loss: 0.6163 - acc: 0.6503
7424/9968 [=====================>........] - ETA: 0s - loss: 0.6151 - acc: 0.6518
7744/9968 [======================>.......] - ETA: 0s - loss: 0.6154 - acc: 0.6515
8064/9968 [=======================>......] - ETA: 0s - loss: 0.6142 - acc: 0.6533
8384/9968 [========================>.....] - ETA: 0s - loss: 0.6138 - acc: 0.6555
8704/9968 [=========================>....] - ETA: 0s - loss: 0.6140 - acc: 0.6564
8960/9968 [=========================>....] - ETA: 0s - loss: 0.6146 - acc: 0.6551
9280/9968 [==========================>...] - ETA: 0s - loss: 0.6145 - acc: 0.6548
9600/9968 [===========================>..] - ETA: 0s - loss: 0.6139 - acc: 0.6552
9920/9968 [============================>.] - ETA: 0s - loss: 0.6131 - acc: 0.6560
9968/9968 [==============================] - 2s 189us/step - loss: 0.6132 - acc: 0.6561 - val_loss: 0.6262 - val_acc: 0.6444

Epoch 00003: val_acc did not improve from 0.65253
Epoch 4/10

  64/9968 [..............................] - ETA: 2s - loss: 0.6556 - acc: 0.6562
 384/9968 [>.............................] - ETA: 1s - loss: 0.6088 - acc: 0.6693
 704/9968 [=>............................] - ETA: 1s - loss: 0.6031 - acc: 0.6804
1024/9968 [==>...........................] - ETA: 1s - loss: 0.5960 - acc: 0.6826
1344/9968 [===>..........................] - ETA: 1s - loss: 0.5986 - acc: 0.6860
1664/9968 [====>.........................] - ETA: 1s - loss: 0.6006 - acc: 0.6749
1984/9968 [====>.........................] - ETA: 1s - loss: 0.6094 - acc: 0.6628
2304/9968 [=====>........................] - ETA: 1s - loss: 0.6100 - acc: 0.6636
2560/9968 [======>.......................] - ETA: 1s - loss: 0.6088 - acc: 0.6668
2816/9968 [=======>......................] - ETA: 1s - loss: 0.6081 - acc: 0.6658
3136/9968 [========>.....................] - ETA: 1s - loss: 0.6032 - acc: 0.6709
3456/9968 [=========>....................] - ETA: 1s - loss: 0.6035 - acc: 0.6719
3776/9968 [==========>...................] - ETA: 1s - loss: 0.6042 - acc: 0.6713
4096/9968 [===========>..................] - ETA: 1s - loss: 0.6045 - acc: 0.6702
4416/9968 [============>.................] - ETA: 1s - loss: 0.6058 - acc: 0.6671
4736/9968 [=============>................] - ETA: 0s - loss: 0.6075 - acc: 0.6641
5056/9968 [==============>...............] - ETA: 0s - loss: 0.6088 - acc: 0.6626
5376/9968 [===============>..............] - ETA: 0s - loss: 0.6092 - acc: 0.6587
5696/9968 [================>.............] - ETA: 0s - loss: 0.6084 - acc: 0.6582
5888/9968 [================>.............] - ETA: 0s - loss: 0.6102 - acc: 0.6568
6208/9968 [=================>............] - ETA: 0s - loss: 0.6113 - acc: 0.6559
6528/9968 [==================>...........] - ETA: 0s - loss: 0.6110 - acc: 0.6566
6848/9968 [===================>..........] - ETA: 0s - loss: 0.6127 - acc: 0.6533
7168/9968 [====================>.........] - ETA: 0s - loss: 0.6126 - acc: 0.6535
7488/9968 [=====================>........] - ETA: 0s - loss: 0.6128 - acc: 0.6546
7808/9968 [======================>.......] - ETA: 0s - loss: 0.6109 - acc: 0.6562
8128/9968 [=======================>......] - ETA: 0s - loss: 0.6097 - acc: 0.6569
8448/9968 [========================>.....] - ETA: 0s - loss: 0.6106 - acc: 0.6555
8768/9968 [=========================>....] - ETA: 0s - loss: 0.6117 - acc: 0.6545
9088/9968 [==========================>...] - ETA: 0s - loss: 0.6117 - acc: 0.6556
9344/9968 [===========================>..] - ETA: 0s - loss: 0.6119 - acc: 0.6558
9664/9968 [============================>.] - ETA: 0s - loss: 0.6114 - acc: 0.6570
9968/9968 [==============================] - 2s 190us/step - loss: 0.6120 - acc: 0.6570 - val_loss: 0.6227 - val_acc: 0.6399

Epoch 00004: val_acc did not improve from 0.65253
Epoch 5/10

  64/9968 [..............................] - ETA: 1s - loss: 0.6738 - acc: 0.5781
 384/9968 [>.............................] - ETA: 1s - loss: 0.6422 - acc: 0.6380
 704/9968 [=>............................] - ETA: 1s - loss: 0.6299 - acc: 0.6406
1024/9968 [==>...........................] - ETA: 1s - loss: 0.6084 - acc: 0.6621
1344/9968 [===>..........................] - ETA: 1s - loss: 0.6125 - acc: 0.6577
1664/9968 [====>.........................] - ETA: 1s - loss: 0.6088 - acc: 0.6605
2048/9968 [=====>........................] - ETA: 1s - loss: 0.6038 - acc: 0.6675
2368/9968 [======>.......................] - ETA: 1s - loss: 0.6070 - acc: 0.6643
2624/9968 [======>.......................] - ETA: 1s - loss: 0.6076 - acc: 0.6608
2944/9968 [=======>......................] - ETA: 1s - loss: 0.6083 - acc: 0.6617
3264/9968 [========>.....................] - ETA: 1s - loss: 0.6086 - acc: 0.6636
3584/9968 [=========>....................] - ETA: 1s - loss: 0.6087 - acc: 0.6638
3840/9968 [==========>...................] - ETA: 1s - loss: 0.6086 - acc: 0.6661
4160/9968 [===========>..................] - ETA: 1s - loss: 0.6085 - acc: 0.6642
4416/9968 [============>.................] - ETA: 0s - loss: 0.6072 - acc: 0.6642
4736/9968 [=============>................] - ETA: 0s - loss: 0.6071 - acc: 0.6645
5056/9968 [==============>...............] - ETA: 0s - loss: 0.6072 - acc: 0.6650
5376/9968 [===============>..............] - ETA: 0s - loss: 0.6076 - acc: 0.6631
5696/9968 [================>.............] - ETA: 0s - loss: 0.6085 - acc: 0.6606
6016/9968 [=================>............] - ETA: 0s - loss: 0.6072 - acc: 0.6626
6336/9968 [==================>...........] - ETA: 0s - loss: 0.6063 - acc: 0.6645
6656/9968 [===================>..........] - ETA: 0s - loss: 0.6067 - acc: 0.6629
6912/9968 [===================>..........] - ETA: 0s - loss: 0.6059 - acc: 0.6633
7232/9968 [====================>.........] - ETA: 0s - loss: 0.6054 - acc: 0.6643
7552/9968 [=====================>........] - ETA: 0s - loss: 0.6048 - acc: 0.6653
7872/9968 [======================>.......] - ETA: 0s - loss: 0.6036 - acc: 0.6664
8192/9968 [=======================>......] - ETA: 0s - loss: 0.6019 - acc: 0.6678
8448/9968 [========================>.....] - ETA: 0s - loss: 0.6024 - acc: 0.6687
8768/9968 [=========================>....] - ETA: 0s - loss: 0.6029 - acc: 0.6671
9088/9968 [==========================>...] - ETA: 0s - loss: 0.6031 - acc: 0.6674
9408/9968 [===========================>..] - ETA: 0s - loss: 0.6034 - acc: 0.6674
9664/9968 [============================>.] - ETA: 0s - loss: 0.6036 - acc: 0.6670
9968/9968 [==============================] - 2s 188us/step - loss: 0.6035 - acc: 0.6672 - val_loss: 0.6178 - val_acc: 0.6471

Epoch 00005: val_acc did not improve from 0.65253
Epoch 6/10

  64/9968 [..............................] - ETA: 2s - loss: 0.5746 - acc: 0.7031
 320/9968 [..............................] - ETA: 1s - loss: 0.5736 - acc: 0.6750
 640/9968 [>.............................] - ETA: 1s - loss: 0.5746 - acc: 0.6922
 960/9968 [=>............................] - ETA: 1s - loss: 0.5733 - acc: 0.6958
1280/9968 [==>...........................] - ETA: 1s - loss: 0.5791 - acc: 0.6922
1600/9968 [===>..........................] - ETA: 1s - loss: 0.5912 - acc: 0.6837
1856/9968 [====>.........................] - ETA: 1s - loss: 0.5934 - acc: 0.6832
2176/9968 [=====>........................] - ETA: 1s - loss: 0.5949 - acc: 0.6806
2496/9968 [======>.......................] - ETA: 1s - loss: 0.5924 - acc: 0.6835
2816/9968 [=======>......................] - ETA: 1s - loss: 0.5960 - acc: 0.6786
3136/9968 [========>.....................] - ETA: 1s - loss: 0.5983 - acc: 0.6751
3456/9968 [=========>....................] - ETA: 1s - loss: 0.5978 - acc: 0.6739
3776/9968 [==========>...................] - ETA: 1s - loss: 0.5982 - acc: 0.6745
4032/9968 [===========>..................] - ETA: 1s - loss: 0.5965 - acc: 0.6771
4352/9968 [============>.................] - ETA: 1s - loss: 0.5957 - acc: 0.6778
4672/9968 [=============>................] - ETA: 0s - loss: 0.5967 - acc: 0.6783
4992/9968 [==============>...............] - ETA: 0s - loss: 0.5972 - acc: 0.6781
5312/9968 [==============>...............] - ETA: 0s - loss: 0.5959 - acc: 0.6805
5632/9968 [===============>..............] - ETA: 0s - loss: 0.5985 - acc: 0.6768
5952/9968 [================>.............] - ETA: 0s - loss: 0.5975 - acc: 0.6762
6272/9968 [=================>............] - ETA: 0s - loss: 0.5972 - acc: 0.6781
6592/9968 [==================>...........] - ETA: 0s - loss: 0.5963 - acc: 0.6782
6912/9968 [===================>..........] - ETA: 0s - loss: 0.5956 - acc: 0.6782
7232/9968 [====================>.........] - ETA: 0s - loss: 0.5948 - acc: 0.6782
7552/9968 [=====================>........] - ETA: 0s - loss: 0.5941 - acc: 0.6781
7872/9968 [======================>.......] - ETA: 0s - loss: 0.5936 - acc: 0.6789
8192/9968 [=======================>......] - ETA: 0s - loss: 0.5936 - acc: 0.6785
8576/9968 [========================>.....] - ETA: 0s - loss: 0.5938 - acc: 0.6771
8960/9968 [=========================>....] - ETA: 0s - loss: 0.5940 - acc: 0.6757
9280/9968 [==========================>...] - ETA: 0s - loss: 0.5968 - acc: 0.6730
9600/9968 [===========================>..] - ETA: 0s - loss: 0.5976 - acc: 0.6723
9856/9968 [============================>.] - ETA: 0s - loss: 0.5984 - acc: 0.6719
9968/9968 [==============================] - 2s 186us/step - loss: 0.5986 - acc: 0.6717 - val_loss: 0.6265 - val_acc: 0.6525

Epoch 00006: val_acc did not improve from 0.65253
Epoch 7/10

  64/9968 [..............................] - ETA: 2s - loss: 0.6007 - acc: 0.6250
 384/9968 [>.............................] - ETA: 1s - loss: 0.5786 - acc: 0.6797
 704/9968 [=>............................] - ETA: 1s - loss: 0.5798 - acc: 0.6861
1024/9968 [==>...........................] - ETA: 1s - loss: 0.5952 - acc: 0.6641
1344/9968 [===>..........................] - ETA: 1s - loss: 0.5943 - acc: 0.6607
1664/9968 [====>.........................] - ETA: 1s - loss: 0.5940 - acc: 0.6671
1920/9968 [====>.........................] - ETA: 1s - loss: 0.5976 - acc: 0.6625
2176/9968 [=====>........................] - ETA: 1s - loss: 0.5936 - acc: 0.6645
2496/9968 [======>.......................] - ETA: 1s - loss: 0.5969 - acc: 0.6675
2816/9968 [=======>......................] - ETA: 1s - loss: 0.5956 - acc: 0.6705
3136/9968 [========>.....................] - ETA: 1s - loss: 0.5949 - acc: 0.6728
3456/9968 [=========>....................] - ETA: 1s - loss: 0.5967 - acc: 0.6742
3776/9968 [==========>...................] - ETA: 1s - loss: 0.5953 - acc: 0.6758
4096/9968 [===========>..................] - ETA: 1s - loss: 0.5953 - acc: 0.6760
4416/9968 [============>.................] - ETA: 0s - loss: 0.5946 - acc: 0.6771
4736/9968 [=============>................] - ETA: 0s - loss: 0.5946 - acc: 0.6765
5056/9968 [==============>...............] - ETA: 0s - loss: 0.5944 - acc: 0.6764
5376/9968 [===============>..............] - ETA: 0s - loss: 0.5941 - acc: 0.6765
5696/9968 [================>.............] - ETA: 0s - loss: 0.5941 - acc: 0.6754
6016/9968 [=================>............] - ETA: 0s - loss: 0.5948 - acc: 0.6749
6336/9968 [==================>...........] - ETA: 0s - loss: 0.5977 - acc: 0.6716
6592/9968 [==================>...........] - ETA: 0s - loss: 0.5991 - acc: 0.6707
6912/9968 [===================>..........] - ETA: 0s - loss: 0.5995 - acc: 0.6709
7168/9968 [====================>.........] - ETA: 0s - loss: 0.5986 - acc: 0.6712
7488/9968 [=====================>........] - ETA: 0s - loss: 0.5971 - acc: 0.6739
7808/9968 [======================>.......] - ETA: 0s - loss: 0.5966 - acc: 0.6738
8128/9968 [=======================>......] - ETA: 0s - loss: 0.5969 - acc: 0.6734
8448/9968 [========================>.....] - ETA: 0s - loss: 0.5972 - acc: 0.6732
8704/9968 [=========================>....] - ETA: 0s - loss: 0.5976 - acc: 0.6723
9024/9968 [==========================>...] - ETA: 0s - loss: 0.5963 - acc: 0.6739
9344/9968 [===========================>..] - ETA: 0s - loss: 0.5962 - acc: 0.6742
9664/9968 [============================>.] - ETA: 0s - loss: 0.5968 - acc: 0.6733
9968/9968 [==============================] - 2s 187us/step - loss: 0.5968 - acc: 0.6736 - val_loss: 0.6167 - val_acc: 0.6327

Epoch 00007: val_acc did not improve from 0.65253
Epoch 8/10

  64/9968 [..............................] - ETA: 1s - loss: 0.5890 - acc: 0.6562
 384/9968 [>.............................] - ETA: 1s - loss: 0.6121 - acc: 0.6771
 704/9968 [=>............................] - ETA: 1s - loss: 0.5979 - acc: 0.6790
1024/9968 [==>...........................] - ETA: 1s - loss: 0.6134 - acc: 0.6650
1344/9968 [===>..........................] - ETA: 1s - loss: 0.6063 - acc: 0.6756
1664/9968 [====>.........................] - ETA: 1s - loss: 0.5993 - acc: 0.6791
1984/9968 [====>.........................] - ETA: 1s - loss: 0.5963 - acc: 0.6835
2240/9968 [=====>........................] - ETA: 1s - loss: 0.5986 - acc: 0.6772
2560/9968 [======>.......................] - ETA: 1s - loss: 0.5994 - acc: 0.6742
2880/9968 [=======>......................] - ETA: 1s - loss: 0.5987 - acc: 0.6743
3200/9968 [========>.....................] - ETA: 1s - loss: 0.5985 - acc: 0.6728
3520/9968 [=========>....................] - ETA: 1s - loss: 0.5987 - acc: 0.6710
3840/9968 [==========>...................] - ETA: 1s - loss: 0.5945 - acc: 0.6742
4160/9968 [===========>..................] - ETA: 1s - loss: 0.5899 - acc: 0.6772
4480/9968 [============>.................] - ETA: 0s - loss: 0.5895 - acc: 0.6786
4800/9968 [=============>................] - ETA: 0s - loss: 0.5926 - acc: 0.6740
5120/9968 [==============>...............] - ETA: 0s - loss: 0.5932 - acc: 0.6750
5440/9968 [===============>..............] - ETA: 0s - loss: 0.5935 - acc: 0.6750
5760/9968 [================>.............] - ETA: 0s - loss: 0.5928 - acc: 0.6757
6080/9968 [=================>............] - ETA: 0s - loss: 0.5931 - acc: 0.6755
6336/9968 [==================>...........] - ETA: 0s - loss: 0.5931 - acc: 0.6758
6656/9968 [===================>..........] - ETA: 0s - loss: 0.5948 - acc: 0.6743
6976/9968 [===================>..........] - ETA: 0s - loss: 0.5943 - acc: 0.6739
7296/9968 [====================>.........] - ETA: 0s - loss: 0.5946 - acc: 0.6735
7616/9968 [=====================>........] - ETA: 0s - loss: 0.5947 - acc: 0.6724
7936/9968 [======================>.......] - ETA: 0s - loss: 0.5934 - acc: 0.6736
8256/9968 [=======================>......] - ETA: 0s - loss: 0.5923 - acc: 0.6738
8576/9968 [========================>.....] - ETA: 0s - loss: 0.5939 - acc: 0.6735
8896/9968 [=========================>....] - ETA: 0s - loss: 0.5942 - acc: 0.6739
9216/9968 [==========================>...] - ETA: 0s - loss: 0.5946 - acc: 0.6735
9536/9968 [===========================>..] - ETA: 0s - loss: 0.5953 - acc: 0.6728
9856/9968 [============================>.] - ETA: 0s - loss: 0.5942 - acc: 0.6740
9968/9968 [==============================] - 2s 183us/step - loss: 0.5942 - acc: 0.6741 - val_loss: 0.6173 - val_acc: 0.6543

Epoch 00008: val_acc improved from 0.65253 to 0.65433, saving model to /data/lyli/Silencer/K562/datasets/6924/5fold/model/checkpoints_4layer_100-/DNA_model/model_DNA1.hdf5
Epoch 9/10

  64/9968 [..............................] - ETA: 1s - loss: 0.5585 - acc: 0.7031
 384/9968 [>.............................] - ETA: 1s - loss: 0.5610 - acc: 0.6849
 704/9968 [=>............................] - ETA: 1s - loss: 0.5888 - acc: 0.6875
1024/9968 [==>...........................] - ETA: 1s - loss: 0.5966 - acc: 0.6689
1344/9968 [===>..........................] - ETA: 1s - loss: 0.6026 - acc: 0.6600
1664/9968 [====>.........................] - ETA: 1s - loss: 0.6041 - acc: 0.6575
1984/9968 [====>.........................] - ETA: 1s - loss: 0.5996 - acc: 0.6648
2304/9968 [=====>........................] - ETA: 1s - loss: 0.6010 - acc: 0.6641
2624/9968 [======>.......................] - ETA: 1s - loss: 0.5956 - acc: 0.6726
3008/9968 [========>.....................] - ETA: 1s - loss: 0.5989 - acc: 0.6699
3328/9968 [=========>....................] - ETA: 1s - loss: 0.6005 - acc: 0.6677
3648/9968 [=========>....................] - ETA: 1s - loss: 0.6005 - acc: 0.6694
3968/9968 [==========>...................] - ETA: 1s - loss: 0.6020 - acc: 0.6696
4288/9968 [===========>..................] - ETA: 0s - loss: 0.5989 - acc: 0.6737
4608/9968 [============>.................] - ETA: 0s - loss: 0.5989 - acc: 0.6736
4928/9968 [=============>................] - ETA: 0s - loss: 0.5959 - acc: 0.6759
5248/9968 [==============>...............] - ETA: 0s - loss: 0.5951 - acc: 0.6764
5568/9968 [===============>..............] - ETA: 0s - loss: 0.5942 - acc: 0.6751
5888/9968 [================>.............] - ETA: 0s - loss: 0.5939 - acc: 0.6761
6208/9968 [=================>............] - ETA: 0s - loss: 0.5939 - acc: 0.6759
6528/9968 [==================>...........] - ETA: 0s - loss: 0.5934 - acc: 0.6765
6912/9968 [===================>..........] - ETA: 0s - loss: 0.5925 - acc: 0.6764
7232/9968 [====================>.........] - ETA: 0s - loss: 0.5923 - acc: 0.6756
7552/9968 [=====================>........] - ETA: 0s - loss: 0.5929 - acc: 0.6752
7872/9968 [======================>.......] - ETA: 0s - loss: 0.5928 - acc: 0.6738
8192/9968 [=======================>......] - ETA: 0s - loss: 0.5927 - acc: 0.6735
8512/9968 [========================>.....] - ETA: 0s - loss: 0.5924 - acc: 0.6734
8832/9968 [=========================>....] - ETA: 0s - loss: 0.5917 - acc: 0.6752
9152/9968 [==========================>...] - ETA: 0s - loss: 0.5927 - acc: 0.6748
9472/9968 [===========================>..] - ETA: 0s - loss: 0.5919 - acc: 0.6751
9792/9968 [============================>.] - ETA: 0s - loss: 0.5915 - acc: 0.6754
9968/9968 [==============================] - 2s 180us/step - loss: 0.5920 - acc: 0.6752 - val_loss: 0.6148 - val_acc: 0.6309

Epoch 00009: val_acc did not improve from 0.65433
Epoch 10/10

  64/9968 [..............................] - ETA: 2s - loss: 0.4942 - acc: 0.8281
 384/9968 [>.............................] - ETA: 1s - loss: 0.5384 - acc: 0.7552
 704/9968 [=>............................] - ETA: 1s - loss: 0.5585 - acc: 0.7259
1024/9968 [==>...........................] - ETA: 1s - loss: 0.5579 - acc: 0.7246
1344/9968 [===>..........................] - ETA: 1s - loss: 0.5844 - acc: 0.7031
1664/9968 [====>.........................] - ETA: 1s - loss: 0.5848 - acc: 0.7001
1984/9968 [====>.........................] - ETA: 1s - loss: 0.5799 - acc: 0.7087
2304/9968 [=====>........................] - ETA: 1s - loss: 0.5776 - acc: 0.7083
2624/9968 [======>.......................] - ETA: 1s - loss: 0.5781 - acc: 0.7077
2944/9968 [=======>......................] - ETA: 1s - loss: 0.5765 - acc: 0.7069
3264/9968 [========>.....................] - ETA: 1s - loss: 0.5759 - acc: 0.7059
3584/9968 [=========>....................] - ETA: 1s - loss: 0.5766 - acc: 0.7040
3904/9968 [==========>...................] - ETA: 1s - loss: 0.5764 - acc: 0.7003
4160/9968 [===========>..................] - ETA: 1s - loss: 0.5787 - acc: 0.6964
4480/9968 [============>.................] - ETA: 0s - loss: 0.5790 - acc: 0.6937
4800/9968 [=============>................] - ETA: 0s - loss: 0.5809 - acc: 0.6915
5120/9968 [==============>...............] - ETA: 0s - loss: 0.5823 - acc: 0.6896
5440/9968 [===============>..............] - ETA: 0s - loss: 0.5802 - acc: 0.6912
5760/9968 [================>.............] - ETA: 0s - loss: 0.5795 - acc: 0.6905
6080/9968 [=================>............] - ETA: 0s - loss: 0.5798 - acc: 0.6906
6400/9968 [==================>...........] - ETA: 0s - loss: 0.5810 - acc: 0.6880
6720/9968 [===================>..........] - ETA: 0s - loss: 0.5834 - acc: 0.6866
7040/9968 [====================>.........] - ETA: 0s - loss: 0.5837 - acc: 0.6872
7360/9968 [=====================>........] - ETA: 0s - loss: 0.5848 - acc: 0.6859
7680/9968 [======================>.......] - ETA: 0s - loss: 0.5863 - acc: 0.6852
8000/9968 [=======================>......] - ETA: 0s - loss: 0.5844 - acc: 0.6880
8320/9968 [========================>.....] - ETA: 0s - loss: 0.5841 - acc: 0.6880
8640/9968 [=========================>....] - ETA: 0s - loss: 0.5849 - acc: 0.6869
8960/9968 [=========================>....] - ETA: 0s - loss: 0.5836 - acc: 0.6874
9280/9968 [==========================>...] - ETA: 0s - loss: 0.5842 - acc: 0.6861
9600/9968 [===========================>..] - ETA: 0s - loss: 0.5841 - acc: 0.6863
9920/9968 [============================>.] - ETA: 0s - loss: 0.5846 - acc: 0.6857
9968/9968 [==============================] - 2s 184us/step - loss: 0.5847 - acc: 0.6855 - val_loss: 0.6180 - val_acc: 0.6417

Epoch 00010: val_acc did not improve from 0.65433
Saved model to disk
ACC: 0.645592485549133
Sens: 0.6883586406362979
Spec: 0.6028880866425993
MCC: 0.2923110355616026
ROC_AUC: 0.7053238003503084
PRC_ROC: 0.6984164594899155
WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.
/data/lyli/Silencer/K562/datasets/6924/5fold/model/checkpoints_4layer_100-/Model_CNN.py:33: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[input_seq], output=[pred_output])
Fitting first model...
Train on 9969 samples, validate on 1108 samples
Epoch 1/10

  64/9969 [..............................] - ETA: 1:30 - loss: 0.6941 - acc: 0.5469
 320/9969 [..............................] - ETA: 19s - loss: 0.6835 - acc: 0.5750 
 576/9969 [>.............................] - ETA: 11s - loss: 0.6970 - acc: 0.5382
 896/9969 [=>............................] - ETA: 7s - loss: 0.6935 - acc: 0.5502 
1216/9969 [==>...........................] - ETA: 5s - loss: 0.6914 - acc: 0.5510
1472/9969 [===>..........................] - ETA: 4s - loss: 0.6888 - acc: 0.5577
1792/9969 [====>.........................] - ETA: 4s - loss: 0.6871 - acc: 0.5631
2112/9969 [=====>........................] - ETA: 3s - loss: 0.6842 - acc: 0.5653
2432/9969 [======>.......................] - ETA: 3s - loss: 0.6822 - acc: 0.5674
2688/9969 [=======>......................] - ETA: 2s - loss: 0.6804 - acc: 0.5703
3008/9969 [========>.....................] - ETA: 2s - loss: 0.6756 - acc: 0.5735
3328/9969 [=========>....................] - ETA: 2s - loss: 0.6726 - acc: 0.5760
3648/9969 [=========>....................] - ETA: 2s - loss: 0.6723 - acc: 0.5787
3904/9969 [==========>...................] - ETA: 2s - loss: 0.6719 - acc: 0.5789
4224/9969 [===========>..................] - ETA: 1s - loss: 0.6710 - acc: 0.5793
4544/9969 [============>.................] - ETA: 1s - loss: 0.6699 - acc: 0.5805
4864/9969 [=============>................] - ETA: 1s - loss: 0.6697 - acc: 0.5796
5184/9969 [==============>...............] - ETA: 1s - loss: 0.6692 - acc: 0.5795
5504/9969 [===============>..............] - ETA: 1s - loss: 0.6688 - acc: 0.5801
5760/9969 [================>.............] - ETA: 1s - loss: 0.6671 - acc: 0.5816
6016/9969 [=================>............] - ETA: 1s - loss: 0.6663 - acc: 0.5813
6336/9969 [==================>...........] - ETA: 1s - loss: 0.6644 - acc: 0.5825
6656/9969 [===================>..........] - ETA: 0s - loss: 0.6628 - acc: 0.5855
6976/9969 [===================>..........] - ETA: 0s - loss: 0.6603 - acc: 0.5896
7296/9969 [====================>.........] - ETA: 0s - loss: 0.6610 - acc: 0.5896
7552/9969 [=====================>........] - ETA: 0s - loss: 0.6606 - acc: 0.5896
7872/9969 [======================>.......] - ETA: 0s - loss: 0.6597 - acc: 0.5917
8192/9969 [=======================>......] - ETA: 0s - loss: 0.6577 - acc: 0.5951
8512/9969 [========================>.....] - ETA: 0s - loss: 0.6589 - acc: 0.5950
8768/9969 [=========================>....] - ETA: 0s - loss: 0.6581 - acc: 0.5958
9088/9969 [==========================>...] - ETA: 0s - loss: 0.6589 - acc: 0.5950
9408/9969 [===========================>..] - ETA: 0s - loss: 0.6587 - acc: 0.5952
9728/9969 [============================>.] - ETA: 0s - loss: 0.6585 - acc: 0.5961
9969/9969 [==============================] - 3s 255us/step - loss: 0.6575 - acc: 0.5978 - val_loss: 0.6318 - val_acc: 0.6255

Epoch 00001: val_acc improved from -inf to 0.62545, saving model to /data/lyli/Silencer/K562/datasets/6924/5fold/model/checkpoints_4layer_100-/DNA_model/model_DNA2.hdf5
Epoch 2/10

  64/9969 [..............................] - ETA: 1s - loss: 0.6629 - acc: 0.6094
 384/9969 [>.............................] - ETA: 1s - loss: 0.6327 - acc: 0.6302
 704/9969 [=>............................] - ETA: 1s - loss: 0.6298 - acc: 0.6392
1024/9969 [==>...........................] - ETA: 1s - loss: 0.6208 - acc: 0.6533
1344/9969 [===>..........................] - ETA: 1s - loss: 0.6317 - acc: 0.6481
1664/9969 [====>.........................] - ETA: 1s - loss: 0.6375 - acc: 0.6376
1984/9969 [====>.........................] - ETA: 1s - loss: 0.6446 - acc: 0.6265
2304/9969 [=====>........................] - ETA: 1s - loss: 0.6464 - acc: 0.6276
2624/9969 [======>.......................] - ETA: 1s - loss: 0.6465 - acc: 0.6277
2944/9969 [=======>......................] - ETA: 1s - loss: 0.6454 - acc: 0.6253
3264/9969 [========>.....................] - ETA: 1s - loss: 0.6469 - acc: 0.6244
3584/9969 [=========>....................] - ETA: 1s - loss: 0.6449 - acc: 0.6236
3904/9969 [==========>...................] - ETA: 1s - loss: 0.6432 - acc: 0.6270
4224/9969 [===========>..................] - ETA: 0s - loss: 0.6425 - acc: 0.6286
4608/9969 [============>.................] - ETA: 0s - loss: 0.6411 - acc: 0.6293
4928/9969 [=============>................] - ETA: 0s - loss: 0.6399 - acc: 0.6293
5248/9969 [==============>...............] - ETA: 0s - loss: 0.6370 - acc: 0.6334
5632/9969 [===============>..............] - ETA: 0s - loss: 0.6395 - acc: 0.6319
5952/9969 [================>.............] - ETA: 0s - loss: 0.6388 - acc: 0.6339
6272/9969 [=================>............] - ETA: 0s - loss: 0.6401 - acc: 0.6312
6592/9969 [==================>...........] - ETA: 0s - loss: 0.6392 - acc: 0.6320
6912/9969 [===================>..........] - ETA: 0s - loss: 0.6384 - acc: 0.6318
7232/9969 [====================>.........] - ETA: 0s - loss: 0.6395 - acc: 0.6304
7552/9969 [=====================>........] - ETA: 0s - loss: 0.6378 - acc: 0.6316
7872/9969 [======================>.......] - ETA: 0s - loss: 0.6375 - acc: 0.6327
8192/9969 [=======================>......] - ETA: 0s - loss: 0.6374 - acc: 0.6324
8512/9969 [========================>.....] - ETA: 0s - loss: 0.6368 - acc: 0.6329
8832/9969 [=========================>....] - ETA: 0s - loss: 0.6362 - acc: 0.6317
9152/9969 [==========================>...] - ETA: 0s - loss: 0.6362 - acc: 0.6318
9472/9969 [===========================>..] - ETA: 0s - loss: 0.6364 - acc: 0.6308
9792/9969 [============================>.] - ETA: 0s - loss: 0.6356 - acc: 0.6318
9969/9969 [==============================] - 2s 173us/step - loss: 0.6349 - acc: 0.6326 - val_loss: 0.6189 - val_acc: 0.6435

Epoch 00002: val_acc improved from 0.62545 to 0.64350, saving model to /data/lyli/Silencer/K562/datasets/6924/5fold/model/checkpoints_4layer_100-/DNA_model/model_DNA2.hdf5
Epoch 3/10

  64/9969 [..............................] - ETA: 1s - loss: 0.6144 - acc: 0.6094
 384/9969 [>.............................] - ETA: 1s - loss: 0.6240 - acc: 0.6276
 704/9969 [=>............................] - ETA: 1s - loss: 0.6176 - acc: 0.6378
1024/9969 [==>...........................] - ETA: 1s - loss: 0.6176 - acc: 0.6455
1344/9969 [===>..........................] - ETA: 1s - loss: 0.6123 - acc: 0.6488
1664/9969 [====>.........................] - ETA: 1s - loss: 0.6139 - acc: 0.6466
1984/9969 [====>.........................] - ETA: 1s - loss: 0.6151 - acc: 0.6472
2304/9969 [=====>........................] - ETA: 1s - loss: 0.6168 - acc: 0.6419
2624/9969 [======>.......................] - ETA: 1s - loss: 0.6151 - acc: 0.6490
2944/9969 [=======>......................] - ETA: 1s - loss: 0.6168 - acc: 0.6515
3328/9969 [=========>....................] - ETA: 1s - loss: 0.6211 - acc: 0.6493
3648/9969 [=========>....................] - ETA: 1s - loss: 0.6222 - acc: 0.6478
3968/9969 [==========>...................] - ETA: 0s - loss: 0.6241 - acc: 0.6464
4288/9969 [===========>..................] - ETA: 0s - loss: 0.6261 - acc: 0.6465
4608/9969 [============>.................] - ETA: 0s - loss: 0.6273 - acc: 0.6450
4928/9969 [=============>................] - ETA: 0s - loss: 0.6282 - acc: 0.6445
5248/9969 [==============>...............] - ETA: 0s - loss: 0.6262 - acc: 0.6477
5568/9969 [===============>..............] - ETA: 0s - loss: 0.6259 - acc: 0.6467
5888/9969 [================>.............] - ETA: 0s - loss: 0.6282 - acc: 0.6450
6208/9969 [=================>............] - ETA: 0s - loss: 0.6281 - acc: 0.6430
6528/9969 [==================>...........] - ETA: 0s - loss: 0.6276 - acc: 0.6441
6912/9969 [===================>..........] - ETA: 0s - loss: 0.6276 - acc: 0.6432
7296/9969 [====================>.........] - ETA: 0s - loss: 0.6279 - acc: 0.6428
7616/9969 [=====================>........] - ETA: 0s - loss: 0.6260 - acc: 0.6440
7936/9969 [======================>.......] - ETA: 0s - loss: 0.6268 - acc: 0.6430
8256/9969 [=======================>......] - ETA: 0s - loss: 0.6265 - acc: 0.6437
8576/9969 [========================>.....] - ETA: 0s - loss: 0.6268 - acc: 0.6428
8896/9969 [=========================>....] - ETA: 0s - loss: 0.6266 - acc: 0.6440
9152/9969 [==========================>...] - ETA: 0s - loss: 0.6255 - acc: 0.6454
9472/9969 [===========================>..] - ETA: 0s - loss: 0.6253 - acc: 0.6459
9792/9969 [============================>.] - ETA: 0s - loss: 0.6252 - acc: 0.6469
9969/9969 [==============================] - 2s 172us/step - loss: 0.6255 - acc: 0.6465 - val_loss: 0.6356 - val_acc: 0.6417

Epoch 00003: val_acc did not improve from 0.64350
Epoch 4/10

  64/9969 [..............................] - ETA: 1s - loss: 0.5575 - acc: 0.6875
 384/9969 [>.............................] - ETA: 1s - loss: 0.6056 - acc: 0.6589
 704/9969 [=>............................] - ETA: 1s - loss: 0.6247 - acc: 0.6435
1024/9969 [==>...........................] - ETA: 1s - loss: 0.6146 - acc: 0.6582
1408/9969 [===>..........................] - ETA: 1s - loss: 0.6076 - acc: 0.6683
1792/9969 [====>.........................] - ETA: 1s - loss: 0.6040 - acc: 0.6696
2112/9969 [=====>........................] - ETA: 1s - loss: 0.6021 - acc: 0.6690
2432/9969 [======>.......................] - ETA: 1s - loss: 0.6137 - acc: 0.6579
2752/9969 [=======>......................] - ETA: 1s - loss: 0.6147 - acc: 0.6552
3136/9969 [========>.....................] - ETA: 1s - loss: 0.6198 - acc: 0.6540
3392/9969 [=========>....................] - ETA: 1s - loss: 0.6219 - acc: 0.6515
3776/9969 [==========>...................] - ETA: 0s - loss: 0.6210 - acc: 0.6531
4160/9969 [===========>..................] - ETA: 0s - loss: 0.6192 - acc: 0.6541
4480/9969 [============>.................] - ETA: 0s - loss: 0.6220 - acc: 0.6518
4800/9969 [=============>................] - ETA: 0s - loss: 0.6198 - acc: 0.6546
5120/9969 [==============>...............] - ETA: 0s - loss: 0.6187 - acc: 0.6547
5504/9969 [===============>..............] - ETA: 0s - loss: 0.6197 - acc: 0.6530
5888/9969 [================>.............] - ETA: 0s - loss: 0.6214 - acc: 0.6513
6144/9969 [=================>............] - ETA: 0s - loss: 0.6206 - acc: 0.6519
6464/9969 [==================>...........] - ETA: 0s - loss: 0.6201 - acc: 0.6522
6784/9969 [===================>..........] - ETA: 0s - loss: 0.6211 - acc: 0.6517
7104/9969 [====================>.........] - ETA: 0s - loss: 0.6206 - acc: 0.6515
7360/9969 [=====================>........] - ETA: 0s - loss: 0.6207 - acc: 0.6512
7680/9969 [======================>.......] - ETA: 0s - loss: 0.6204 - acc: 0.6521
8000/9969 [=======================>......] - ETA: 0s - loss: 0.6192 - acc: 0.6538
8320/9969 [========================>.....] - ETA: 0s - loss: 0.6195 - acc: 0.6532
8640/9969 [=========================>....] - ETA: 0s - loss: 0.6199 - acc: 0.6539
8960/9969 [=========================>....] - ETA: 0s - loss: 0.6203 - acc: 0.6535
9280/9969 [==========================>...] - ETA: 0s - loss: 0.6203 - acc: 0.6537
9600/9969 [===========================>..] - ETA: 0s - loss: 0.6195 - acc: 0.6558
9920/9969 [============================>.] - ETA: 0s - loss: 0.6192 - acc: 0.6561
9969/9969 [==============================] - 2s 176us/step - loss: 0.6199 - acc: 0.6556 - val_loss: 0.6724 - val_acc: 0.5984

Epoch 00004: val_acc did not improve from 0.64350
Epoch 5/10

  64/9969 [..............................] - ETA: 1s - loss: 0.6044 - acc: 0.7031
 320/9969 [..............................] - ETA: 1s - loss: 0.6533 - acc: 0.6312
 640/9969 [>.............................] - ETA: 1s - loss: 0.6458 - acc: 0.6125
 960/9969 [=>............................] - ETA: 1s - loss: 0.6455 - acc: 0.6073
1280/9969 [==>...........................] - ETA: 1s - loss: 0.6494 - acc: 0.6078
1600/9969 [===>..........................] - ETA: 1s - loss: 0.6434 - acc: 0.6144
1920/9969 [====>.........................] - ETA: 1s - loss: 0.6433 - acc: 0.6120
2176/9969 [=====>........................] - ETA: 1s - loss: 0.6412 - acc: 0.6117
2496/9969 [======>.......................] - ETA: 1s - loss: 0.6402 - acc: 0.6134
2816/9969 [=======>......................] - ETA: 1s - loss: 0.6363 - acc: 0.6211
3136/9969 [========>.....................] - ETA: 1s - loss: 0.6312 - acc: 0.6247
3456/9969 [=========>....................] - ETA: 1s - loss: 0.6287 - acc: 0.6308
3776/9969 [==========>...................] - ETA: 1s - loss: 0.6300 - acc: 0.6303
4096/9969 [===========>..................] - ETA: 1s - loss: 0.6289 - acc: 0.6343
4416/9969 [============>.................] - ETA: 0s - loss: 0.6280 - acc: 0.6356
4736/9969 [=============>................] - ETA: 0s - loss: 0.6241 - acc: 0.6398
4928/9969 [=============>................] - ETA: 0s - loss: 0.6239 - acc: 0.6404
5248/9969 [==============>...............] - ETA: 0s - loss: 0.6231 - acc: 0.6429
5568/9969 [===============>..............] - ETA: 0s - loss: 0.6212 - acc: 0.6444
5824/9969 [================>.............] - ETA: 0s - loss: 0.6211 - acc: 0.6458
6144/9969 [=================>............] - ETA: 0s - loss: 0.6204 - acc: 0.6455
6464/9969 [==================>...........] - ETA: 0s - loss: 0.6202 - acc: 0.6456
6720/9969 [===================>..........] - ETA: 0s - loss: 0.6203 - acc: 0.6455
7040/9969 [====================>.........] - ETA: 0s - loss: 0.6202 - acc: 0.6462
7360/9969 [=====================>........] - ETA: 0s - loss: 0.6214 - acc: 0.6463
7680/9969 [======================>.......] - ETA: 0s - loss: 0.6218 - acc: 0.6443
8000/9969 [=======================>......] - ETA: 0s - loss: 0.6210 - acc: 0.6454
8320/9969 [========================>.....] - ETA: 0s - loss: 0.6202 - acc: 0.6460
8640/9969 [=========================>....] - ETA: 0s - loss: 0.6186 - acc: 0.6477
8960/9969 [=========================>....] - ETA: 0s - loss: 0.6190 - acc: 0.6477
9280/9969 [==========================>...] - ETA: 0s - loss: 0.6185 - acc: 0.6482
9536/9969 [===========================>..] - ETA: 0s - loss: 0.6193 - acc: 0.6470
9856/9969 [============================>.] - ETA: 0s - loss: 0.6188 - acc: 0.6478
9969/9969 [==============================] - 2s 190us/step - loss: 0.6192 - acc: 0.6475 - val_loss: 0.6143 - val_acc: 0.6543

Epoch 00005: val_acc improved from 0.64350 to 0.65433, saving model to /data/lyli/Silencer/K562/datasets/6924/5fold/model/checkpoints_4layer_100-/DNA_model/model_DNA2.hdf5
Epoch 6/10

  64/9969 [..............................] - ETA: 1s - loss: 0.5623 - acc: 0.7344
 320/9969 [..............................] - ETA: 1s - loss: 0.5772 - acc: 0.6906
 704/9969 [=>............................] - ETA: 1s - loss: 0.6108 - acc: 0.6634
1024/9969 [==>...........................] - ETA: 1s - loss: 0.6144 - acc: 0.6572
1344/9969 [===>..........................] - ETA: 1s - loss: 0.6158 - acc: 0.6473
1600/9969 [===>..........................] - ETA: 1s - loss: 0.6198 - acc: 0.6475
1920/9969 [====>.........................] - ETA: 1s - loss: 0.6169 - acc: 0.6484
2240/9969 [=====>........................] - ETA: 1s - loss: 0.6152 - acc: 0.6500
2560/9969 [======>.......................] - ETA: 1s - loss: 0.6096 - acc: 0.6516
2880/9969 [=======>......................] - ETA: 1s - loss: 0.6120 - acc: 0.6528
3200/9969 [========>.....................] - ETA: 1s - loss: 0.6166 - acc: 0.6484
3520/9969 [=========>....................] - ETA: 1s - loss: 0.6152 - acc: 0.6489
3840/9969 [==========>...................] - ETA: 1s - loss: 0.6161 - acc: 0.6490
4160/9969 [===========>..................] - ETA: 1s - loss: 0.6143 - acc: 0.6514
4480/9969 [============>.................] - ETA: 0s - loss: 0.6150 - acc: 0.6509
4736/9969 [=============>................] - ETA: 0s - loss: 0.6164 - acc: 0.6501
5056/9969 [==============>...............] - ETA: 0s - loss: 0.6167 - acc: 0.6495
5376/9969 [===============>..............] - ETA: 0s - loss: 0.6169 - acc: 0.6505
5696/9969 [================>.............] - ETA: 0s - loss: 0.6168 - acc: 0.6506
6016/9969 [=================>............] - ETA: 0s - loss: 0.6160 - acc: 0.6531
6336/9969 [==================>...........] - ETA: 0s - loss: 0.6154 - acc: 0.6531
6656/9969 [===================>..........] - ETA: 0s - loss: 0.6148 - acc: 0.6526
6976/9969 [===================>..........] - ETA: 0s - loss: 0.6135 - acc: 0.6547
7360/9969 [=====================>........] - ETA: 0s - loss: 0.6142 - acc: 0.6545
7680/9969 [======================>.......] - ETA: 0s - loss: 0.6135 - acc: 0.6556
8000/9969 [=======================>......] - ETA: 0s - loss: 0.6146 - acc: 0.6549
8384/9969 [========================>.....] - ETA: 0s - loss: 0.6142 - acc: 0.6552
8704/9969 [=========================>....] - ETA: 0s - loss: 0.6146 - acc: 0.6552
9024/9969 [==========================>...] - ETA: 0s - loss: 0.6136 - acc: 0.6574
9344/9969 [===========================>..] - ETA: 0s - loss: 0.6127 - acc: 0.6585
9664/9969 [============================>.] - ETA: 0s - loss: 0.6126 - acc: 0.6575
9969/9969 [==============================] - 2s 179us/step - loss: 0.6130 - acc: 0.6587 - val_loss: 0.6201 - val_acc: 0.6390

Epoch 00006: val_acc did not improve from 0.65433
Epoch 7/10

  64/9969 [..............................] - ETA: 1s - loss: 0.6593 - acc: 0.5938
 320/9969 [..............................] - ETA: 1s - loss: 0.6401 - acc: 0.6031
 640/9969 [>.............................] - ETA: 1s - loss: 0.6097 - acc: 0.6594
 896/9969 [=>............................] - ETA: 1s - loss: 0.6108 - acc: 0.6562
1280/9969 [==>...........................] - ETA: 1s - loss: 0.6106 - acc: 0.6586
1600/9969 [===>..........................] - ETA: 1s - loss: 0.6107 - acc: 0.6587
1920/9969 [====>.........................] - ETA: 1s - loss: 0.6120 - acc: 0.6552
2176/9969 [=====>........................] - ETA: 1s - loss: 0.6127 - acc: 0.6572
2432/9969 [======>.......................] - ETA: 1s - loss: 0.6101 - acc: 0.6591
2752/9969 [=======>......................] - ETA: 1s - loss: 0.6120 - acc: 0.6533
3072/9969 [========>.....................] - ETA: 1s - loss: 0.6088 - acc: 0.6566
3328/9969 [=========>....................] - ETA: 1s - loss: 0.6054 - acc: 0.6602
3648/9969 [=========>....................] - ETA: 1s - loss: 0.6071 - acc: 0.6601
3968/9969 [==========>...................] - ETA: 1s - loss: 0.6082 - acc: 0.6618
4288/9969 [===========>..................] - ETA: 1s - loss: 0.6090 - acc: 0.6628
4608/9969 [============>.................] - ETA: 0s - loss: 0.6077 - acc: 0.6641
4928/9969 [=============>................] - ETA: 0s - loss: 0.6063 - acc: 0.6652
5248/9969 [==============>...............] - ETA: 0s - loss: 0.6066 - acc: 0.6650
5632/9969 [===============>..............] - ETA: 0s - loss: 0.6061 - acc: 0.6664
6016/9969 [=================>............] - ETA: 0s - loss: 0.6062 - acc: 0.6662
6400/9969 [==================>...........] - ETA: 0s - loss: 0.6068 - acc: 0.6663
6720/9969 [===================>..........] - ETA: 0s - loss: 0.6062 - acc: 0.6680
7104/9969 [====================>.........] - ETA: 0s - loss: 0.6057 - acc: 0.6684
7424/9969 [=====================>........] - ETA: 0s - loss: 0.6068 - acc: 0.6682
7744/9969 [======================>.......] - ETA: 0s - loss: 0.6068 - acc: 0.6686
8064/9969 [=======================>......] - ETA: 0s - loss: 0.6059 - acc: 0.6700
8384/9969 [========================>.....] - ETA: 0s - loss: 0.6049 - acc: 0.6707
8704/9969 [=========================>....] - ETA: 0s - loss: 0.6044 - acc: 0.6719
9024/9969 [==========================>...] - ETA: 0s - loss: 0.6047 - acc: 0.6720
9344/9969 [===========================>..] - ETA: 0s - loss: 0.6052 - acc: 0.6709
9664/9969 [============================>.] - ETA: 0s - loss: 0.6046 - acc: 0.6720
9969/9969 [==============================] - 2s 182us/step - loss: 0.6042 - acc: 0.6726 - val_loss: 0.6216 - val_acc: 0.6588

Epoch 00007: val_acc improved from 0.65433 to 0.65884, saving model to /data/lyli/Silencer/K562/datasets/6924/5fold/model/checkpoints_4layer_100-/DNA_model/model_DNA2.hdf5
Epoch 8/10

  64/9969 [..............................] - ETA: 1s - loss: 0.6320 - acc: 0.6406
 384/9969 [>.............................] - ETA: 1s - loss: 0.5752 - acc: 0.6797
 768/9969 [=>............................] - ETA: 1s - loss: 0.5832 - acc: 0.6745
1088/9969 [==>...........................] - ETA: 1s - loss: 0.5840 - acc: 0.6792
1408/9969 [===>..........................] - ETA: 1s - loss: 0.5850 - acc: 0.6790
1728/9969 [====>.........................] - ETA: 1s - loss: 0.5906 - acc: 0.6719
2048/9969 [=====>........................] - ETA: 1s - loss: 0.5946 - acc: 0.6689
2368/9969 [======>.......................] - ETA: 1s - loss: 0.5975 - acc: 0.6664
2688/9969 [=======>......................] - ETA: 1s - loss: 0.6035 - acc: 0.6603
3008/9969 [========>.....................] - ETA: 1s - loss: 0.6077 - acc: 0.6582
3264/9969 [========>.....................] - ETA: 1s - loss: 0.6049 - acc: 0.6624
3584/9969 [=========>....................] - ETA: 1s - loss: 0.6031 - acc: 0.6649
3904/9969 [==========>...................] - ETA: 1s - loss: 0.6059 - acc: 0.6621
4224/9969 [===========>..................] - ETA: 1s - loss: 0.6054 - acc: 0.6615
4544/9969 [============>.................] - ETA: 0s - loss: 0.6016 - acc: 0.6655
4800/9969 [=============>................] - ETA: 0s - loss: 0.6015 - acc: 0.6673
5120/9969 [==============>...............] - ETA: 0s - loss: 0.5998 - acc: 0.6687
5440/9969 [===============>..............] - ETA: 0s - loss: 0.6003 - acc: 0.6689
5760/9969 [================>.............] - ETA: 0s - loss: 0.5992 - acc: 0.6707
6080/9969 [=================>............] - ETA: 0s - loss: 0.5994 - acc: 0.6714
6336/9969 [==================>...........] - ETA: 0s - loss: 0.6008 - acc: 0.6690
6656/9969 [===================>..........] - ETA: 0s - loss: 0.6006 - acc: 0.6686
6976/9969 [===================>..........] - ETA: 0s - loss: 0.6004 - acc: 0.6683
7296/9969 [====================>.........] - ETA: 0s - loss: 0.6001 - acc: 0.6695
7552/9969 [=====================>........] - ETA: 0s - loss: 0.6007 - acc: 0.6709
7936/9969 [======================>.......] - ETA: 0s - loss: 0.6010 - acc: 0.6717
8256/9969 [=======================>......] - ETA: 0s - loss: 0.6018 - acc: 0.6721
8576/9969 [========================>.....] - ETA: 0s - loss: 0.6026 - acc: 0.6713
8960/9969 [=========================>....] - ETA: 0s - loss: 0.6030 - acc: 0.6706
9280/9969 [==========================>...] - ETA: 0s - loss: 0.6029 - acc: 0.6696
9600/9969 [===========================>..] - ETA: 0s - loss: 0.6027 - acc: 0.6694
9920/9969 [============================>.] - ETA: 0s - loss: 0.6032 - acc: 0.6694
9969/9969 [==============================] - 2s 188us/step - loss: 0.6033 - acc: 0.6687 - val_loss: 0.6153 - val_acc: 0.6561

Epoch 00008: val_acc did not improve from 0.65884
Epoch 9/10

  64/9969 [..............................] - ETA: 1s - loss: 0.5296 - acc: 0.7188
 384/9969 [>.............................] - ETA: 1s - loss: 0.5982 - acc: 0.6875
 704/9969 [=>............................] - ETA: 1s - loss: 0.6138 - acc: 0.6562
1088/9969 [==>...........................] - ETA: 1s - loss: 0.6122 - acc: 0.6535
1408/9969 [===>..........................] - ETA: 1s - loss: 0.6080 - acc: 0.6612
1664/9969 [====>.........................] - ETA: 1s - loss: 0.6125 - acc: 0.6550
1984/9969 [====>.........................] - ETA: 1s - loss: 0.6137 - acc: 0.6547
2304/9969 [=====>........................] - ETA: 1s - loss: 0.6142 - acc: 0.6576
2624/9969 [======>.......................] - ETA: 1s - loss: 0.6122 - acc: 0.6582
2880/9969 [=======>......................] - ETA: 1s - loss: 0.6117 - acc: 0.6573
3200/9969 [========>.....................] - ETA: 1s - loss: 0.6093 - acc: 0.6600
3520/9969 [=========>....................] - ETA: 1s - loss: 0.6077 - acc: 0.6602
3776/9969 [==========>...................] - ETA: 1s - loss: 0.6014 - acc: 0.6684
4096/9969 [===========>..................] - ETA: 1s - loss: 0.6009 - acc: 0.6667
4352/9969 [============>.................] - ETA: 1s - loss: 0.6036 - acc: 0.6650
4672/9969 [=============>................] - ETA: 0s - loss: 0.6038 - acc: 0.6667
4928/9969 [=============>................] - ETA: 0s - loss: 0.6020 - acc: 0.6705
5184/9969 [==============>...............] - ETA: 0s - loss: 0.6038 - acc: 0.6684
5504/9969 [===============>..............] - ETA: 0s - loss: 0.6047 - acc: 0.6675
5824/9969 [================>.............] - ETA: 0s - loss: 0.6038 - acc: 0.6679
6144/9969 [=================>............] - ETA: 0s - loss: 0.6046 - acc: 0.6660
6464/9969 [==================>...........] - ETA: 0s - loss: 0.6042 - acc: 0.6669
6784/9969 [===================>..........] - ETA: 0s - loss: 0.6033 - acc: 0.6688
7104/9969 [====================>.........] - ETA: 0s - loss: 0.6033 - acc: 0.6685
7424/9969 [=====================>........] - ETA: 0s - loss: 0.6039 - acc: 0.6676
7744/9969 [======================>.......] - ETA: 0s - loss: 0.6032 - acc: 0.6692
8064/9969 [=======================>......] - ETA: 0s - loss: 0.6021 - acc: 0.6708
8384/9969 [========================>.....] - ETA: 0s - loss: 0.5999 - acc: 0.6729
8704/9969 [=========================>....] - ETA: 0s - loss: 0.5987 - acc: 0.6742
9024/9969 [==========================>...] - ETA: 0s - loss: 0.5991 - acc: 0.6755
9344/9969 [===========================>..] - ETA: 0s - loss: 0.5991 - acc: 0.6754
9664/9969 [============================>.] - ETA: 0s - loss: 0.5982 - acc: 0.6761
9969/9969 [==============================] - 2s 189us/step - loss: 0.5980 - acc: 0.6763 - val_loss: 0.6203 - val_acc: 0.6327

Epoch 00009: val_acc did not improve from 0.65884
Epoch 10/10

  64/9969 [..............................] - ETA: 1s - loss: 0.5956 - acc: 0.6562
 384/9969 [>.............................] - ETA: 1s - loss: 0.6069 - acc: 0.6484
 704/9969 [=>............................] - ETA: 1s - loss: 0.5861 - acc: 0.6847
1024/9969 [==>...........................] - ETA: 1s - loss: 0.5730 - acc: 0.6885
1344/9969 [===>..........................] - ETA: 1s - loss: 0.5701 - acc: 0.6927
1728/9969 [====>.........................] - ETA: 1s - loss: 0.5859 - acc: 0.6800
2048/9969 [=====>........................] - ETA: 1s - loss: 0.5896 - acc: 0.6733
2368/9969 [======>.......................] - ETA: 1s - loss: 0.5910 - acc: 0.6736
2688/9969 [=======>......................] - ETA: 1s - loss: 0.5965 - acc: 0.6674
3008/9969 [========>.....................] - ETA: 1s - loss: 0.5942 - acc: 0.6715
3328/9969 [=========>....................] - ETA: 1s - loss: 0.5933 - acc: 0.6734
3584/9969 [=========>....................] - ETA: 1s - loss: 0.5959 - acc: 0.6724
3968/9969 [==========>...................] - ETA: 1s - loss: 0.5962 - acc: 0.6711
4352/9969 [============>.................] - ETA: 0s - loss: 0.5956 - acc: 0.6700
4672/9969 [=============>................] - ETA: 0s - loss: 0.5953 - acc: 0.6699
4928/9969 [=============>................] - ETA: 0s - loss: 0.5975 - acc: 0.6682
5184/9969 [==============>...............] - ETA: 0s - loss: 0.5979 - acc: 0.6692
5504/9969 [===============>..............] - ETA: 0s - loss: 0.5984 - acc: 0.6681
5760/9969 [================>.............] - ETA: 0s - loss: 0.5981 - acc: 0.6684
6080/9969 [=================>............] - ETA: 0s - loss: 0.5994 - acc: 0.6661
6400/9969 [==================>...........] - ETA: 0s - loss: 0.5992 - acc: 0.6677
6720/9969 [===================>..........] - ETA: 0s - loss: 0.5976 - acc: 0.6702
6976/9969 [===================>..........] - ETA: 0s - loss: 0.5997 - acc: 0.6700
7232/9969 [====================>.........] - ETA: 0s - loss: 0.5994 - acc: 0.6687
7552/9969 [=====================>........] - ETA: 0s - loss: 0.6005 - acc: 0.6676
7872/9969 [======================>.......] - ETA: 0s - loss: 0.6000 - acc: 0.6681
8192/9969 [=======================>......] - ETA: 0s - loss: 0.5996 - acc: 0.6682
8448/9969 [========================>.....] - ETA: 0s - loss: 0.5973 - acc: 0.6697
8768/9969 [=========================>....] - ETA: 0s - loss: 0.5974 - acc: 0.6703
9088/9969 [==========================>...] - ETA: 0s - loss: 0.5970 - acc: 0.6709
9408/9969 [===========================>..] - ETA: 0s - loss: 0.5978 - acc: 0.6704
9728/9969 [============================>.] - ETA: 0s - loss: 0.5963 - acc: 0.6719
9969/9969 [==============================] - 2s 185us/step - loss: 0.5958 - acc: 0.6721 - val_loss: 0.6298 - val_acc: 0.6462

Epoch 00010: val_acc did not improve from 0.65884
Saved model to disk
ACC: 0.6640173410404624
Sens: 0.6401734104046243
Spec: 0.6878612716763006
MCC: 0.32840831657477715
ROC_AUC: 0.7271088451000702
PRC_ROC: 0.7252113729200518
WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.
/data/lyli/Silencer/K562/datasets/6924/5fold/model/checkpoints_4layer_100-/Model_CNN.py:33: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[input_seq], output=[pred_output])
Fitting first model...
Train on 9969 samples, validate on 1108 samples
Epoch 1/10

  64/9969 [..............................] - ETA: 1:19 - loss: 0.6824 - acc: 0.5781
 320/9969 [..............................] - ETA: 17s - loss: 0.6834 - acc: 0.5406 
 576/9969 [>.............................] - ETA: 10s - loss: 0.6721 - acc: 0.5781
 896/9969 [=>............................] - ETA: 7s - loss: 0.6794 - acc: 0.5603 
1152/9969 [==>...........................] - ETA: 5s - loss: 0.6780 - acc: 0.5634
1472/9969 [===>..........................] - ETA: 4s - loss: 0.6747 - acc: 0.5666
1792/9969 [====>.........................] - ETA: 3s - loss: 0.6717 - acc: 0.5748
2048/9969 [=====>........................] - ETA: 3s - loss: 0.6691 - acc: 0.5801
2368/9969 [======>.......................] - ETA: 3s - loss: 0.6648 - acc: 0.5874
2624/9969 [======>.......................] - ETA: 2s - loss: 0.6631 - acc: 0.5922
2944/9969 [=======>......................] - ETA: 2s - loss: 0.6576 - acc: 0.5992
3264/9969 [========>.....................] - ETA: 2s - loss: 0.6552 - acc: 0.6045
3584/9969 [=========>....................] - ETA: 2s - loss: 0.6512 - acc: 0.6085
3840/9969 [==========>...................] - ETA: 2s - loss: 0.6503 - acc: 0.6128
4096/9969 [===========>..................] - ETA: 1s - loss: 0.6514 - acc: 0.6130
4352/9969 [============>.................] - ETA: 1s - loss: 0.6513 - acc: 0.6128
4672/9969 [=============>................] - ETA: 1s - loss: 0.6475 - acc: 0.6169
4992/9969 [==============>...............] - ETA: 1s - loss: 0.6441 - acc: 0.6198
5248/9969 [==============>...............] - ETA: 1s - loss: 0.6449 - acc: 0.6208
5568/9969 [===============>..............] - ETA: 1s - loss: 0.6443 - acc: 0.6225
5888/9969 [================>.............] - ETA: 1s - loss: 0.6446 - acc: 0.6225
6208/9969 [=================>............] - ETA: 1s - loss: 0.6441 - acc: 0.6215
6528/9969 [==================>...........] - ETA: 0s - loss: 0.6440 - acc: 0.6206
6848/9969 [===================>..........] - ETA: 0s - loss: 0.6437 - acc: 0.6221
7104/9969 [====================>.........] - ETA: 0s - loss: 0.6419 - acc: 0.6233
7424/9969 [=====================>........] - ETA: 0s - loss: 0.6419 - acc: 0.6223
7744/9969 [======================>.......] - ETA: 0s - loss: 0.6407 - acc: 0.6251
8064/9969 [=======================>......] - ETA: 0s - loss: 0.6394 - acc: 0.6261
8384/9969 [========================>.....] - ETA: 0s - loss: 0.6375 - acc: 0.6280
8640/9969 [=========================>....] - ETA: 0s - loss: 0.6381 - acc: 0.6281
8960/9969 [=========================>....] - ETA: 0s - loss: 0.6366 - acc: 0.6292
9216/9969 [==========================>...] - ETA: 0s - loss: 0.6370 - acc: 0.6283
9536/9969 [===========================>..] - ETA: 0s - loss: 0.6367 - acc: 0.6284
9856/9969 [============================>.] - ETA: 0s - loss: 0.6362 - acc: 0.6296
9969/9969 [==============================] - 3s 258us/step - loss: 0.6359 - acc: 0.6299 - val_loss: 0.6276 - val_acc: 0.6255

Epoch 00001: val_acc improved from -inf to 0.62545, saving model to /data/lyli/Silencer/K562/datasets/6924/5fold/model/checkpoints_4layer_100-/DNA_model/model_DNA3.hdf5
Epoch 2/10

  64/9969 [..............................] - ETA: 1s - loss: 0.5765 - acc: 0.6406
 384/9969 [>.............................] - ETA: 1s - loss: 0.6034 - acc: 0.6380
 704/9969 [=>............................] - ETA: 1s - loss: 0.6033 - acc: 0.6378
1024/9969 [==>...........................] - ETA: 1s - loss: 0.6075 - acc: 0.6396
1344/9969 [===>..........................] - ETA: 1s - loss: 0.6006 - acc: 0.6510
1664/9969 [====>.........................] - ETA: 1s - loss: 0.5970 - acc: 0.6593
1984/9969 [====>.........................] - ETA: 1s - loss: 0.6032 - acc: 0.6542
2304/9969 [=====>........................] - ETA: 1s - loss: 0.6085 - acc: 0.6467
2624/9969 [======>.......................] - ETA: 1s - loss: 0.6129 - acc: 0.6437
2944/9969 [=======>......................] - ETA: 1s - loss: 0.6112 - acc: 0.6467
3264/9969 [========>.....................] - ETA: 1s - loss: 0.6116 - acc: 0.6483
3648/9969 [=========>....................] - ETA: 1s - loss: 0.6090 - acc: 0.6494
3904/9969 [==========>...................] - ETA: 1s - loss: 0.6141 - acc: 0.6445
4160/9969 [===========>..................] - ETA: 1s - loss: 0.6148 - acc: 0.6447
4480/9969 [============>.................] - ETA: 1s - loss: 0.6156 - acc: 0.6417
4736/9969 [=============>................] - ETA: 0s - loss: 0.6160 - acc: 0.6402
5056/9969 [==============>...............] - ETA: 0s - loss: 0.6149 - acc: 0.6402
5376/9969 [===============>..............] - ETA: 0s - loss: 0.6140 - acc: 0.6438
5696/9969 [================>.............] - ETA: 0s - loss: 0.6160 - acc: 0.6419
6016/9969 [=================>............] - ETA: 0s - loss: 0.6197 - acc: 0.6380
6272/9969 [=================>............] - ETA: 0s - loss: 0.6198 - acc: 0.6379
6592/9969 [==================>...........] - ETA: 0s - loss: 0.6183 - acc: 0.6399
6848/9969 [===================>..........] - ETA: 0s - loss: 0.6184 - acc: 0.6400
7104/9969 [====================>.........] - ETA: 0s - loss: 0.6172 - acc: 0.6410
7424/9969 [=====================>........] - ETA: 0s - loss: 0.6176 - acc: 0.6398
7744/9969 [======================>.......] - ETA: 0s - loss: 0.6168 - acc: 0.6405
8064/9969 [=======================>......] - ETA: 0s - loss: 0.6157 - acc: 0.6417
8384/9969 [========================>.....] - ETA: 0s - loss: 0.6152 - acc: 0.6431
8704/9969 [=========================>....] - ETA: 0s - loss: 0.6148 - acc: 0.6436
9024/9969 [==========================>...] - ETA: 0s - loss: 0.6153 - acc: 0.6436
9280/9969 [==========================>...] - ETA: 0s - loss: 0.6148 - acc: 0.6443
9600/9969 [===========================>..] - ETA: 0s - loss: 0.6146 - acc: 0.6461
9920/9969 [============================>.] - ETA: 0s - loss: 0.6154 - acc: 0.6456
9969/9969 [==============================] - 2s 192us/step - loss: 0.6155 - acc: 0.6457 - val_loss: 0.6141 - val_acc: 0.6480

Epoch 00002: val_acc improved from 0.62545 to 0.64801, saving model to /data/lyli/Silencer/K562/datasets/6924/5fold/model/checkpoints_4layer_100-/DNA_model/model_DNA3.hdf5
Epoch 3/10

  64/9969 [..............................] - ETA: 1s - loss: 0.6106 - acc: 0.6875
 384/9969 [>.............................] - ETA: 1s - loss: 0.6204 - acc: 0.6823
 704/9969 [=>............................] - ETA: 1s - loss: 0.6268 - acc: 0.6605
 960/9969 [=>............................] - ETA: 1s - loss: 0.6237 - acc: 0.6542
1216/9969 [==>...........................] - ETA: 1s - loss: 0.6166 - acc: 0.6530
1536/9969 [===>..........................] - ETA: 1s - loss: 0.6128 - acc: 0.6569
1792/9969 [====>.........................] - ETA: 1s - loss: 0.6087 - acc: 0.6585
2112/9969 [=====>........................] - ETA: 1s - loss: 0.6066 - acc: 0.6629
2432/9969 [======>.......................] - ETA: 1s - loss: 0.6067 - acc: 0.6612
2752/9969 [=======>......................] - ETA: 1s - loss: 0.6033 - acc: 0.6635
3072/9969 [========>.....................] - ETA: 1s - loss: 0.6035 - acc: 0.6644
3392/9969 [=========>....................] - ETA: 1s - loss: 0.6044 - acc: 0.6630
3712/9969 [==========>...................] - ETA: 1s - loss: 0.6025 - acc: 0.6659
4032/9969 [===========>..................] - ETA: 1s - loss: 0.6019 - acc: 0.6696
4352/9969 [============>.................] - ETA: 1s - loss: 0.6042 - acc: 0.6675
4672/9969 [=============>................] - ETA: 0s - loss: 0.6024 - acc: 0.6699
4992/9969 [==============>...............] - ETA: 0s - loss: 0.6025 - acc: 0.6705
5312/9969 [==============>...............] - ETA: 0s - loss: 0.6009 - acc: 0.6715
5632/9969 [===============>..............] - ETA: 0s - loss: 0.6005 - acc: 0.6724
5952/9969 [================>.............] - ETA: 0s - loss: 0.6002 - acc: 0.6727
6272/9969 [=================>............] - ETA: 0s - loss: 0.6013 - acc: 0.6712
6592/9969 [==================>...........] - ETA: 0s - loss: 0.6027 - acc: 0.6688
6912/9969 [===================>..........] - ETA: 0s - loss: 0.6031 - acc: 0.6670
7232/9969 [====================>.........] - ETA: 0s - loss: 0.6029 - acc: 0.6673
7552/9969 [=====================>........] - ETA: 0s - loss: 0.6023 - acc: 0.6682
7872/9969 [======================>.......] - ETA: 0s - loss: 0.6021 - acc: 0.6677
8192/9969 [=======================>......] - ETA: 0s - loss: 0.6018 - acc: 0.6674
8512/9969 [========================>.....] - ETA: 0s - loss: 0.6020 - acc: 0.6673
8832/9969 [=========================>....] - ETA: 0s - loss: 0.6020 - acc: 0.6670
9152/9969 [==========================>...] - ETA: 0s - loss: 0.6030 - acc: 0.6656
9408/9969 [===========================>..] - ETA: 0s - loss: 0.6029 - acc: 0.6653
9728/9969 [============================>.] - ETA: 0s - loss: 0.6031 - acc: 0.6645
9969/9969 [==============================] - 2s 188us/step - loss: 0.6023 - acc: 0.6653 - val_loss: 0.6105 - val_acc: 0.6606

Epoch 00003: val_acc improved from 0.64801 to 0.66065, saving model to /data/lyli/Silencer/K562/datasets/6924/5fold/model/checkpoints_4layer_100-/DNA_model/model_DNA3.hdf5
Epoch 4/10

  64/9969 [..............................] - ETA: 1s - loss: 0.5877 - acc: 0.7969
 384/9969 [>.............................] - ETA: 1s - loss: 0.5950 - acc: 0.6823
 704/9969 [=>............................] - ETA: 1s - loss: 0.5778 - acc: 0.6946
1024/9969 [==>...........................] - ETA: 1s - loss: 0.5946 - acc: 0.6865
1344/9969 [===>..........................] - ETA: 1s - loss: 0.5921 - acc: 0.6882
1664/9969 [====>.........................] - ETA: 1s - loss: 0.5928 - acc: 0.6809
1984/9969 [====>.........................] - ETA: 1s - loss: 0.5928 - acc: 0.6784
2240/9969 [=====>........................] - ETA: 1s - loss: 0.5882 - acc: 0.6772
2560/9969 [======>.......................] - ETA: 1s - loss: 0.5849 - acc: 0.6777
2880/9969 [=======>......................] - ETA: 1s - loss: 0.5872 - acc: 0.6747
3200/9969 [========>.....................] - ETA: 1s - loss: 0.5897 - acc: 0.6737
3456/9969 [=========>....................] - ETA: 1s - loss: 0.5908 - acc: 0.6727
3776/9969 [==========>...................] - ETA: 1s - loss: 0.5919 - acc: 0.6708
4096/9969 [===========>..................] - ETA: 1s - loss: 0.5928 - acc: 0.6702
4352/9969 [============>.................] - ETA: 1s - loss: 0.5945 - acc: 0.6680
4672/9969 [=============>................] - ETA: 0s - loss: 0.5938 - acc: 0.6680
4928/9969 [=============>................] - ETA: 0s - loss: 0.5949 - acc: 0.6690
5248/9969 [==============>...............] - ETA: 0s - loss: 0.5946 - acc: 0.6684
5568/9969 [===============>..............] - ETA: 0s - loss: 0.5946 - acc: 0.6679
5888/9969 [================>.............] - ETA: 0s - loss: 0.5929 - acc: 0.6712
6208/9969 [=================>............] - ETA: 0s - loss: 0.5940 - acc: 0.6703
6400/9969 [==================>...........] - ETA: 0s - loss: 0.5948 - acc: 0.6691
6720/9969 [===================>..........] - ETA: 0s - loss: 0.5950 - acc: 0.6701
7040/9969 [====================>.........] - ETA: 0s - loss: 0.5942 - acc: 0.6713
7360/9969 [=====================>........] - ETA: 0s - loss: 0.5941 - acc: 0.6719
7616/9969 [=====================>........] - ETA: 0s - loss: 0.5948 - acc: 0.6713
7872/9969 [======================>.......] - ETA: 0s - loss: 0.5935 - acc: 0.6715
8128/9969 [=======================>......] - ETA: 0s - loss: 0.5934 - acc: 0.6713
8384/9969 [========================>.....] - ETA: 0s - loss: 0.5937 - acc: 0.6713
8704/9969 [=========================>....] - ETA: 0s - loss: 0.5945 - acc: 0.6704
8960/9969 [=========================>....] - ETA: 0s - loss: 0.5951 - acc: 0.6700
9216/9969 [==========================>...] - ETA: 0s - loss: 0.5945 - acc: 0.6711
9536/9969 [===========================>..] - ETA: 0s - loss: 0.5946 - acc: 0.6717
9856/9969 [============================>.] - ETA: 0s - loss: 0.5948 - acc: 0.6715
9969/9969 [==============================] - 2s 195us/step - loss: 0.5952 - acc: 0.6708 - val_loss: 0.6168 - val_acc: 0.6453

Epoch 00004: val_acc did not improve from 0.66065
Epoch 5/10

  64/9969 [..............................] - ETA: 2s - loss: 0.5723 - acc: 0.7500
 384/9969 [>.............................] - ETA: 1s - loss: 0.5979 - acc: 0.6615
 704/9969 [=>............................] - ETA: 1s - loss: 0.6055 - acc: 0.6818
 960/9969 [=>............................] - ETA: 1s - loss: 0.6037 - acc: 0.6875
1216/9969 [==>...........................] - ETA: 1s - loss: 0.6002 - acc: 0.6834
1536/9969 [===>..........................] - ETA: 1s - loss: 0.5879 - acc: 0.6862
1856/9969 [====>.........................] - ETA: 1s - loss: 0.5802 - acc: 0.6902
2112/9969 [=====>........................] - ETA: 1s - loss: 0.5748 - acc: 0.6932
2432/9969 [======>.......................] - ETA: 1s - loss: 0.5754 - acc: 0.6933
2752/9969 [=======>......................] - ETA: 1s - loss: 0.5722 - acc: 0.6940
3072/9969 [========>.....................] - ETA: 1s - loss: 0.5705 - acc: 0.6960
3392/9969 [=========>....................] - ETA: 1s - loss: 0.5718 - acc: 0.6937
3712/9969 [==========>...................] - ETA: 1s - loss: 0.5717 - acc: 0.6953
3968/9969 [==========>...................] - ETA: 1s - loss: 0.5704 - acc: 0.6961
4288/9969 [===========>..................] - ETA: 1s - loss: 0.5731 - acc: 0.6954
4672/9969 [=============>................] - ETA: 0s - loss: 0.5758 - acc: 0.6935
4992/9969 [==============>...............] - ETA: 0s - loss: 0.5754 - acc: 0.6911
5312/9969 [==============>...............] - ETA: 0s - loss: 0.5752 - acc: 0.6931
5632/9969 [===============>..............] - ETA: 0s - loss: 0.5765 - acc: 0.6912
5952/9969 [================>.............] - ETA: 0s - loss: 0.5782 - acc: 0.6917
6272/9969 [=================>............] - ETA: 0s - loss: 0.5803 - acc: 0.6902
6592/9969 [==================>...........] - ETA: 0s - loss: 0.5804 - acc: 0.6902
6912/9969 [===================>..........] - ETA: 0s - loss: 0.5807 - acc: 0.6895
7232/9969 [====================>.........] - ETA: 0s - loss: 0.5806 - acc: 0.6903
7552/9969 [=====================>........] - ETA: 0s - loss: 0.5808 - acc: 0.6894
7872/9969 [======================>.......] - ETA: 0s - loss: 0.5807 - acc: 0.6893
8192/9969 [=======================>......] - ETA: 0s - loss: 0.5817 - acc: 0.6885
8512/9969 [========================>.....] - ETA: 0s - loss: 0.5823 - acc: 0.6887
8768/9969 [=========================>....] - ETA: 0s - loss: 0.5823 - acc: 0.6890
9088/9969 [==========================>...] - ETA: 0s - loss: 0.5819 - acc: 0.6896
9408/9969 [===========================>..] - ETA: 0s - loss: 0.5833 - acc: 0.6887
9728/9969 [============================>.] - ETA: 0s - loss: 0.5832 - acc: 0.6887
9969/9969 [==============================] - 2s 186us/step - loss: 0.5826 - acc: 0.6889 - val_loss: 0.6211 - val_acc: 0.6327

Epoch 00005: val_acc did not improve from 0.66065
Epoch 6/10

  64/9969 [..............................] - ETA: 1s - loss: 0.6040 - acc: 0.7031
 384/9969 [>.............................] - ETA: 1s - loss: 0.5943 - acc: 0.6875
 704/9969 [=>............................] - ETA: 1s - loss: 0.5770 - acc: 0.6989
1024/9969 [==>...........................] - ETA: 1s - loss: 0.5608 - acc: 0.7109
1344/9969 [===>..........................] - ETA: 1s - loss: 0.5660 - acc: 0.7091
1664/9969 [====>.........................] - ETA: 1s - loss: 0.5679 - acc: 0.6989
1984/9969 [====>.........................] - ETA: 1s - loss: 0.5649 - acc: 0.6981
2304/9969 [=====>........................] - ETA: 1s - loss: 0.5630 - acc: 0.7014
2624/9969 [======>.......................] - ETA: 1s - loss: 0.5670 - acc: 0.7001
2944/9969 [=======>......................] - ETA: 1s - loss: 0.5657 - acc: 0.7031
3264/9969 [========>.....................] - ETA: 1s - loss: 0.5621 - acc: 0.7044
3520/9969 [=========>....................] - ETA: 1s - loss: 0.5674 - acc: 0.7026
3840/9969 [==========>...................] - ETA: 1s - loss: 0.5659 - acc: 0.7036
4160/9969 [===========>..................] - ETA: 1s - loss: 0.5648 - acc: 0.7048
4416/9969 [============>.................] - ETA: 1s - loss: 0.5646 - acc: 0.7058
4736/9969 [=============>................] - ETA: 0s - loss: 0.5633 - acc: 0.7065
5056/9969 [==============>...............] - ETA: 0s - loss: 0.5652 - acc: 0.7051
5376/9969 [===============>..............] - ETA: 0s - loss: 0.5659 - acc: 0.7031
5696/9969 [================>.............] - ETA: 0s - loss: 0.5665 - acc: 0.7022
6016/9969 [=================>............] - ETA: 0s - loss: 0.5663 - acc: 0.7026
6336/9969 [==================>...........] - ETA: 0s - loss: 0.5663 - acc: 0.7034
6656/9969 [===================>..........] - ETA: 0s - loss: 0.5656 - acc: 0.7028
6976/9969 [===================>..........] - ETA: 0s - loss: 0.5672 - acc: 0.7013
7296/9969 [====================>.........] - ETA: 0s - loss: 0.5682 - acc: 0.7009
7616/9969 [=====================>........] - ETA: 0s - loss: 0.5670 - acc: 0.7010
7936/9969 [======================>.......] - ETA: 0s - loss: 0.5663 - acc: 0.7010
8192/9969 [=======================>......] - ETA: 0s - loss: 0.5675 - acc: 0.6993
8512/9969 [========================>.....] - ETA: 0s - loss: 0.5681 - acc: 0.6995
8832/9969 [=========================>....] - ETA: 0s - loss: 0.5683 - acc: 0.6990
9152/9969 [==========================>...] - ETA: 0s - loss: 0.5691 - acc: 0.6985
9472/9969 [===========================>..] - ETA: 0s - loss: 0.5695 - acc: 0.6977
9728/9969 [============================>.] - ETA: 0s - loss: 0.5697 - acc: 0.6975
9969/9969 [==============================] - 2s 185us/step - loss: 0.5702 - acc: 0.6971 - val_loss: 0.6225 - val_acc: 0.6498

Epoch 00006: val_acc did not improve from 0.66065
Epoch 7/10

  64/9969 [..............................] - ETA: 2s - loss: 0.5548 - acc: 0.7188
 384/9969 [>.............................] - ETA: 1s - loss: 0.5303 - acc: 0.7292
 704/9969 [=>............................] - ETA: 1s - loss: 0.5600 - acc: 0.7031
1024/9969 [==>...........................] - ETA: 1s - loss: 0.5537 - acc: 0.6943
1408/9969 [===>..........................] - ETA: 1s - loss: 0.5545 - acc: 0.6996
1728/9969 [====>.........................] - ETA: 1s - loss: 0.5544 - acc: 0.6956
2048/9969 [=====>........................] - ETA: 1s - loss: 0.5482 - acc: 0.7026
2368/9969 [======>.......................] - ETA: 1s - loss: 0.5486 - acc: 0.7052
2688/9969 [=======>......................] - ETA: 1s - loss: 0.5455 - acc: 0.7080
3008/9969 [========>.....................] - ETA: 1s - loss: 0.5437 - acc: 0.7121
3328/9969 [=========>....................] - ETA: 1s - loss: 0.5481 - acc: 0.7091
3648/9969 [=========>....................] - ETA: 1s - loss: 0.5460 - acc: 0.7108
3904/9969 [==========>...................] - ETA: 1s - loss: 0.5493 - acc: 0.7075
4160/9969 [===========>..................] - ETA: 1s - loss: 0.5487 - acc: 0.7082
4480/9969 [============>.................] - ETA: 0s - loss: 0.5484 - acc: 0.7096
4800/9969 [=============>................] - ETA: 0s - loss: 0.5500 - acc: 0.7090
5120/9969 [==============>...............] - ETA: 0s - loss: 0.5509 - acc: 0.7092
5440/9969 [===============>..............] - ETA: 0s - loss: 0.5502 - acc: 0.7097
5696/9969 [================>.............] - ETA: 0s - loss: 0.5502 - acc: 0.7080
5952/9969 [================>.............] - ETA: 0s - loss: 0.5509 - acc: 0.7058
6272/9969 [=================>............] - ETA: 0s - loss: 0.5511 - acc: 0.7060
6592/9969 [==================>...........] - ETA: 0s - loss: 0.5516 - acc: 0.7063
6912/9969 [===================>..........] - ETA: 0s - loss: 0.5511 - acc: 0.7069
7232/9969 [====================>.........] - ETA: 0s - loss: 0.5522 - acc: 0.7045
7552/9969 [=====================>........] - ETA: 0s - loss: 0.5523 - acc: 0.7046
7872/9969 [======================>.......] - ETA: 0s - loss: 0.5531 - acc: 0.7044
8192/9969 [=======================>......] - ETA: 0s - loss: 0.5530 - acc: 0.7057
8512/9969 [========================>.....] - ETA: 0s - loss: 0.5520 - acc: 0.7069
8832/9969 [=========================>....] - ETA: 0s - loss: 0.5546 - acc: 0.7043
9152/9969 [==========================>...] - ETA: 0s - loss: 0.5545 - acc: 0.7033
9472/9969 [===========================>..] - ETA: 0s - loss: 0.5536 - acc: 0.7054
9792/9969 [============================>.] - ETA: 0s - loss: 0.5536 - acc: 0.7051
9969/9969 [==============================] - 2s 185us/step - loss: 0.5548 - acc: 0.7038 - val_loss: 0.6402 - val_acc: 0.6507

Epoch 00007: val_acc did not improve from 0.66065
Epoch 8/10

  64/9969 [..............................] - ETA: 1s - loss: 0.5104 - acc: 0.7344
 384/9969 [>.............................] - ETA: 1s - loss: 0.5178 - acc: 0.7552
 768/9969 [=>............................] - ETA: 1s - loss: 0.5387 - acc: 0.7383
1088/9969 [==>...........................] - ETA: 1s - loss: 0.5322 - acc: 0.7436
1408/9969 [===>..........................] - ETA: 1s - loss: 0.5220 - acc: 0.7436
1728/9969 [====>.........................] - ETA: 1s - loss: 0.5212 - acc: 0.7477
2048/9969 [=====>........................] - ETA: 1s - loss: 0.5271 - acc: 0.7417
2368/9969 [======>.......................] - ETA: 1s - loss: 0.5268 - acc: 0.7416
2688/9969 [=======>......................] - ETA: 1s - loss: 0.5268 - acc: 0.7370
3008/9969 [========>.....................] - ETA: 1s - loss: 0.5255 - acc: 0.7394
3328/9969 [=========>....................] - ETA: 1s - loss: 0.5286 - acc: 0.7341
3648/9969 [=========>....................] - ETA: 1s - loss: 0.5320 - acc: 0.7311
3968/9969 [==========>...................] - ETA: 1s - loss: 0.5349 - acc: 0.7306
4288/9969 [===========>..................] - ETA: 0s - loss: 0.5350 - acc: 0.7318
4672/9969 [=============>................] - ETA: 0s - loss: 0.5365 - acc: 0.7320
5056/9969 [==============>...............] - ETA: 0s - loss: 0.5373 - acc: 0.7312
5376/9969 [===============>..............] - ETA: 0s - loss: 0.5372 - acc: 0.7299
5696/9969 [================>.............] - ETA: 0s - loss: 0.5373 - acc: 0.7295
6016/9969 [=================>............] - ETA: 0s - loss: 0.5369 - acc: 0.7304
6336/9969 [==================>...........] - ETA: 0s - loss: 0.5392 - acc: 0.7289
6656/9969 [===================>..........] - ETA: 0s - loss: 0.5384 - acc: 0.7291
6976/9969 [===================>..........] - ETA: 0s - loss: 0.5369 - acc: 0.7302
7296/9969 [====================>.........] - ETA: 0s - loss: 0.5357 - acc: 0.7304
7616/9969 [=====================>........] - ETA: 0s - loss: 0.5365 - acc: 0.7295
7872/9969 [======================>.......] - ETA: 0s - loss: 0.5357 - acc: 0.7298
8192/9969 [=======================>......] - ETA: 0s - loss: 0.5368 - acc: 0.7279
8448/9969 [========================>.....] - ETA: 0s - loss: 0.5379 - acc: 0.7275
8768/9969 [=========================>....] - ETA: 0s - loss: 0.5381 - acc: 0.7257
9088/9969 [==========================>...] - ETA: 0s - loss: 0.5386 - acc: 0.7238
9408/9969 [===========================>..] - ETA: 0s - loss: 0.5387 - acc: 0.7241
9728/9969 [============================>.] - ETA: 0s - loss: 0.5393 - acc: 0.7227
9969/9969 [==============================] - 2s 182us/step - loss: 0.5404 - acc: 0.7210 - val_loss: 0.6549 - val_acc: 0.6498

Epoch 00008: val_acc did not improve from 0.66065
Epoch 9/10

  64/9969 [..............................] - ETA: 1s - loss: 0.5395 - acc: 0.7031
 384/9969 [>.............................] - ETA: 1s - loss: 0.5045 - acc: 0.7578
 640/9969 [>.............................] - ETA: 1s - loss: 0.5255 - acc: 0.7312
 960/9969 [=>............................] - ETA: 1s - loss: 0.5218 - acc: 0.7354
1280/9969 [==>...........................] - ETA: 1s - loss: 0.5123 - acc: 0.7461
1600/9969 [===>..........................] - ETA: 1s - loss: 0.5159 - acc: 0.7469
1920/9969 [====>.........................] - ETA: 1s - loss: 0.5165 - acc: 0.7443
2240/9969 [=====>........................] - ETA: 1s - loss: 0.5097 - acc: 0.7496
2560/9969 [======>.......................] - ETA: 1s - loss: 0.5046 - acc: 0.7531
2880/9969 [=======>......................] - ETA: 1s - loss: 0.5110 - acc: 0.7458
3200/9969 [========>.....................] - ETA: 1s - loss: 0.5107 - acc: 0.7447
3456/9969 [=========>....................] - ETA: 1s - loss: 0.5135 - acc: 0.7433
3776/9969 [==========>...................] - ETA: 1s - loss: 0.5096 - acc: 0.7452
4096/9969 [===========>..................] - ETA: 1s - loss: 0.5084 - acc: 0.7458
4416/9969 [============>.................] - ETA: 0s - loss: 0.5100 - acc: 0.7441
4736/9969 [=============>................] - ETA: 0s - loss: 0.5095 - acc: 0.7447
5056/9969 [==============>...............] - ETA: 0s - loss: 0.5122 - acc: 0.7425
5376/9969 [===============>..............] - ETA: 0s - loss: 0.5112 - acc: 0.7442
5696/9969 [================>.............] - ETA: 0s - loss: 0.5090 - acc: 0.7454
5952/9969 [================>.............] - ETA: 0s - loss: 0.5085 - acc: 0.7455
6272/9969 [=================>............] - ETA: 0s - loss: 0.5097 - acc: 0.7438
6528/9969 [==================>...........] - ETA: 0s - loss: 0.5103 - acc: 0.7437
6784/9969 [===================>..........] - ETA: 0s - loss: 0.5124 - acc: 0.7425
7104/9969 [====================>.........] - ETA: 0s - loss: 0.5143 - acc: 0.7409
7424/9969 [=====================>........] - ETA: 0s - loss: 0.5141 - acc: 0.7411
7680/9969 [======================>.......] - ETA: 0s - loss: 0.5146 - acc: 0.7404
8000/9969 [=======================>......] - ETA: 0s - loss: 0.5146 - acc: 0.7411
8320/9969 [========================>.....] - ETA: 0s - loss: 0.5148 - acc: 0.7409
8640/9969 [=========================>....] - ETA: 0s - loss: 0.5193 - acc: 0.7374
8960/9969 [=========================>....] - ETA: 0s - loss: 0.5192 - acc: 0.7379
9280/9969 [==========================>...] - ETA: 0s - loss: 0.5204 - acc: 0.7373
9600/9969 [===========================>..] - ETA: 0s - loss: 0.5208 - acc: 0.7375
9969/9969 [==============================] - 2s 187us/step - loss: 0.5205 - acc: 0.7371 - val_loss: 0.6585 - val_acc: 0.6426

Epoch 00009: val_acc did not improve from 0.66065
Epoch 10/10

  64/9969 [..............................] - ETA: 2s - loss: 0.4020 - acc: 0.8906
 448/9969 [>.............................] - ETA: 1s - loss: 0.4188 - acc: 0.8170
 768/9969 [=>............................] - ETA: 1s - loss: 0.4410 - acc: 0.7956
1088/9969 [==>...........................] - ETA: 1s - loss: 0.4461 - acc: 0.7886
1408/9969 [===>..........................] - ETA: 1s - loss: 0.4583 - acc: 0.7798
1728/9969 [====>.........................] - ETA: 1s - loss: 0.4569 - acc: 0.7818
2048/9969 [=====>........................] - ETA: 1s - loss: 0.4648 - acc: 0.7778
2368/9969 [======>.......................] - ETA: 1s - loss: 0.4677 - acc: 0.7762
2688/9969 [=======>......................] - ETA: 1s - loss: 0.4689 - acc: 0.7753
3008/9969 [========>.....................] - ETA: 1s - loss: 0.4803 - acc: 0.7646
3328/9969 [=========>....................] - ETA: 1s - loss: 0.4854 - acc: 0.7602
3648/9969 [=========>....................] - ETA: 1s - loss: 0.4912 - acc: 0.7555
3968/9969 [==========>...................] - ETA: 1s - loss: 0.4878 - acc: 0.7586
4288/9969 [===========>..................] - ETA: 0s - loss: 0.4907 - acc: 0.7575
4608/9969 [============>.................] - ETA: 0s - loss: 0.4924 - acc: 0.7559
4928/9969 [=============>................] - ETA: 0s - loss: 0.4896 - acc: 0.7597
5184/9969 [==============>...............] - ETA: 0s - loss: 0.4898 - acc: 0.7598
5504/9969 [===============>..............] - ETA: 0s - loss: 0.4921 - acc: 0.7578
5824/9969 [================>.............] - ETA: 0s - loss: 0.4921 - acc: 0.7564
6144/9969 [=================>............] - ETA: 0s - loss: 0.4923 - acc: 0.7565
6464/9969 [==================>...........] - ETA: 0s - loss: 0.4912 - acc: 0.7577
6784/9969 [===================>..........] - ETA: 0s - loss: 0.4898 - acc: 0.7591
7104/9969 [====================>.........] - ETA: 0s - loss: 0.4896 - acc: 0.7594
7360/9969 [=====================>........] - ETA: 0s - loss: 0.4886 - acc: 0.7598
7616/9969 [=====================>........] - ETA: 0s - loss: 0.4885 - acc: 0.7595
7936/9969 [======================>.......] - ETA: 0s - loss: 0.4889 - acc: 0.7598
8256/9969 [=======================>......] - ETA: 0s - loss: 0.4873 - acc: 0.7610
8512/9969 [========================>.....] - ETA: 0s - loss: 0.4870 - acc: 0.7610
8832/9969 [=========================>....] - ETA: 0s - loss: 0.4858 - acc: 0.7619
9088/9969 [==========================>...] - ETA: 0s - loss: 0.4871 - acc: 0.7603
9408/9969 [===========================>..] - ETA: 0s - loss: 0.4876 - acc: 0.7597
9728/9969 [============================>.] - ETA: 0s - loss: 0.4886 - acc: 0.7595
9969/9969 [==============================] - 2s 185us/step - loss: 0.4903 - acc: 0.7580 - val_loss: 0.6602 - val_acc: 0.6264

Epoch 00010: val_acc did not improve from 0.66065
Saved model to disk
ACC: 0.6473988439306358
Sens: 0.6546242774566474
Spec: 0.6401734104046243
MCC: 0.2948284736237542
ROC_AUC: 0.7048133708109191
PRC_ROC: 0.697090612518336
WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.
/data/lyli/Silencer/K562/datasets/6924/5fold/model/checkpoints_4layer_100-/Model_CNN.py:33: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[input_seq], output=[pred_output])
Fitting first model...
Train on 9969 samples, validate on 1108 samples
Epoch 1/10

  64/9969 [..............................] - ETA: 1:19 - loss: 0.6901 - acc: 0.5625
 320/9969 [..............................] - ETA: 17s - loss: 0.6971 - acc: 0.4875 
 576/9969 [>.............................] - ETA: 10s - loss: 0.6930 - acc: 0.5069
 832/9969 [=>............................] - ETA: 7s - loss: 0.6832 - acc: 0.5529 
1152/9969 [==>...........................] - ETA: 5s - loss: 0.6780 - acc: 0.5642
1408/9969 [===>..........................] - ETA: 4s - loss: 0.6722 - acc: 0.5753
1728/9969 [====>.........................] - ETA: 4s - loss: 0.6704 - acc: 0.5810
2048/9969 [=====>........................] - ETA: 3s - loss: 0.6656 - acc: 0.5903
2368/9969 [======>.......................] - ETA: 3s - loss: 0.6601 - acc: 0.5959
2688/9969 [=======>......................] - ETA: 2s - loss: 0.6576 - acc: 0.5978
3008/9969 [========>.....................] - ETA: 2s - loss: 0.6548 - acc: 0.6001
3328/9969 [=========>....................] - ETA: 2s - loss: 0.6523 - acc: 0.6043
3648/9969 [=========>....................] - ETA: 2s - loss: 0.6499 - acc: 0.6066
3968/9969 [==========>...................] - ETA: 1s - loss: 0.6477 - acc: 0.6101
4288/9969 [===========>..................] - ETA: 1s - loss: 0.6478 - acc: 0.6089
4608/9969 [============>.................] - ETA: 1s - loss: 0.6455 - acc: 0.6126
4928/9969 [=============>................] - ETA: 1s - loss: 0.6447 - acc: 0.6130
5248/9969 [==============>...............] - ETA: 1s - loss: 0.6431 - acc: 0.6160
5568/9969 [===============>..............] - ETA: 1s - loss: 0.6437 - acc: 0.6155
5888/9969 [================>.............] - ETA: 1s - loss: 0.6444 - acc: 0.6160
6208/9969 [=================>............] - ETA: 1s - loss: 0.6446 - acc: 0.6150
6528/9969 [==================>...........] - ETA: 0s - loss: 0.6443 - acc: 0.6176
6912/9969 [===================>..........] - ETA: 0s - loss: 0.6443 - acc: 0.6191
7232/9969 [====================>.........] - ETA: 0s - loss: 0.6423 - acc: 0.6207
7552/9969 [=====================>........] - ETA: 0s - loss: 0.6428 - acc: 0.6208
7872/9969 [======================>.......] - ETA: 0s - loss: 0.6428 - acc: 0.6206
8192/9969 [=======================>......] - ETA: 0s - loss: 0.6413 - acc: 0.6230
8512/9969 [========================>.....] - ETA: 0s - loss: 0.6410 - acc: 0.6229
8832/9969 [=========================>....] - ETA: 0s - loss: 0.6405 - acc: 0.6244
9152/9969 [==========================>...] - ETA: 0s - loss: 0.6413 - acc: 0.6238
9472/9969 [===========================>..] - ETA: 0s - loss: 0.6403 - acc: 0.6253
9792/9969 [============================>.] - ETA: 0s - loss: 0.6401 - acc: 0.6256
9969/9969 [==============================] - 2s 243us/step - loss: 0.6397 - acc: 0.6267 - val_loss: 0.6201 - val_acc: 0.6390

Epoch 00001: val_acc improved from -inf to 0.63899, saving model to /data/lyli/Silencer/K562/datasets/6924/5fold/model/checkpoints_4layer_100-/DNA_model/model_DNA4.hdf5
Epoch 2/10

  64/9969 [..............................] - ETA: 1s - loss: 0.6322 - acc: 0.5938
 320/9969 [..............................] - ETA: 1s - loss: 0.6105 - acc: 0.6625
 640/9969 [>.............................] - ETA: 1s - loss: 0.6109 - acc: 0.6500
 960/9969 [=>............................] - ETA: 1s - loss: 0.6117 - acc: 0.6635
1280/9969 [==>...........................] - ETA: 1s - loss: 0.6210 - acc: 0.6594
1600/9969 [===>..........................] - ETA: 1s - loss: 0.6142 - acc: 0.6606
1920/9969 [====>.........................] - ETA: 1s - loss: 0.6101 - acc: 0.6682
2240/9969 [=====>........................] - ETA: 1s - loss: 0.6131 - acc: 0.6603
2560/9969 [======>.......................] - ETA: 1s - loss: 0.6193 - acc: 0.6516
2880/9969 [=======>......................] - ETA: 1s - loss: 0.6238 - acc: 0.6444
3200/9969 [========>.....................] - ETA: 1s - loss: 0.6282 - acc: 0.6322
3520/9969 [=========>....................] - ETA: 1s - loss: 0.6300 - acc: 0.6327
3840/9969 [==========>...................] - ETA: 1s - loss: 0.6285 - acc: 0.6341
4160/9969 [===========>..................] - ETA: 1s - loss: 0.6257 - acc: 0.6375
4480/9969 [============>.................] - ETA: 0s - loss: 0.6242 - acc: 0.6400
4800/9969 [=============>................] - ETA: 0s - loss: 0.6218 - acc: 0.6408
5120/9969 [==============>...............] - ETA: 0s - loss: 0.6222 - acc: 0.6418
5440/9969 [===============>..............] - ETA: 0s - loss: 0.6215 - acc: 0.6434
5696/9969 [================>.............] - ETA: 0s - loss: 0.6208 - acc: 0.6441
6016/9969 [=================>............] - ETA: 0s - loss: 0.6212 - acc: 0.6439
6336/9969 [==================>...........] - ETA: 0s - loss: 0.6206 - acc: 0.6446
6656/9969 [===================>..........] - ETA: 0s - loss: 0.6193 - acc: 0.6462
6912/9969 [===================>..........] - ETA: 0s - loss: 0.6200 - acc: 0.6467
7168/9969 [====================>.........] - ETA: 0s - loss: 0.6213 - acc: 0.6461
7488/9969 [=====================>........] - ETA: 0s - loss: 0.6193 - acc: 0.6488
7808/9969 [======================>.......] - ETA: 0s - loss: 0.6187 - acc: 0.6489
8128/9969 [=======================>......] - ETA: 0s - loss: 0.6183 - acc: 0.6503
8448/9969 [========================>.....] - ETA: 0s - loss: 0.6163 - acc: 0.6522
8768/9969 [=========================>....] - ETA: 0s - loss: 0.6149 - acc: 0.6540
9088/9969 [==========================>...] - ETA: 0s - loss: 0.6151 - acc: 0.6536
9408/9969 [===========================>..] - ETA: 0s - loss: 0.6152 - acc: 0.6528
9728/9969 [============================>.] - ETA: 0s - loss: 0.6151 - acc: 0.6528
9969/9969 [==============================] - 2s 188us/step - loss: 0.6154 - acc: 0.6518 - val_loss: 0.6282 - val_acc: 0.6390

Epoch 00002: val_acc did not improve from 0.63899
Epoch 3/10

  64/9969 [..............................] - ETA: 1s - loss: 0.5574 - acc: 0.7031
 384/9969 [>.............................] - ETA: 1s - loss: 0.6022 - acc: 0.6615
 640/9969 [>.............................] - ETA: 1s - loss: 0.6013 - acc: 0.6703
 960/9969 [=>............................] - ETA: 1s - loss: 0.5882 - acc: 0.6906
1280/9969 [==>...........................] - ETA: 1s - loss: 0.5923 - acc: 0.6813
1600/9969 [===>..........................] - ETA: 1s - loss: 0.5870 - acc: 0.6869
1920/9969 [====>.........................] - ETA: 1s - loss: 0.5895 - acc: 0.6891
2240/9969 [=====>........................] - ETA: 1s - loss: 0.5956 - acc: 0.6804
2560/9969 [======>.......................] - ETA: 1s - loss: 0.5965 - acc: 0.6766
2880/9969 [=======>......................] - ETA: 1s - loss: 0.5932 - acc: 0.6788
3200/9969 [========>.....................] - ETA: 1s - loss: 0.5986 - acc: 0.6750
3520/9969 [=========>....................] - ETA: 1s - loss: 0.5970 - acc: 0.6759
3776/9969 [==========>...................] - ETA: 1s - loss: 0.5998 - acc: 0.6737
4096/9969 [===========>..................] - ETA: 1s - loss: 0.6014 - acc: 0.6714
4416/9969 [============>.................] - ETA: 0s - loss: 0.5997 - acc: 0.6728
4736/9969 [=============>................] - ETA: 0s - loss: 0.5986 - acc: 0.6736
5056/9969 [==============>...............] - ETA: 0s - loss: 0.5992 - acc: 0.6727
5312/9969 [==============>...............] - ETA: 0s - loss: 0.6000 - acc: 0.6717
5632/9969 [===============>..............] - ETA: 0s - loss: 0.6011 - acc: 0.6706
5888/9969 [================>.............] - ETA: 0s - loss: 0.6008 - acc: 0.6712
6208/9969 [=================>............] - ETA: 0s - loss: 0.6014 - acc: 0.6706
6528/9969 [==================>...........] - ETA: 0s - loss: 0.6020 - acc: 0.6694
6848/9969 [===================>..........] - ETA: 0s - loss: 0.6023 - acc: 0.6675
7168/9969 [====================>.........] - ETA: 0s - loss: 0.6015 - acc: 0.6692
7424/9969 [=====================>........] - ETA: 0s - loss: 0.6027 - acc: 0.6685
7744/9969 [======================>.......] - ETA: 0s - loss: 0.6010 - acc: 0.6705
8064/9969 [=======================>......] - ETA: 0s - loss: 0.6026 - acc: 0.6695
8384/9969 [========================>.....] - ETA: 0s - loss: 0.6027 - acc: 0.6694
8704/9969 [=========================>....] - ETA: 0s - loss: 0.6018 - acc: 0.6704
8960/9969 [=========================>....] - ETA: 0s - loss: 0.6024 - acc: 0.6702
9280/9969 [==========================>...] - ETA: 0s - loss: 0.6025 - acc: 0.6694
9600/9969 [===========================>..] - ETA: 0s - loss: 0.6045 - acc: 0.6680
9920/9969 [============================>.] - ETA: 0s - loss: 0.6038 - acc: 0.6691
9969/9969 [==============================] - 2s 188us/step - loss: 0.6034 - acc: 0.6693 - val_loss: 0.6291 - val_acc: 0.6372

Epoch 00003: val_acc did not improve from 0.63899
Epoch 4/10

  64/9969 [..............................] - ETA: 2s - loss: 0.6800 - acc: 0.5781
 384/9969 [>.............................] - ETA: 1s - loss: 0.6046 - acc: 0.6484
 704/9969 [=>............................] - ETA: 1s - loss: 0.5840 - acc: 0.6733
1024/9969 [==>...........................] - ETA: 1s - loss: 0.5788 - acc: 0.6846
1344/9969 [===>..........................] - ETA: 1s - loss: 0.5838 - acc: 0.6823
1664/9969 [====>.........................] - ETA: 1s - loss: 0.5833 - acc: 0.6803
1984/9969 [====>.........................] - ETA: 1s - loss: 0.5856 - acc: 0.6825
2304/9969 [=====>........................] - ETA: 1s - loss: 0.5842 - acc: 0.6836
2624/9969 [======>.......................] - ETA: 1s - loss: 0.5873 - acc: 0.6814
2944/9969 [=======>......................] - ETA: 1s - loss: 0.5870 - acc: 0.6834
3200/9969 [========>.....................] - ETA: 1s - loss: 0.5892 - acc: 0.6800
3456/9969 [=========>....................] - ETA: 1s - loss: 0.5878 - acc: 0.6814
3776/9969 [==========>...................] - ETA: 1s - loss: 0.5893 - acc: 0.6790
4096/9969 [===========>..................] - ETA: 1s - loss: 0.5900 - acc: 0.6809
4416/9969 [============>.................] - ETA: 1s - loss: 0.5918 - acc: 0.6789
4672/9969 [=============>................] - ETA: 0s - loss: 0.5916 - acc: 0.6807
4928/9969 [=============>................] - ETA: 0s - loss: 0.5936 - acc: 0.6788
5248/9969 [==============>...............] - ETA: 0s - loss: 0.5902 - acc: 0.6812
5568/9969 [===============>..............] - ETA: 0s - loss: 0.5878 - acc: 0.6827
5888/9969 [================>.............] - ETA: 0s - loss: 0.5885 - acc: 0.6824
6208/9969 [=================>............] - ETA: 0s - loss: 0.5904 - acc: 0.6804
6528/9969 [==================>...........] - ETA: 0s - loss: 0.5906 - acc: 0.6791
6912/9969 [===================>..........] - ETA: 0s - loss: 0.5906 - acc: 0.6794
7232/9969 [====================>.........] - ETA: 0s - loss: 0.5926 - acc: 0.6774
7552/9969 [=====================>........] - ETA: 0s - loss: 0.5916 - acc: 0.6788
7872/9969 [======================>.......] - ETA: 0s - loss: 0.5924 - acc: 0.6780
8192/9969 [=======================>......] - ETA: 0s - loss: 0.5920 - acc: 0.6790
8512/9969 [========================>.....] - ETA: 0s - loss: 0.5909 - acc: 0.6802
8832/9969 [=========================>....] - ETA: 0s - loss: 0.5916 - acc: 0.6793
9152/9969 [==========================>...] - ETA: 0s - loss: 0.5913 - acc: 0.6785
9408/9969 [===========================>..] - ETA: 0s - loss: 0.5920 - acc: 0.6781
9728/9969 [============================>.] - ETA: 0s - loss: 0.5928 - acc: 0.6771
9969/9969 [==============================] - 2s 189us/step - loss: 0.5931 - acc: 0.6770 - val_loss: 0.6065 - val_acc: 0.6507

Epoch 00004: val_acc improved from 0.63899 to 0.65072, saving model to /data/lyli/Silencer/K562/datasets/6924/5fold/model/checkpoints_4layer_100-/DNA_model/model_DNA4.hdf5
Epoch 5/10

  64/9969 [..............................] - ETA: 1s - loss: 0.5327 - acc: 0.7344
 384/9969 [>.............................] - ETA: 1s - loss: 0.5560 - acc: 0.7188
 704/9969 [=>............................] - ETA: 1s - loss: 0.5663 - acc: 0.6989
1024/9969 [==>...........................] - ETA: 1s - loss: 0.5542 - acc: 0.7021
1344/9969 [===>..........................] - ETA: 1s - loss: 0.5540 - acc: 0.6994
1664/9969 [====>.........................] - ETA: 1s - loss: 0.5563 - acc: 0.6947
1984/9969 [====>.........................] - ETA: 1s - loss: 0.5592 - acc: 0.6925
2304/9969 [=====>........................] - ETA: 1s - loss: 0.5585 - acc: 0.6936
2624/9969 [======>.......................] - ETA: 1s - loss: 0.5615 - acc: 0.6955
2944/9969 [=======>......................] - ETA: 1s - loss: 0.5634 - acc: 0.6957
3264/9969 [========>.....................] - ETA: 1s - loss: 0.5660 - acc: 0.6942
3520/9969 [=========>....................] - ETA: 1s - loss: 0.5636 - acc: 0.6983
3776/9969 [==========>...................] - ETA: 1s - loss: 0.5656 - acc: 0.6965
4096/9969 [===========>..................] - ETA: 1s - loss: 0.5648 - acc: 0.6956
4416/9969 [============>.................] - ETA: 0s - loss: 0.5658 - acc: 0.6959
4736/9969 [=============>................] - ETA: 0s - loss: 0.5688 - acc: 0.6940
5056/9969 [==============>...............] - ETA: 0s - loss: 0.5684 - acc: 0.6966
5376/9969 [===============>..............] - ETA: 0s - loss: 0.5678 - acc: 0.6979
5696/9969 [================>.............] - ETA: 0s - loss: 0.5687 - acc: 0.6972
6016/9969 [=================>............] - ETA: 0s - loss: 0.5690 - acc: 0.6981
6272/9969 [=================>............] - ETA: 0s - loss: 0.5695 - acc: 0.6972
6592/9969 [==================>...........] - ETA: 0s - loss: 0.5687 - acc: 0.6983
6912/9969 [===================>..........] - ETA: 0s - loss: 0.5697 - acc: 0.6986
7232/9969 [====================>.........] - ETA: 0s - loss: 0.5707 - acc: 0.6983
7616/9969 [=====================>........] - ETA: 0s - loss: 0.5702 - acc: 0.6994
7936/9969 [======================>.......] - ETA: 0s - loss: 0.5723 - acc: 0.6978
8256/9969 [=======================>......] - ETA: 0s - loss: 0.5720 - acc: 0.6977
8576/9969 [========================>.....] - ETA: 0s - loss: 0.5726 - acc: 0.6972
8960/9969 [=========================>....] - ETA: 0s - loss: 0.5750 - acc: 0.6959
9280/9969 [==========================>...] - ETA: 0s - loss: 0.5752 - acc: 0.6956
9664/9969 [============================>.] - ETA: 0s - loss: 0.5761 - acc: 0.6948
9969/9969 [==============================] - 2s 182us/step - loss: 0.5759 - acc: 0.6955 - val_loss: 0.6194 - val_acc: 0.6525

Epoch 00005: val_acc improved from 0.65072 to 0.65253, saving model to /data/lyli/Silencer/K562/datasets/6924/5fold/model/checkpoints_4layer_100-/DNA_model/model_DNA4.hdf5
Epoch 6/10

  64/9969 [..............................] - ETA: 1s - loss: 0.6112 - acc: 0.6562
 384/9969 [>.............................] - ETA: 1s - loss: 0.5447 - acc: 0.7318
 704/9969 [=>............................] - ETA: 1s - loss: 0.5485 - acc: 0.7344
1088/9969 [==>...........................] - ETA: 1s - loss: 0.5525 - acc: 0.7261
1472/9969 [===>..........................] - ETA: 1s - loss: 0.5395 - acc: 0.7351
1792/9969 [====>.........................] - ETA: 1s - loss: 0.5348 - acc: 0.7377
2112/9969 [=====>........................] - ETA: 1s - loss: 0.5328 - acc: 0.7344
2432/9969 [======>.......................] - ETA: 1s - loss: 0.5356 - acc: 0.7315
2752/9969 [=======>......................] - ETA: 1s - loss: 0.5416 - acc: 0.7253
3072/9969 [========>.....................] - ETA: 1s - loss: 0.5431 - acc: 0.7249
3392/9969 [=========>....................] - ETA: 1s - loss: 0.5421 - acc: 0.7235
3712/9969 [==========>...................] - ETA: 1s - loss: 0.5423 - acc: 0.7228
4096/9969 [===========>..................] - ETA: 0s - loss: 0.5477 - acc: 0.7207
4480/9969 [============>.................] - ETA: 0s - loss: 0.5488 - acc: 0.7190
4864/9969 [=============>................] - ETA: 0s - loss: 0.5491 - acc: 0.7198
5248/9969 [==============>...............] - ETA: 0s - loss: 0.5493 - acc: 0.7199
5632/9969 [===============>..............] - ETA: 0s - loss: 0.5519 - acc: 0.7168
6016/9969 [=================>............] - ETA: 0s - loss: 0.5526 - acc: 0.7146
6400/9969 [==================>...........] - ETA: 0s - loss: 0.5549 - acc: 0.7109
6784/9969 [===================>..........] - ETA: 0s - loss: 0.5564 - acc: 0.7078
7168/9969 [====================>.........] - ETA: 0s - loss: 0.5569 - acc: 0.7062
7552/9969 [=====================>........] - ETA: 0s - loss: 0.5577 - acc: 0.7063
7936/9969 [======================>.......] - ETA: 0s - loss: 0.5583 - acc: 0.7055
8320/9969 [========================>.....] - ETA: 0s - loss: 0.5598 - acc: 0.7044
8640/9969 [=========================>....] - ETA: 0s - loss: 0.5601 - acc: 0.7041
9024/9969 [==========================>...] - ETA: 0s - loss: 0.5587 - acc: 0.7049
9408/9969 [===========================>..] - ETA: 0s - loss: 0.5582 - acc: 0.7054
9792/9969 [============================>.] - ETA: 0s - loss: 0.5595 - acc: 0.7047
9969/9969 [==============================] - 2s 160us/step - loss: 0.5600 - acc: 0.7046 - val_loss: 0.6227 - val_acc: 0.6381

Epoch 00006: val_acc did not improve from 0.65253
Epoch 7/10

  64/9969 [..............................] - ETA: 1s - loss: 0.5888 - acc: 0.6562
 384/9969 [>.............................] - ETA: 1s - loss: 0.5457 - acc: 0.7448
 704/9969 [=>............................] - ETA: 1s - loss: 0.5403 - acc: 0.7386
1088/9969 [==>...........................] - ETA: 1s - loss: 0.5338 - acc: 0.7316
1472/9969 [===>..........................] - ETA: 1s - loss: 0.5306 - acc: 0.7371
1856/9969 [====>.........................] - ETA: 1s - loss: 0.5241 - acc: 0.7392
2240/9969 [=====>........................] - ETA: 1s - loss: 0.5308 - acc: 0.7362
2624/9969 [======>.......................] - ETA: 1s - loss: 0.5329 - acc: 0.7309
3008/9969 [========>.....................] - ETA: 1s - loss: 0.5324 - acc: 0.7317
3328/9969 [=========>....................] - ETA: 1s - loss: 0.5313 - acc: 0.7317
3648/9969 [=========>....................] - ETA: 0s - loss: 0.5283 - acc: 0.7346
4032/9969 [===========>..................] - ETA: 0s - loss: 0.5286 - acc: 0.7366
4416/9969 [============>.................] - ETA: 0s - loss: 0.5307 - acc: 0.7348
4800/9969 [=============>................] - ETA: 0s - loss: 0.5299 - acc: 0.7350
5184/9969 [==============>...............] - ETA: 0s - loss: 0.5342 - acc: 0.7332
5568/9969 [===============>..............] - ETA: 0s - loss: 0.5316 - acc: 0.7356
5952/9969 [================>.............] - ETA: 0s - loss: 0.5330 - acc: 0.7339
6272/9969 [=================>............] - ETA: 0s - loss: 0.5334 - acc: 0.7350
6656/9969 [===================>..........] - ETA: 0s - loss: 0.5358 - acc: 0.7338
7040/9969 [====================>.........] - ETA: 0s - loss: 0.5353 - acc: 0.7337
7424/9969 [=====================>........] - ETA: 0s - loss: 0.5368 - acc: 0.7325
7808/9969 [======================>.......] - ETA: 0s - loss: 0.5377 - acc: 0.7305
8192/9969 [=======================>......] - ETA: 0s - loss: 0.5386 - acc: 0.7288
8576/9969 [========================>.....] - ETA: 0s - loss: 0.5377 - acc: 0.7287
8896/9969 [=========================>....] - ETA: 0s - loss: 0.5381 - acc: 0.7282
9280/9969 [==========================>...] - ETA: 0s - loss: 0.5369 - acc: 0.7276
9664/9969 [============================>.] - ETA: 0s - loss: 0.5379 - acc: 0.7270
9969/9969 [==============================] - 2s 158us/step - loss: 0.5374 - acc: 0.7273 - val_loss: 0.6376 - val_acc: 0.6471

Epoch 00007: val_acc did not improve from 0.65253
Epoch 8/10

  64/9969 [..............................] - ETA: 2s - loss: 0.4449 - acc: 0.7188
 384/9969 [>.............................] - ETA: 1s - loss: 0.4783 - acc: 0.7526
 768/9969 [=>............................] - ETA: 1s - loss: 0.4878 - acc: 0.7617
1152/9969 [==>...........................] - ETA: 1s - loss: 0.5030 - acc: 0.7561
1536/9969 [===>..........................] - ETA: 1s - loss: 0.4972 - acc: 0.7572
1856/9969 [====>.........................] - ETA: 1s - loss: 0.4958 - acc: 0.7532
2240/9969 [=====>........................] - ETA: 1s - loss: 0.4936 - acc: 0.7540
2624/9969 [======>.......................] - ETA: 1s - loss: 0.4955 - acc: 0.7523
3008/9969 [========>.....................] - ETA: 1s - loss: 0.4957 - acc: 0.7530
3392/9969 [=========>....................] - ETA: 1s - loss: 0.4948 - acc: 0.7541
3712/9969 [==========>...................] - ETA: 0s - loss: 0.4948 - acc: 0.7567
4096/9969 [===========>..................] - ETA: 0s - loss: 0.4976 - acc: 0.7507
4480/9969 [============>.................] - ETA: 0s - loss: 0.4990 - acc: 0.7507
4864/9969 [=============>................] - ETA: 0s - loss: 0.5014 - acc: 0.7490
5248/9969 [==============>...............] - ETA: 0s - loss: 0.5053 - acc: 0.7454
5632/9969 [===============>..............] - ETA: 0s - loss: 0.5062 - acc: 0.7452
6016/9969 [=================>............] - ETA: 0s - loss: 0.5083 - acc: 0.7438
6400/9969 [==================>...........] - ETA: 0s - loss: 0.5102 - acc: 0.7425
6720/9969 [===================>..........] - ETA: 0s - loss: 0.5113 - acc: 0.7405
7040/9969 [====================>.........] - ETA: 0s - loss: 0.5118 - acc: 0.7411
7360/9969 [=====================>........] - ETA: 0s - loss: 0.5126 - acc: 0.7402
7744/9969 [======================>.......] - ETA: 0s - loss: 0.5123 - acc: 0.7389
8128/9969 [=======================>......] - ETA: 0s - loss: 0.5139 - acc: 0.7381
8512/9969 [========================>.....] - ETA: 0s - loss: 0.5140 - acc: 0.7384
8896/9969 [=========================>....] - ETA: 0s - loss: 0.5156 - acc: 0.7372
9216/9969 [==========================>...] - ETA: 0s - loss: 0.5162 - acc: 0.7361
9536/9969 [===========================>..] - ETA: 0s - loss: 0.5164 - acc: 0.7363
9856/9969 [============================>.] - ETA: 0s - loss: 0.5176 - acc: 0.7347
9969/9969 [==============================] - 2s 164us/step - loss: 0.5173 - acc: 0.7348 - val_loss: 0.6475 - val_acc: 0.6435

Epoch 00008: val_acc did not improve from 0.65253
Epoch 9/10

  64/9969 [..............................] - ETA: 1s - loss: 0.4371 - acc: 0.8125
 448/9969 [>.............................] - ETA: 1s - loss: 0.4674 - acc: 0.7991
 768/9969 [=>............................] - ETA: 1s - loss: 0.4677 - acc: 0.7799
1088/9969 [==>...........................] - ETA: 1s - loss: 0.4683 - acc: 0.7822
1408/9969 [===>..........................] - ETA: 1s - loss: 0.4623 - acc: 0.7827
1664/9969 [====>.........................] - ETA: 1s - loss: 0.4716 - acc: 0.7698
1984/9969 [====>.........................] - ETA: 1s - loss: 0.4683 - acc: 0.7671
2304/9969 [=====>........................] - ETA: 1s - loss: 0.4667 - acc: 0.7678
2624/9969 [======>.......................] - ETA: 1s - loss: 0.4696 - acc: 0.7683
2944/9969 [=======>......................] - ETA: 1s - loss: 0.4653 - acc: 0.7711
3200/9969 [========>.....................] - ETA: 1s - loss: 0.4658 - acc: 0.7694
3520/9969 [=========>....................] - ETA: 1s - loss: 0.4651 - acc: 0.7727
3840/9969 [==========>...................] - ETA: 1s - loss: 0.4700 - acc: 0.7695
4160/9969 [===========>..................] - ETA: 1s - loss: 0.4727 - acc: 0.7700
4480/9969 [============>.................] - ETA: 0s - loss: 0.4727 - acc: 0.7705
4864/9969 [=============>................] - ETA: 0s - loss: 0.4752 - acc: 0.7685
5184/9969 [==============>...............] - ETA: 0s - loss: 0.4797 - acc: 0.7658
5504/9969 [===============>..............] - ETA: 0s - loss: 0.4804 - acc: 0.7647
5824/9969 [================>.............] - ETA: 0s - loss: 0.4811 - acc: 0.7653
6144/9969 [=================>............] - ETA: 0s - loss: 0.4829 - acc: 0.7645
6464/9969 [==================>...........] - ETA: 0s - loss: 0.4833 - acc: 0.7647
6784/9969 [===================>..........] - ETA: 0s - loss: 0.4849 - acc: 0.7640
7104/9969 [====================>.........] - ETA: 0s - loss: 0.4849 - acc: 0.7631
7424/9969 [=====================>........] - ETA: 0s - loss: 0.4855 - acc: 0.7633
7744/9969 [======================>.......] - ETA: 0s - loss: 0.4863 - acc: 0.7628
8064/9969 [=======================>......] - ETA: 0s - loss: 0.4857 - acc: 0.7631
8384/9969 [========================>.....] - ETA: 0s - loss: 0.4864 - acc: 0.7626
8704/9969 [=========================>....] - ETA: 0s - loss: 0.4872 - acc: 0.7621
8960/9969 [=========================>....] - ETA: 0s - loss: 0.4859 - acc: 0.7627
9280/9969 [==========================>...] - ETA: 0s - loss: 0.4866 - acc: 0.7629
9600/9969 [===========================>..] - ETA: 0s - loss: 0.4847 - acc: 0.7649
9920/9969 [============================>.] - ETA: 0s - loss: 0.4850 - acc: 0.7641
9969/9969 [==============================] - 2s 182us/step - loss: 0.4853 - acc: 0.7641 - val_loss: 0.7050 - val_acc: 0.6408

Epoch 00009: val_acc did not improve from 0.65253
Epoch 10/10

  64/9969 [..............................] - ETA: 1s - loss: 0.4130 - acc: 0.8438
 384/9969 [>.............................] - ETA: 1s - loss: 0.4181 - acc: 0.7995
 704/9969 [=>............................] - ETA: 1s - loss: 0.3992 - acc: 0.8139
1024/9969 [==>...........................] - ETA: 1s - loss: 0.4072 - acc: 0.8125
1344/9969 [===>..........................] - ETA: 1s - loss: 0.4037 - acc: 0.8170
1664/9969 [====>.........................] - ETA: 1s - loss: 0.4121 - acc: 0.8113
1984/9969 [====>.........................] - ETA: 1s - loss: 0.4160 - acc: 0.8080
2304/9969 [=====>........................] - ETA: 1s - loss: 0.4198 - acc: 0.8073
2560/9969 [======>.......................] - ETA: 1s - loss: 0.4320 - acc: 0.8008
2880/9969 [=======>......................] - ETA: 1s - loss: 0.4374 - acc: 0.7955
3200/9969 [========>.....................] - ETA: 1s - loss: 0.4380 - acc: 0.7969
3520/9969 [=========>....................] - ETA: 1s - loss: 0.4366 - acc: 0.8006
3840/9969 [==========>...................] - ETA: 1s - loss: 0.4370 - acc: 0.7997
4160/9969 [===========>..................] - ETA: 1s - loss: 0.4408 - acc: 0.7983
4480/9969 [============>.................] - ETA: 0s - loss: 0.4407 - acc: 0.7991
4800/9969 [=============>................] - ETA: 0s - loss: 0.4424 - acc: 0.7977
4928/9969 [=============>................] - ETA: 0s - loss: 0.4423 - acc: 0.7971
5184/9969 [==============>...............] - ETA: 0s - loss: 0.4413 - acc: 0.7986
5504/9969 [===============>..............] - ETA: 0s - loss: 0.4416 - acc: 0.7980
5824/9969 [================>.............] - ETA: 0s - loss: 0.4388 - acc: 0.7996
6080/9969 [=================>............] - ETA: 0s - loss: 0.4399 - acc: 0.7975
6400/9969 [==================>...........] - ETA: 0s - loss: 0.4361 - acc: 0.7994
6656/9969 [===================>..........] - ETA: 0s - loss: 0.4365 - acc: 0.7996
6976/9969 [===================>..........] - ETA: 0s - loss: 0.4371 - acc: 0.7989
7296/9969 [====================>.........] - ETA: 0s - loss: 0.4373 - acc: 0.7974
7616/9969 [=====================>........] - ETA: 0s - loss: 0.4408 - acc: 0.7945
7936/9969 [======================>.......] - ETA: 0s - loss: 0.4405 - acc: 0.7952
8256/9969 [=======================>......] - ETA: 0s - loss: 0.4416 - acc: 0.7946
8576/9969 [========================>.....] - ETA: 0s - loss: 0.4439 - acc: 0.7927
8896/9969 [=========================>....] - ETA: 0s - loss: 0.4443 - acc: 0.7920
9216/9969 [==========================>...] - ETA: 0s - loss: 0.4445 - acc: 0.7918
9536/9969 [===========================>..] - ETA: 0s - loss: 0.4455 - acc: 0.7911
9856/9969 [============================>.] - ETA: 0s - loss: 0.4460 - acc: 0.7898
9969/9969 [==============================] - 2s 192us/step - loss: 0.4456 - acc: 0.7898 - val_loss: 0.7007 - val_acc: 0.6300

Epoch 00010: val_acc did not improve from 0.65253
Saved model to disk
ACC: 0.6694364161849711
Sens: 0.6657039711191336
Spec: 0.673174258857556
MCC: 0.33888698775103115
ROC_AUC: 0.7381582965927156
PRC_ROC: 0.7305507381425855
WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.
/data/lyli/Silencer/K562/datasets/6924/5fold/model/checkpoints_4layer_100-/Model_CNN.py:33: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[input_seq], output=[pred_output])
Fitting first model...
Train on 9969 samples, validate on 1108 samples
Epoch 1/10

  64/9969 [..............................] - ETA: 1:28 - loss: 0.6928 - acc: 0.4844
 320/9969 [..............................] - ETA: 19s - loss: 0.6990 - acc: 0.5125 
 576/9969 [>.............................] - ETA: 11s - loss: 0.6949 - acc: 0.5191
 896/9969 [=>............................] - ETA: 7s - loss: 0.6906 - acc: 0.5368 
1216/9969 [==>...........................] - ETA: 5s - loss: 0.6871 - acc: 0.5485
1536/9969 [===>..........................] - ETA: 4s - loss: 0.6770 - acc: 0.5573
1856/9969 [====>.........................] - ETA: 4s - loss: 0.6767 - acc: 0.5625
2176/9969 [=====>........................] - ETA: 3s - loss: 0.6745 - acc: 0.5735
2496/9969 [======>.......................] - ETA: 3s - loss: 0.6715 - acc: 0.5793
2816/9969 [=======>......................] - ETA: 2s - loss: 0.6719 - acc: 0.5749
3136/9969 [========>.....................] - ETA: 2s - loss: 0.6666 - acc: 0.5800
3456/9969 [=========>....................] - ETA: 2s - loss: 0.6655 - acc: 0.5825
3776/9969 [==========>...................] - ETA: 2s - loss: 0.6629 - acc: 0.5855
4096/9969 [===========>..................] - ETA: 1s - loss: 0.6600 - acc: 0.5916
4416/9969 [============>.................] - ETA: 1s - loss: 0.6634 - acc: 0.5888
4736/9969 [=============>................] - ETA: 1s - loss: 0.6614 - acc: 0.5925
5056/9969 [==============>...............] - ETA: 1s - loss: 0.6610 - acc: 0.5926
5376/9969 [===============>..............] - ETA: 1s - loss: 0.6603 - acc: 0.5952
5696/9969 [================>.............] - ETA: 1s - loss: 0.6592 - acc: 0.5969
6016/9969 [=================>............] - ETA: 1s - loss: 0.6568 - acc: 0.6007
6336/9969 [==================>...........] - ETA: 0s - loss: 0.6553 - acc: 0.6035
6656/9969 [===================>..........] - ETA: 0s - loss: 0.6553 - acc: 0.6032
6976/9969 [===================>..........] - ETA: 0s - loss: 0.6553 - acc: 0.6015
7232/9969 [====================>.........] - ETA: 0s - loss: 0.6536 - acc: 0.6044
7552/9969 [=====================>........] - ETA: 0s - loss: 0.6541 - acc: 0.6053
7872/9969 [======================>.......] - ETA: 0s - loss: 0.6526 - acc: 0.6053
8192/9969 [=======================>......] - ETA: 0s - loss: 0.6509 - acc: 0.6069
8512/9969 [========================>.....] - ETA: 0s - loss: 0.6487 - acc: 0.6094
8832/9969 [=========================>....] - ETA: 0s - loss: 0.6479 - acc: 0.6118
9088/9969 [==========================>...] - ETA: 0s - loss: 0.6472 - acc: 0.6122
9408/9969 [===========================>..] - ETA: 0s - loss: 0.6470 - acc: 0.6111
9728/9969 [============================>.] - ETA: 0s - loss: 0.6463 - acc: 0.6119
9969/9969 [==============================] - 3s 252us/step - loss: 0.6457 - acc: 0.6128 - val_loss: 0.6112 - val_acc: 0.6444

Epoch 00001: val_acc improved from -inf to 0.64440, saving model to /data/lyli/Silencer/K562/datasets/6924/5fold/model/checkpoints_4layer_100-/DNA_model/model_DNA5.hdf5
Epoch 2/10

  64/9969 [..............................] - ETA: 1s - loss: 0.5491 - acc: 0.7031
 384/9969 [>.............................] - ETA: 1s - loss: 0.6022 - acc: 0.6484
 640/9969 [>.............................] - ETA: 1s - loss: 0.6095 - acc: 0.6391
 960/9969 [=>............................] - ETA: 1s - loss: 0.6035 - acc: 0.6427
1280/9969 [==>...........................] - ETA: 1s - loss: 0.6021 - acc: 0.6547
1536/9969 [===>..........................] - ETA: 1s - loss: 0.5991 - acc: 0.6562
1856/9969 [====>.........................] - ETA: 1s - loss: 0.6088 - acc: 0.6460
2176/9969 [=====>........................] - ETA: 1s - loss: 0.6126 - acc: 0.6397
2496/9969 [======>.......................] - ETA: 1s - loss: 0.6115 - acc: 0.6410
2880/9969 [=======>......................] - ETA: 1s - loss: 0.6133 - acc: 0.6385
3200/9969 [========>.....................] - ETA: 1s - loss: 0.6136 - acc: 0.6391
3520/9969 [=========>....................] - ETA: 1s - loss: 0.6130 - acc: 0.6412
3840/9969 [==========>...................] - ETA: 1s - loss: 0.6151 - acc: 0.6391
4096/9969 [===========>..................] - ETA: 1s - loss: 0.6170 - acc: 0.6384
4416/9969 [============>.................] - ETA: 0s - loss: 0.6184 - acc: 0.6388
4672/9969 [=============>................] - ETA: 0s - loss: 0.6184 - acc: 0.6372
4992/9969 [==============>...............] - ETA: 0s - loss: 0.6172 - acc: 0.6394
5312/9969 [==============>...............] - ETA: 0s - loss: 0.6182 - acc: 0.6378
5632/9969 [===============>..............] - ETA: 0s - loss: 0.6199 - acc: 0.6390
5952/9969 [================>.............] - ETA: 0s - loss: 0.6194 - acc: 0.6381
6272/9969 [=================>............] - ETA: 0s - loss: 0.6188 - acc: 0.6386
6592/9969 [==================>...........] - ETA: 0s - loss: 0.6182 - acc: 0.6411
6912/9969 [===================>..........] - ETA: 0s - loss: 0.6193 - acc: 0.6400
7232/9969 [====================>.........] - ETA: 0s - loss: 0.6199 - acc: 0.6397
7552/9969 [=====================>........] - ETA: 0s - loss: 0.6195 - acc: 0.6405
7808/9969 [======================>.......] - ETA: 0s - loss: 0.6195 - acc: 0.6409
8128/9969 [=======================>......] - ETA: 0s - loss: 0.6192 - acc: 0.6414
8448/9969 [========================>.....] - ETA: 0s - loss: 0.6189 - acc: 0.6425
8832/9969 [=========================>....] - ETA: 0s - loss: 0.6177 - acc: 0.6444
9152/9969 [==========================>...] - ETA: 0s - loss: 0.6191 - acc: 0.6424
9408/9969 [===========================>..] - ETA: 0s - loss: 0.6198 - acc: 0.6419
9728/9969 [============================>.] - ETA: 0s - loss: 0.6208 - acc: 0.6409
9969/9969 [==============================] - 2s 185us/step - loss: 0.6213 - acc: 0.6411 - val_loss: 0.6161 - val_acc: 0.6552

Epoch 00002: val_acc improved from 0.64440 to 0.65523, saving model to /data/lyli/Silencer/K562/datasets/6924/5fold/model/checkpoints_4layer_100-/DNA_model/model_DNA5.hdf5
Epoch 3/10

  64/9969 [..............................] - ETA: 2s - loss: 0.6727 - acc: 0.5938
 384/9969 [>.............................] - ETA: 1s - loss: 0.6407 - acc: 0.6146
 704/9969 [=>............................] - ETA: 1s - loss: 0.6235 - acc: 0.6648
1024/9969 [==>...........................] - ETA: 1s - loss: 0.6134 - acc: 0.6670
1344/9969 [===>..........................] - ETA: 1s - loss: 0.6091 - acc: 0.6704
1664/9969 [====>.........................] - ETA: 1s - loss: 0.6034 - acc: 0.6719
1984/9969 [====>.........................] - ETA: 1s - loss: 0.6004 - acc: 0.6714
2304/9969 [=====>........................] - ETA: 1s - loss: 0.5985 - acc: 0.6723
2624/9969 [======>.......................] - ETA: 1s - loss: 0.6092 - acc: 0.6658
2944/9969 [=======>......................] - ETA: 1s - loss: 0.6107 - acc: 0.6647
3264/9969 [========>.....................] - ETA: 1s - loss: 0.6108 - acc: 0.6648
3648/9969 [=========>....................] - ETA: 1s - loss: 0.6130 - acc: 0.6612
3968/9969 [==========>...................] - ETA: 1s - loss: 0.6160 - acc: 0.6560
4288/9969 [===========>..................] - ETA: 1s - loss: 0.6137 - acc: 0.6574
4608/9969 [============>.................] - ETA: 0s - loss: 0.6160 - acc: 0.6547
4928/9969 [=============>................] - ETA: 0s - loss: 0.6136 - acc: 0.6583
5248/9969 [==============>...............] - ETA: 0s - loss: 0.6124 - acc: 0.6572
5568/9969 [===============>..............] - ETA: 0s - loss: 0.6116 - acc: 0.6573
5888/9969 [================>.............] - ETA: 0s - loss: 0.6114 - acc: 0.6574
6208/9969 [=================>............] - ETA: 0s - loss: 0.6122 - acc: 0.6559
6528/9969 [==================>...........] - ETA: 0s - loss: 0.6123 - acc: 0.6561
6848/9969 [===================>..........] - ETA: 0s - loss: 0.6117 - acc: 0.6560
7168/9969 [====================>.........] - ETA: 0s - loss: 0.6121 - acc: 0.6558
7488/9969 [=====================>........] - ETA: 0s - loss: 0.6121 - acc: 0.6562
7808/9969 [======================>.......] - ETA: 0s - loss: 0.6132 - acc: 0.6539
8128/9969 [=======================>......] - ETA: 0s - loss: 0.6142 - acc: 0.6524
8512/9969 [========================>.....] - ETA: 0s - loss: 0.6139 - acc: 0.6520
8768/9969 [=========================>....] - ETA: 0s - loss: 0.6139 - acc: 0.6519
9088/9969 [==========================>...] - ETA: 0s - loss: 0.6146 - acc: 0.6506
9408/9969 [===========================>..] - ETA: 0s - loss: 0.6131 - acc: 0.6520
9728/9969 [============================>.] - ETA: 0s - loss: 0.6134 - acc: 0.6506
9969/9969 [==============================] - 2s 183us/step - loss: 0.6144 - acc: 0.6505 - val_loss: 0.5993 - val_acc: 0.6552

Epoch 00003: val_acc did not improve from 0.65523
Epoch 4/10

  64/9969 [..............................] - ETA: 2s - loss: 0.5887 - acc: 0.6875
 384/9969 [>.............................] - ETA: 1s - loss: 0.5760 - acc: 0.6901
 704/9969 [=>............................] - ETA: 1s - loss: 0.5836 - acc: 0.6875
1088/9969 [==>...........................] - ETA: 1s - loss: 0.5926 - acc: 0.6756
1408/9969 [===>..........................] - ETA: 1s - loss: 0.5974 - acc: 0.6705
1728/9969 [====>.........................] - ETA: 1s - loss: 0.5967 - acc: 0.6730
2048/9969 [=====>........................] - ETA: 1s - loss: 0.6007 - acc: 0.6709
2368/9969 [======>.......................] - ETA: 1s - loss: 0.6067 - acc: 0.6617
2688/9969 [=======>......................] - ETA: 1s - loss: 0.6105 - acc: 0.6592
3008/9969 [========>.....................] - ETA: 1s - loss: 0.6118 - acc: 0.6572
3328/9969 [=========>....................] - ETA: 1s - loss: 0.6106 - acc: 0.6569
3648/9969 [=========>....................] - ETA: 1s - loss: 0.6085 - acc: 0.6568
3968/9969 [==========>...................] - ETA: 1s - loss: 0.6097 - acc: 0.6545
4224/9969 [===========>..................] - ETA: 1s - loss: 0.6117 - acc: 0.6515
4480/9969 [============>.................] - ETA: 1s - loss: 0.6105 - acc: 0.6527
4800/9969 [=============>................] - ETA: 0s - loss: 0.6104 - acc: 0.6512
5120/9969 [==============>...............] - ETA: 0s - loss: 0.6110 - acc: 0.6514
5440/9969 [===============>..............] - ETA: 0s - loss: 0.6110 - acc: 0.6517
5760/9969 [================>.............] - ETA: 0s - loss: 0.6111 - acc: 0.6517
6016/9969 [=================>............] - ETA: 0s - loss: 0.6104 - acc: 0.6538
6336/9969 [==================>...........] - ETA: 0s - loss: 0.6123 - acc: 0.6520
6656/9969 [===================>..........] - ETA: 0s - loss: 0.6121 - acc: 0.6540
7040/9969 [====================>.........] - ETA: 0s - loss: 0.6110 - acc: 0.6557
7360/9969 [=====================>........] - ETA: 0s - loss: 0.6090 - acc: 0.6576
7680/9969 [======================>.......] - ETA: 0s - loss: 0.6086 - acc: 0.6591
8000/9969 [=======================>......] - ETA: 0s - loss: 0.6109 - acc: 0.6567
8320/9969 [========================>.....] - ETA: 0s - loss: 0.6114 - acc: 0.6564
8704/9969 [=========================>....] - ETA: 0s - loss: 0.6103 - acc: 0.6573
9024/9969 [==========================>...] - ETA: 0s - loss: 0.6097 - acc: 0.6589
9344/9969 [===========================>..] - ETA: 0s - loss: 0.6103 - acc: 0.6586
9664/9969 [============================>.] - ETA: 0s - loss: 0.6093 - acc: 0.6604
9969/9969 [==============================] - 2s 184us/step - loss: 0.6096 - acc: 0.6604 - val_loss: 0.6178 - val_acc: 0.6381

Epoch 00004: val_acc did not improve from 0.65523
Epoch 5/10

  64/9969 [..............................] - ETA: 1s - loss: 0.6034 - acc: 0.6250
 320/9969 [..............................] - ETA: 1s - loss: 0.6080 - acc: 0.6344
 640/9969 [>.............................] - ETA: 1s - loss: 0.5969 - acc: 0.6531
 960/9969 [=>............................] - ETA: 1s - loss: 0.5854 - acc: 0.6677
1280/9969 [==>...........................] - ETA: 1s - loss: 0.5833 - acc: 0.6789
1664/9969 [====>.........................] - ETA: 1s - loss: 0.5799 - acc: 0.6869
1984/9969 [====>.........................] - ETA: 1s - loss: 0.5849 - acc: 0.6809
2304/9969 [=====>........................] - ETA: 1s - loss: 0.5864 - acc: 0.6788
2624/9969 [======>.......................] - ETA: 1s - loss: 0.5905 - acc: 0.6780
2944/9969 [=======>......................] - ETA: 1s - loss: 0.5896 - acc: 0.6790
3264/9969 [========>.....................] - ETA: 1s - loss: 0.5933 - acc: 0.6780
3584/9969 [=========>....................] - ETA: 1s - loss: 0.5973 - acc: 0.6735
3904/9969 [==========>...................] - ETA: 1s - loss: 0.5982 - acc: 0.6749
4224/9969 [===========>..................] - ETA: 1s - loss: 0.5994 - acc: 0.6742
4544/9969 [============>.................] - ETA: 0s - loss: 0.6006 - acc: 0.6747
4864/9969 [=============>................] - ETA: 0s - loss: 0.5992 - acc: 0.6754
5184/9969 [==============>...............] - ETA: 0s - loss: 0.6012 - acc: 0.6711
5504/9969 [===============>..............] - ETA: 0s - loss: 0.6005 - acc: 0.6713
5760/9969 [================>.............] - ETA: 0s - loss: 0.6026 - acc: 0.6694
6144/9969 [=================>............] - ETA: 0s - loss: 0.6008 - acc: 0.6694
6464/9969 [==================>...........] - ETA: 0s - loss: 0.6017 - acc: 0.6674
6784/9969 [===================>..........] - ETA: 0s - loss: 0.6023 - acc: 0.6657
7104/9969 [====================>.........] - ETA: 0s - loss: 0.6033 - acc: 0.6641
7360/9969 [=====================>........] - ETA: 0s - loss: 0.6021 - acc: 0.6652
7680/9969 [======================>.......] - ETA: 0s - loss: 0.6015 - acc: 0.6667
8000/9969 [=======================>......] - ETA: 0s - loss: 0.6016 - acc: 0.6667
8320/9969 [========================>.....] - ETA: 0s - loss: 0.6027 - acc: 0.6653
8640/9969 [=========================>....] - ETA: 0s - loss: 0.6027 - acc: 0.6659
8960/9969 [=========================>....] - ETA: 0s - loss: 0.6032 - acc: 0.6660
9216/9969 [==========================>...] - ETA: 0s - loss: 0.6036 - acc: 0.6657
9536/9969 [===========================>..] - ETA: 0s - loss: 0.6023 - acc: 0.6677
9856/9969 [============================>.] - ETA: 0s - loss: 0.6022 - acc: 0.6676
9969/9969 [==============================] - 2s 184us/step - loss: 0.6014 - acc: 0.6685 - val_loss: 0.6032 - val_acc: 0.6588

Epoch 00005: val_acc improved from 0.65523 to 0.65884, saving model to /data/lyli/Silencer/K562/datasets/6924/5fold/model/checkpoints_4layer_100-/DNA_model/model_DNA5.hdf5
Epoch 6/10

  64/9969 [..............................] - ETA: 1s - loss: 0.6245 - acc: 0.6875
 384/9969 [>.............................] - ETA: 1s - loss: 0.5953 - acc: 0.6953
 704/9969 [=>............................] - ETA: 1s - loss: 0.5995 - acc: 0.6776
1024/9969 [==>...........................] - ETA: 1s - loss: 0.5906 - acc: 0.6748
1280/9969 [==>...........................] - ETA: 1s - loss: 0.5819 - acc: 0.6820
1600/9969 [===>..........................] - ETA: 1s - loss: 0.5816 - acc: 0.6875
1920/9969 [====>.........................] - ETA: 1s - loss: 0.5826 - acc: 0.6870
2240/9969 [=====>........................] - ETA: 1s - loss: 0.5840 - acc: 0.6884
2560/9969 [======>.......................] - ETA: 1s - loss: 0.5854 - acc: 0.6875
2880/9969 [=======>......................] - ETA: 1s - loss: 0.5835 - acc: 0.6885
3200/9969 [========>.....................] - ETA: 1s - loss: 0.5879 - acc: 0.6828
3520/9969 [=========>....................] - ETA: 1s - loss: 0.5863 - acc: 0.6858
3840/9969 [==========>...................] - ETA: 1s - loss: 0.5888 - acc: 0.6862
4224/9969 [===========>..................] - ETA: 0s - loss: 0.5897 - acc: 0.6863
4544/9969 [============>.................] - ETA: 0s - loss: 0.5900 - acc: 0.6842
4864/9969 [=============>................] - ETA: 0s - loss: 0.5903 - acc: 0.6819
5184/9969 [==============>...............] - ETA: 0s - loss: 0.5909 - acc: 0.6796
5504/9969 [===============>..............] - ETA: 0s - loss: 0.5903 - acc: 0.6799
5824/9969 [================>.............] - ETA: 0s - loss: 0.5893 - acc: 0.6823
6144/9969 [=================>............] - ETA: 0s - loss: 0.5912 - acc: 0.6800
6464/9969 [==================>...........] - ETA: 0s - loss: 0.5904 - acc: 0.6810
6784/9969 [===================>..........] - ETA: 0s - loss: 0.5901 - acc: 0.6800
7040/9969 [====================>.........] - ETA: 0s - loss: 0.5895 - acc: 0.6807
7424/9969 [=====================>........] - ETA: 0s - loss: 0.5905 - acc: 0.6797
7808/9969 [======================>.......] - ETA: 0s - loss: 0.5914 - acc: 0.6775
8192/9969 [=======================>......] - ETA: 0s - loss: 0.5917 - acc: 0.6772
8576/9969 [========================>.....] - ETA: 0s - loss: 0.5933 - acc: 0.6760
8896/9969 [=========================>....] - ETA: 0s - loss: 0.5936 - acc: 0.6759
9216/9969 [==========================>...] - ETA: 0s - loss: 0.5930 - acc: 0.6772
9536/9969 [===========================>..] - ETA: 0s - loss: 0.5932 - acc: 0.6773
9856/9969 [============================>.] - ETA: 0s - loss: 0.5925 - acc: 0.6779
9969/9969 [==============================] - 2s 179us/step - loss: 0.5924 - acc: 0.6782 - val_loss: 0.6231 - val_acc: 0.6489

Epoch 00006: val_acc did not improve from 0.65884
Epoch 7/10

  64/9969 [..............................] - ETA: 2s - loss: 0.5650 - acc: 0.7344
 384/9969 [>.............................] - ETA: 1s - loss: 0.6085 - acc: 0.6693
 704/9969 [=>............................] - ETA: 1s - loss: 0.5989 - acc: 0.6619
1024/9969 [==>...........................] - ETA: 1s - loss: 0.5916 - acc: 0.6719
1344/9969 [===>..........................] - ETA: 1s - loss: 0.5853 - acc: 0.6778
1664/9969 [====>.........................] - ETA: 1s - loss: 0.5840 - acc: 0.6785
1984/9969 [====>.........................] - ETA: 1s - loss: 0.5854 - acc: 0.6764
2304/9969 [=====>........................] - ETA: 1s - loss: 0.5838 - acc: 0.6797
2624/9969 [======>.......................] - ETA: 1s - loss: 0.5820 - acc: 0.6772
2944/9969 [=======>......................] - ETA: 1s - loss: 0.5798 - acc: 0.6810
3264/9969 [========>.....................] - ETA: 1s - loss: 0.5789 - acc: 0.6820
3584/9969 [=========>....................] - ETA: 1s - loss: 0.5795 - acc: 0.6836
3904/9969 [==========>...................] - ETA: 1s - loss: 0.5794 - acc: 0.6844
4224/9969 [===========>..................] - ETA: 0s - loss: 0.5786 - acc: 0.6863
4544/9969 [============>.................] - ETA: 0s - loss: 0.5786 - acc: 0.6866
4864/9969 [=============>................] - ETA: 0s - loss: 0.5771 - acc: 0.6889
5184/9969 [==============>...............] - ETA: 0s - loss: 0.5806 - acc: 0.6844
5504/9969 [===============>..............] - ETA: 0s - loss: 0.5807 - acc: 0.6844
5824/9969 [================>.............] - ETA: 0s - loss: 0.5818 - acc: 0.6836
6144/9969 [=================>............] - ETA: 0s - loss: 0.5843 - acc: 0.6831
6400/9969 [==================>...........] - ETA: 0s - loss: 0.5840 - acc: 0.6847
6720/9969 [===================>..........] - ETA: 0s - loss: 0.5828 - acc: 0.6857
7040/9969 [====================>.........] - ETA: 0s - loss: 0.5816 - acc: 0.6871
7360/9969 [=====================>........] - ETA: 0s - loss: 0.5812 - acc: 0.6887
7680/9969 [======================>.......] - ETA: 0s - loss: 0.5827 - acc: 0.6882
8064/9969 [=======================>......] - ETA: 0s - loss: 0.5841 - acc: 0.6871
8384/9969 [========================>.....] - ETA: 0s - loss: 0.5856 - acc: 0.6861
8704/9969 [=========================>....] - ETA: 0s - loss: 0.5858 - acc: 0.6849
9024/9969 [==========================>...] - ETA: 0s - loss: 0.5855 - acc: 0.6842
9344/9969 [===========================>..] - ETA: 0s - loss: 0.5839 - acc: 0.6859
9728/9969 [============================>.] - ETA: 0s - loss: 0.5835 - acc: 0.6858
9969/9969 [==============================] - 2s 179us/step - loss: 0.5834 - acc: 0.6863 - val_loss: 0.6025 - val_acc: 0.6625

Epoch 00007: val_acc improved from 0.65884 to 0.66245, saving model to /data/lyli/Silencer/K562/datasets/6924/5fold/model/checkpoints_4layer_100-/DNA_model/model_DNA5.hdf5
Epoch 8/10

  64/9969 [..............................] - ETA: 2s - loss: 0.5547 - acc: 0.7656
 384/9969 [>.............................] - ETA: 1s - loss: 0.5127 - acc: 0.7682
 768/9969 [=>............................] - ETA: 1s - loss: 0.5309 - acc: 0.7370
1152/9969 [==>...........................] - ETA: 1s - loss: 0.5519 - acc: 0.7101
1472/9969 [===>..........................] - ETA: 1s - loss: 0.5633 - acc: 0.6990
1792/9969 [====>.........................] - ETA: 1s - loss: 0.5739 - acc: 0.6931
2112/9969 [=====>........................] - ETA: 1s - loss: 0.5719 - acc: 0.6970
2496/9969 [======>.......................] - ETA: 1s - loss: 0.5675 - acc: 0.7015
2816/9969 [=======>......................] - ETA: 1s - loss: 0.5664 - acc: 0.7024
3136/9969 [========>.....................] - ETA: 1s - loss: 0.5661 - acc: 0.7025
3456/9969 [=========>....................] - ETA: 1s - loss: 0.5638 - acc: 0.7025
3840/9969 [==========>...................] - ETA: 1s - loss: 0.5668 - acc: 0.6971
4160/9969 [===========>..................] - ETA: 0s - loss: 0.5678 - acc: 0.6964
4480/9969 [============>.................] - ETA: 0s - loss: 0.5683 - acc: 0.6953
4800/9969 [=============>................] - ETA: 0s - loss: 0.5678 - acc: 0.6967
5120/9969 [==============>...............] - ETA: 0s - loss: 0.5698 - acc: 0.6943
5440/9969 [===============>..............] - ETA: 0s - loss: 0.5688 - acc: 0.6967
5760/9969 [================>.............] - ETA: 0s - loss: 0.5706 - acc: 0.6957
6080/9969 [=================>............] - ETA: 0s - loss: 0.5702 - acc: 0.6959
6400/9969 [==================>...........] - ETA: 0s - loss: 0.5701 - acc: 0.6969
6720/9969 [===================>..........] - ETA: 0s - loss: 0.5700 - acc: 0.6976
7040/9969 [====================>.........] - ETA: 0s - loss: 0.5685 - acc: 0.6973
7424/9969 [=====================>........] - ETA: 0s - loss: 0.5688 - acc: 0.6980
7744/9969 [======================>.......] - ETA: 0s - loss: 0.5695 - acc: 0.6971
8064/9969 [=======================>......] - ETA: 0s - loss: 0.5712 - acc: 0.6959
8320/9969 [========================>.....] - ETA: 0s - loss: 0.5700 - acc: 0.6972
8640/9969 [=========================>....] - ETA: 0s - loss: 0.5698 - acc: 0.6976
9024/9969 [==========================>...] - ETA: 0s - loss: 0.5702 - acc: 0.6966
9344/9969 [===========================>..] - ETA: 0s - loss: 0.5710 - acc: 0.6958
9664/9969 [============================>.] - ETA: 0s - loss: 0.5704 - acc: 0.6960
9969/9969 [==============================] - 2s 176us/step - loss: 0.5690 - acc: 0.6971 - val_loss: 0.6143 - val_acc: 0.6670

Epoch 00008: val_acc improved from 0.66245 to 0.66697, saving model to /data/lyli/Silencer/K562/datasets/6924/5fold/model/checkpoints_4layer_100-/DNA_model/model_DNA5.hdf5
Epoch 9/10

  64/9969 [..............................] - ETA: 1s - loss: 0.5540 - acc: 0.6562
 384/9969 [>.............................] - ETA: 1s - loss: 0.5310 - acc: 0.7266
 704/9969 [=>............................] - ETA: 1s - loss: 0.5211 - acc: 0.7443
 960/9969 [=>............................] - ETA: 1s - loss: 0.5403 - acc: 0.7354
1280/9969 [==>...........................] - ETA: 1s - loss: 0.5416 - acc: 0.7320
1600/9969 [===>..........................] - ETA: 1s - loss: 0.5414 - acc: 0.7331
1920/9969 [====>.........................] - ETA: 1s - loss: 0.5488 - acc: 0.7234
2240/9969 [=====>........................] - ETA: 1s - loss: 0.5510 - acc: 0.7214
2560/9969 [======>.......................] - ETA: 1s - loss: 0.5468 - acc: 0.7230
2880/9969 [=======>......................] - ETA: 1s - loss: 0.5484 - acc: 0.7229
3264/9969 [========>.....................] - ETA: 1s - loss: 0.5481 - acc: 0.7215
3584/9969 [=========>....................] - ETA: 1s - loss: 0.5457 - acc: 0.7213
3968/9969 [==========>...................] - ETA: 1s - loss: 0.5444 - acc: 0.7215
4352/9969 [============>.................] - ETA: 0s - loss: 0.5487 - acc: 0.7162
4672/9969 [=============>................] - ETA: 0s - loss: 0.5464 - acc: 0.7196
5056/9969 [==============>...............] - ETA: 0s - loss: 0.5470 - acc: 0.7182
5376/9969 [===============>..............] - ETA: 0s - loss: 0.5472 - acc: 0.7174
5760/9969 [================>.............] - ETA: 0s - loss: 0.5475 - acc: 0.7161
6080/9969 [=================>............] - ETA: 0s - loss: 0.5459 - acc: 0.7176
6400/9969 [==================>...........] - ETA: 0s - loss: 0.5465 - acc: 0.7186
6720/9969 [===================>..........] - ETA: 0s - loss: 0.5474 - acc: 0.7180
7040/9969 [====================>.........] - ETA: 0s - loss: 0.5479 - acc: 0.7169
7360/9969 [=====================>........] - ETA: 0s - loss: 0.5484 - acc: 0.7155
7680/9969 [======================>.......] - ETA: 0s - loss: 0.5495 - acc: 0.7150
8000/9969 [=======================>......] - ETA: 0s - loss: 0.5508 - acc: 0.7136
8384/9969 [========================>.....] - ETA: 0s - loss: 0.5511 - acc: 0.7135
8768/9969 [=========================>....] - ETA: 0s - loss: 0.5512 - acc: 0.7130
9088/9969 [==========================>...] - ETA: 0s - loss: 0.5531 - acc: 0.7113
9408/9969 [===========================>..] - ETA: 0s - loss: 0.5538 - acc: 0.7099
9728/9969 [============================>.] - ETA: 0s - loss: 0.5534 - acc: 0.7100
9969/9969 [==============================] - 2s 177us/step - loss: 0.5541 - acc: 0.7095 - val_loss: 0.6003 - val_acc: 0.6697

Epoch 00009: val_acc improved from 0.66697 to 0.66968, saving model to /data/lyli/Silencer/K562/datasets/6924/5fold/model/checkpoints_4layer_100-/DNA_model/model_DNA5.hdf5
Epoch 10/10

  64/9969 [..............................] - ETA: 1s - loss: 0.4938 - acc: 0.7656
 384/9969 [>.............................] - ETA: 1s - loss: 0.5254 - acc: 0.7474
 704/9969 [=>............................] - ETA: 1s - loss: 0.5154 - acc: 0.7457
1024/9969 [==>...........................] - ETA: 1s - loss: 0.5152 - acc: 0.7559
1344/9969 [===>..........................] - ETA: 1s - loss: 0.5163 - acc: 0.7567
1728/9969 [====>.........................] - ETA: 1s - loss: 0.5129 - acc: 0.7500
2048/9969 [=====>........................] - ETA: 1s - loss: 0.5088 - acc: 0.7520
2368/9969 [======>.......................] - ETA: 1s - loss: 0.5118 - acc: 0.7513
2688/9969 [=======>......................] - ETA: 1s - loss: 0.5112 - acc: 0.7496
3008/9969 [========>.....................] - ETA: 1s - loss: 0.5144 - acc: 0.7440
3328/9969 [=========>....................] - ETA: 1s - loss: 0.5140 - acc: 0.7422
3648/9969 [=========>....................] - ETA: 1s - loss: 0.5152 - acc: 0.7440
4032/9969 [===========>..................] - ETA: 1s - loss: 0.5172 - acc: 0.7428
4352/9969 [============>.................] - ETA: 0s - loss: 0.5199 - acc: 0.7397
4672/9969 [=============>................] - ETA: 0s - loss: 0.5243 - acc: 0.7359
4992/9969 [==============>...............] - ETA: 0s - loss: 0.5255 - acc: 0.7328
5312/9969 [==============>...............] - ETA: 0s - loss: 0.5272 - acc: 0.7306
5632/9969 [===============>..............] - ETA: 0s - loss: 0.5297 - acc: 0.7276
5952/9969 [================>.............] - ETA: 0s - loss: 0.5301 - acc: 0.7261
6272/9969 [=================>............] - ETA: 0s - loss: 0.5304 - acc: 0.7250
6592/9969 [==================>...........] - ETA: 0s - loss: 0.5317 - acc: 0.7247
6912/9969 [===================>..........] - ETA: 0s - loss: 0.5336 - acc: 0.7245
7232/9969 [====================>.........] - ETA: 0s - loss: 0.5358 - acc: 0.7233
7616/9969 [=====================>........] - ETA: 0s - loss: 0.5353 - acc: 0.7231
8000/9969 [=======================>......] - ETA: 0s - loss: 0.5368 - acc: 0.7226
8320/9969 [========================>.....] - ETA: 0s - loss: 0.5371 - acc: 0.7224
8640/9969 [=========================>....] - ETA: 0s - loss: 0.5378 - acc: 0.7225
8960/9969 [=========================>....] - ETA: 0s - loss: 0.5392 - acc: 0.7220
9344/9969 [===========================>..] - ETA: 0s - loss: 0.5390 - acc: 0.7219
9664/9969 [============================>.] - ETA: 0s - loss: 0.5401 - acc: 0.7205
9969/9969 [==============================] - 2s 177us/step - loss: 0.5407 - acc: 0.7201 - val_loss: 0.6117 - val_acc: 0.6534

Epoch 00010: val_acc did not improve from 0.66968
Saved model to disk
ACC: 0.6578757225433526
Sens: 0.6173285198555957
Spec: 0.6984815618221258
MCC: 0.3168491995482249
ROC_AUC: 0.7288910467747871
PRC_ROC: 0.7199634265112901
ACC_average: 0.656864161849711
Sens_average: 0.6532377638944598
Spec_average: 0.6605157178806411
MCC_average: 0.314256802611878
ROC_average: 0.7208590719257602
PRC_average: 0.7142465219164358
